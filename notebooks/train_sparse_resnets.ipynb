{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ox72K94Tk_f",
   "metadata": {
    "id": "0ox72K94Tk_f"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "EoU7-e4NcM4c",
   "metadata": {
    "id": "EoU7-e4NcM4c",
    "outputId": "bfe7b96a-3a75-43da-b0ef-9854dfa1dbee",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Jan 12 01:40:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   31C    P0    41W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# clone apex\n",
    "!git clone https://github.com/NVIDIA/apex"
   ],
   "metadata": {
    "id": "Ql05uVturRYD",
    "outputId": "547bb8f6-c0ca-48c0-e39e-891055e313aa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "Ql05uVturRYD",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 10686, done.\u001b[K\n",
      "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
      "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
      "remote: Total 10686 (delta 120), reused 119 (delta 62), pack-reused 10478\u001b[K\n",
      "Receiving objects: 100% (10686/10686), 15.22 MiB | 32.67 MiB/s, done.\n",
      "Resolving deltas: 100% (7348/7348), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# install apex\n",
    "!cd apex && pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--permutation_search\" ./"
   ],
   "metadata": {
    "id": "8-ADq-absivt",
    "outputId": "1bcfadab-4967-408d-cab5-0f76e5ab0a45",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "8-ADq-absivt",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mWARNING: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\u001b[0m\u001b[33m\n",
      "\u001b[0mUsing pip 22.0.4 from /usr/local/lib/python3.8/dist-packages/pip (python 3.8)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Processing /content/apex\n",
      "  Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.13.1+cu116\n",
      "\n",
      "\n",
      "  running egg_info\n",
      "  creating /tmp/pip-pip-egg-info-09sxrs62/apex.egg-info\n",
      "  writing /tmp/pip-pip-egg-info-09sxrs62/apex.egg-info/PKG-INFO\n",
      "  writing dependency_links to /tmp/pip-pip-egg-info-09sxrs62/apex.egg-info/dependency_links.txt\n",
      "  writing requirements to /tmp/pip-pip-egg-info-09sxrs62/apex.egg-info/requires.txt\n",
      "  writing top-level names to /tmp/pip-pip-egg-info-09sxrs62/apex.egg-info/top_level.txt\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-09sxrs62/apex.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-09sxrs62/apex.egg-info/SOURCES.txt'\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: packaging>20.6 in /usr/local/lib/python3.8/dist-packages (from apex==0.1) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>20.6->apex==0.1) (3.0.9)\n",
      "Skipping wheel build for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Running command Running setup.py install for apex\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.13.1+cu116\n",
      "\n",
      "\n",
      "  running install\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.8\n",
      "  creating build/lib.linux-x86_64-3.8/apex\n",
      "  copying apex/_autocast_utils.py -> build/lib.linux-x86_64-3.8/apex\n",
      "  copying apex/__init__.py -> build/lib.linux-x86_64-3.8/apex\n",
      "  creating build/lib.linux-x86_64-3.8/apex/transformer\n",
      "  copying apex/transformer/_ucc_util.py -> build/lib.linux-x86_64-3.8/apex/transformer\n",
      "  copying apex/transformer/log_util.py -> build/lib.linux-x86_64-3.8/apex/transformer\n",
      "  copying apex/transformer/enums.py -> build/lib.linux-x86_64-3.8/apex/transformer\n",
      "  copying apex/transformer/utils.py -> build/lib.linux-x86_64-3.8/apex/transformer\n",
      "  copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-3.8/apex/transformer\n",
      "  copying apex/transformer/__init__.py -> build/lib.linux-x86_64-3.8/apex/transformer\n",
      "  copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-3.8/apex/transformer\n",
      "  creating build/lib.linux-x86_64-3.8/apex/fused_dense\n",
      "  copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-3.8/apex/fused_dense\n",
      "  copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-3.8/apex/fused_dense\n",
      "  creating build/lib.linux-x86_64-3.8/apex/normalization\n",
      "  copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.8/apex/normalization\n",
      "  copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.8/apex/normalization\n",
      "  creating build/lib.linux-x86_64-3.8/apex/parallel\n",
      "  copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.8/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.8/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.8/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.8/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.8/apex/parallel\n",
      "  copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.8/apex/parallel\n",
      "  copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.8/apex/parallel\n",
      "  copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.8/apex/parallel\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib\n",
      "  copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib\n",
      "  creating build/lib.linux-x86_64-3.8/apex/RNN\n",
      "  copying apex/RNN/models.py -> build/lib.linux-x86_64-3.8/apex/RNN\n",
      "  copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.8/apex/RNN\n",
      "  copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.8/apex/RNN\n",
      "  copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.8/apex/RNN\n",
      "  creating build/lib.linux-x86_64-3.8/apex/optimizers\n",
      "  copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n",
      "  copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n",
      "  copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n",
      "  copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n",
      "  copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n",
      "  copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n",
      "  copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.8/apex/optimizers\n",
      "  creating build/lib.linux-x86_64-3.8/apex/mlp\n",
      "  copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.8/apex/mlp\n",
      "  copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.8/apex/mlp\n",
      "  creating build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/opt.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/handle.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/utils.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/amp.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/compat.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.8/apex/amp\n",
      "  creating build/lib.linux-x86_64-3.8/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.8/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.8/apex/fp16_utils\n",
      "  copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.8/apex/fp16_utils\n",
      "  copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.8/apex/fp16_utils\n",
      "  creating build/lib.linux-x86_64-3.8/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.8/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.8/apex/multi_tensor_apply\n",
      "  creating build/lib.linux-x86_64-3.8/apex/transformer/testing\n",
      "  copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-3.8/apex/transformer/testing\n",
      "  copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-3.8/apex/transformer/testing\n",
      "  copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-3.8/apex/transformer/testing\n",
      "  copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-3.8/apex/transformer/testing\n",
      "  copying apex/transformer/testing/distributed_test_base.py -> build/lib.linux-x86_64-3.8/apex/transformer/testing\n",
      "  copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-3.8/apex/transformer/testing\n",
      "  copying apex/transformer/testing/standalone_transformer_lm.py -> build/lib.linux-x86_64-3.8/apex/transformer/testing\n",
      "  copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-3.8/apex/transformer/testing\n",
      "  creating build/lib.linux-x86_64-3.8/apex/transformer/_data\n",
      "  copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-3.8/apex/transformer/_data\n",
      "  copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-3.8/apex/transformer/_data\n",
      "  creating build/lib.linux-x86_64-3.8/apex/transformer/functional\n",
      "  copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-3.8/apex/transformer/functional\n",
      "  copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-3.8/apex/transformer/functional\n",
      "  creating build/lib.linux-x86_64-3.8/apex/transformer/amp\n",
      "  copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-3.8/apex/transformer/amp\n",
      "  copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-3.8/apex/transformer/amp\n",
      "  creating build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel\n",
      "  copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel\n",
      "  copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel\n",
      "  copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel\n",
      "  copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel\n",
      "  copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel\n",
      "  copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel\n",
      "  copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel\n",
      "  copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel\n",
      "  creating build/lib.linux-x86_64-3.8/apex/transformer/layers\n",
      "  copying apex/transformer/layers/layer_norm.py -> build/lib.linux-x86_64-3.8/apex/transformer/layers\n",
      "  copying apex/transformer/layers/__init__.py -> build/lib.linux-x86_64-3.8/apex/transformer/layers\n",
      "  creating build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel\n",
      "  copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel\n",
      "  copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel\n",
      "  copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel\n",
      "  copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel\n",
      "  creating build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules\n",
      "  copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules\n",
      "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules\n",
      "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules\n",
      "  copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules\n",
      "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/cudnn_gbn\n",
      "  copying apex/contrib/cudnn_gbn/batch_norm.py -> build/lib.linux-x86_64-3.8/apex/contrib/cudnn_gbn\n",
      "  copying apex/contrib/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/cudnn_gbn\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/focal_loss\n",
      "  copying apex/contrib/focal_loss/focal_loss.py -> build/lib.linux-x86_64-3.8/apex/contrib/focal_loss\n",
      "  copying apex/contrib/focal_loss/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/focal_loss\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.8/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/groupbn\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/clip_grad\n",
      "  copying apex/contrib/clip_grad/clip_grad.py -> build/lib.linux-x86_64-3.8/apex/contrib/clip_grad\n",
      "  copying apex/contrib/clip_grad/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/clip_grad\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/permutation_lib.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/transducer\n",
      "  copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-3.8/apex/contrib/transducer\n",
      "  copying apex/contrib/transducer/_transducer_ref.py -> build/lib.linux-x86_64-3.8/apex/contrib/transducer\n",
      "  copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/transducer\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/index_mul_2d\n",
      "  copying apex/contrib/index_mul_2d/index_mul_2d.py -> build/lib.linux-x86_64-3.8/apex/contrib/index_mul_2d\n",
      "  copying apex/contrib/index_mul_2d/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/index_mul_2d\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/layer_norm\n",
      "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-3.8/apex/contrib/layer_norm\n",
      "  copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/layer_norm\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/optimizers\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.8/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/xentropy\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test\n",
      "  copying apex/contrib/test/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/peer_memory\n",
      "  copying apex/contrib/peer_memory/peer_memory.py -> build/lib.linux-x86_64-3.8/apex/contrib/peer_memory\n",
      "  copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib.linux-x86_64-3.8/apex/contrib/peer_memory\n",
      "  copying apex/contrib/peer_memory/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/peer_memory\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-3.8/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib.linux-x86_64-3.8/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-3.8/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/bottleneck\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/conv_bias_relu\n",
      "  copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib.linux-x86_64-3.8/apex/contrib/conv_bias_relu\n",
      "  copying apex/contrib/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/conv_bias_relu\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/fmha\n",
      "  copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-3.8/apex/contrib/fmha\n",
      "  copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/fmha\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/cudnn_gbn\n",
      "  copying apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/cudnn_gbn\n",
      "  copying apex/contrib/test/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/cudnn_gbn\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/focal_loss\n",
      "  copying apex/contrib/test/focal_loss/test_focal_loss.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/focal_loss\n",
      "  copying apex/contrib/test/focal_loss/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/focal_loss\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/clip_grad\n",
      "  copying apex/contrib/test/clip_grad/test_clip_grad.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/clip_grad\n",
      "  copying apex/contrib/test/clip_grad/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/clip_grad\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn\n",
      "  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn\n",
      "  copying apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn\n",
      "  copying apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn\n",
      "  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn\n",
      "  copying apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn\n",
      "  copying apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn\n",
      "  copying apex/contrib/test/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/transducer\n",
      "  copying apex/contrib/test/transducer/test_transducer_loss.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/transducer\n",
      "  copying apex/contrib/test/transducer/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/transducer\n",
      "  copying apex/contrib/test/transducer/test_transducer_joint.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/transducer\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/index_mul_2d\n",
      "  copying apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/index_mul_2d\n",
      "  copying apex/contrib/test/index_mul_2d/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/index_mul_2d\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/layer_norm\n",
      "  copying apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/layer_norm\n",
      "  copying apex/contrib/test/layer_norm/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/layer_norm\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/optimizers\n",
      "  copying apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/optimizers\n",
      "  copying apex/contrib/test/optimizers/test_dist_adam.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/optimizers\n",
      "  copying apex/contrib/test/optimizers/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/optimizers\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/xentropy\n",
      "  copying apex/contrib/test/xentropy/test_label_smoothing.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/xentropy\n",
      "  copying apex/contrib/test/xentropy/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/xentropy\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/peer_memory\n",
      "  copying apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/peer_memory\n",
      "  copying apex/contrib/test/peer_memory/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/peer_memory\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/bottleneck\n",
      "  copying apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/bottleneck\n",
      "  copying apex/contrib/test/bottleneck/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/bottleneck\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/conv_bias_relu\n",
      "  copying apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/conv_bias_relu\n",
      "  copying apex/contrib/test/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/conv_bias_relu\n",
      "  creating build/lib.linux-x86_64-3.8/apex/contrib/test/fmha\n",
      "  copying apex/contrib/test/fmha/test_fmha.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/fmha\n",
      "  copying apex/contrib/test/fmha/__init__.py -> build/lib.linux-x86_64-3.8/apex/contrib/test/fmha\n",
      "  creating build/lib.linux-x86_64-3.8/apex/amp/lists\n",
      "  copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.8/apex/amp/lists\n",
      "  copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.8/apex/amp/lists\n",
      "  copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.8/apex/amp/lists\n",
      "  copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.8/apex/amp/lists\n",
      "  running build_ext\n",
      "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "    warnings.warn(msg.format('we could not find ninja.'))\n",
      "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
      "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
      "  building 'permutation_search_cuda' extension\n",
      "  creating build/temp.linux-x86_64-3.8\n",
      "  creating build/temp.linux-x86_64-3.8/apex\n",
      "  creating build/temp.linux-x86_64-3.8/apex/contrib\n",
      "  creating build/temp.linux-x86_64-3.8/apex/contrib/sparsity\n",
      "  creating build/temp.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels\n",
      "  creating build/temp.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels/CUDA_kernels\n",
      "  /usr/local/cuda/bin/nvcc -I/content/apex/apex/contrib/sparsity/permutation_search_kernels/CUDA_kernels -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c apex/contrib/sparsity/permutation_search_kernels/CUDA_kernels/permutation_search_kernels.cu -o build/temp.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels/CUDA_kernels/permutation_search_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -Xcompiler -fPIC -shared -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=permutation_search_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  apex/contrib/sparsity/permutation_search_kernels/CUDA_kernels/permutation_search_kernels.cu(78): warning: extern declaration of the entity s is treated as a static definition\n",
      "\n",
      "  apex/contrib/sparsity/permutation_search_kernels/CUDA_kernels/permutation_search_kernels.cu(290): warning: extern declaration of the entity pm_shared is treated as a static definition\n",
      "\n",
      "  apex/contrib/sparsity/permutation_search_kernels/CUDA_kernels/permutation_search_kernels.cu(571): warning: extern declaration of the entity cs is treated as a static definition\n",
      "\n",
      "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels/CUDA_kernels/permutation_search_kernels.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/permutation_search_cuda.cpython-38-x86_64-linux-gnu.so\n",
      "  running install_lib\n",
      "  copying build/lib.linux-x86_64-3.8/permutation_search_cuda.cpython-38-x86_64-linux-gnu.so -> /usr/local/lib/python3.8/dist-packages\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/transformer\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/testing/arguments.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/testing/global_vars.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/testing/commons.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/testing/standalone_bert.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/testing/distributed_test_base.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/testing/standalone_gpt.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/testing/standalone_transformer_lm.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/testing\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/testing/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/testing\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/transformer/_data\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/_data/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/_data\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/_data/_batchsampler.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/_data\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/_ucc_util.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/log_util.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/transformer/functional\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/functional/fused_softmax.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/functional\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/functional/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/functional\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/enums.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/transformer/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/amp/grad_scaler.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/amp/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/utils.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/microbatches.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel/mappings.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel/random.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel/layers.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel/utils.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel/data.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel/memory.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel/cross_entropy.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/tensor_parallel/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/transformer/layers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/layers/layer_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/layers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/layers/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/layers\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/_timers.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/utils.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/p2p_communication.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules/common.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/pipeline_parallel/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/transformer/parallel_state.py -> /usr/local/lib/python3.8/dist-packages/apex/transformer\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/fused_dense\n",
      "  copying build/lib.linux-x86_64-3.8/apex/fused_dense/fused_dense.py -> /usr/local/lib/python3.8/dist-packages/apex/fused_dense\n",
      "  copying build/lib.linux-x86_64-3.8/apex/fused_dense/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/fused_dense\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/normalization\n",
      "  copying build/lib.linux-x86_64-3.8/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/normalization\n",
      "  copying build/lib.linux-x86_64-3.8/apex/normalization/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/normalization\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/parallel/multiproc.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/parallel/distributed.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/parallel/LARC.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n",
      "  copying build/lib.linux-x86_64-3.8/apex/parallel/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/parallel\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/cudnn_gbn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/cudnn_gbn/batch_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/cudnn_gbn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/cudnn_gbn/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/cudnn_gbn\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/focal_loss\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/focal_loss/focal_loss.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/focal_loss\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/focal_loss/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/focal_loss\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/clip_grad\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/clip_grad/clip_grad.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/clip_grad\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/clip_grad/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/clip_grad\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/permutation_lib.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/transducer\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/transducer/transducer.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/transducer\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/transducer/_transducer_ref.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/transducer\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/transducer/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/transducer\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/index_mul_2d\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/index_mul_2d/index_mul_2d.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/index_mul_2d\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/index_mul_2d/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/index_mul_2d\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/layer_norm/layer_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/layer_norm/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/cudnn_gbn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/cudnn_gbn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/cudnn_gbn/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/cudnn_gbn\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/focal_loss\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/focal_loss/test_focal_loss.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/focal_loss\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/focal_loss/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/focal_loss\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/clip_grad\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/clip_grad/test_clip_grad.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/clip_grad\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/clip_grad/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/clip_grad\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/multihead_attn/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/transducer\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/transducer/test_transducer_loss.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/transducer\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/transducer/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/transducer\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/transducer/test_transducer_joint.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/transducer\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/index_mul_2d\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/index_mul_2d\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/index_mul_2d/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/index_mul_2d\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/layer_norm\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/layer_norm\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/layer_norm/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/layer_norm\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/optimizers/test_dist_adam.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/optimizers/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/optimizers\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/xentropy\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/xentropy/test_label_smoothing.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/xentropy\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/xentropy/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/xentropy\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/peer_memory\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/peer_memory\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/peer_memory/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/peer_memory\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/bottleneck\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/bottleneck/test_bottleneck_module.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/bottleneck\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/bottleneck/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/bottleneck\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/conv_bias_relu\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/conv_bias_relu\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/conv_bias_relu/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/conv_bias_relu\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/test/fmha\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/fmha/test_fmha.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/fmha\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/fmha/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test/fmha\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/test/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/test\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/peer_memory\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/peer_memory/peer_memory.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/peer_memory\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/peer_memory\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/peer_memory/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/peer_memory\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/bottleneck\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/bottleneck/bottleneck.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/bottleneck\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/bottleneck/halo_exchangers.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/bottleneck\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/bottleneck/test.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/bottleneck\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/bottleneck/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/bottleneck\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/conv_bias_relu\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/conv_bias_relu/conv_bias_relu.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/conv_bias_relu\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/conv_bias_relu/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/conv_bias_relu\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/contrib/fmha\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/fmha/fmha.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/fmha\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/fmha/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib/fmha\n",
      "  copying build/lib.linux-x86_64-3.8/apex/contrib/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/contrib\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/RNN\n",
      "  copying build/lib.linux-x86_64-3.8/apex/RNN/models.py -> /usr/local/lib/python3.8/dist-packages/apex/RNN\n",
      "  copying build/lib.linux-x86_64-3.8/apex/RNN/cells.py -> /usr/local/lib/python3.8/dist-packages/apex/RNN\n",
      "  copying build/lib.linux-x86_64-3.8/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.8/dist-packages/apex/RNN\n",
      "  copying build/lib.linux-x86_64-3.8/apex/RNN/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/RNN\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/optimizers/fused_mixed_precision_lamb.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n",
      "  copying build/lib.linux-x86_64-3.8/apex/optimizers/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/optimizers\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/mlp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/mlp/mlp.py -> /usr/local/lib/python3.8/dist-packages/apex/mlp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/mlp/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/mlp\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/scaler.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/opt.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/handle.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/_amp_state.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/utils.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/_initialize.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/__version__.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/lists/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.8/dist-packages/apex/amp/lists\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/frontend.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/amp.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/compat.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/rnn_compat.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  copying build/lib.linux-x86_64-3.8/apex/amp/wrap.py -> /usr/local/lib/python3.8/dist-packages/apex/amp\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n",
      "  copying build/lib.linux-x86_64-3.8/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n",
      "  copying build/lib.linux-x86_64-3.8/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n",
      "  copying build/lib.linux-x86_64-3.8/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n",
      "  copying build/lib.linux-x86_64-3.8/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/fp16_utils\n",
      "  creating /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply\n",
      "  copying build/lib.linux-x86_64-3.8/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply\n",
      "  copying build/lib.linux-x86_64-3.8/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply\n",
      "  copying build/lib.linux-x86_64-3.8/apex/_autocast_utils.py -> /usr/local/lib/python3.8/dist-packages/apex\n",
      "  copying build/lib.linux-x86_64-3.8/apex/__init__.py -> /usr/local/lib/python3.8/dist-packages/apex\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/testing/arguments.py to arguments.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/testing/global_vars.py to global_vars.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/testing/commons.py to commons.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/testing/standalone_bert.py to standalone_bert.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/testing/distributed_test_base.py to distributed_test_base.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/testing/standalone_gpt.py to standalone_gpt.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/testing/standalone_transformer_lm.py to standalone_transformer_lm.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/testing/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/_data/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/_data/_batchsampler.py to _batchsampler.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/_ucc_util.py to _ucc_util.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/log_util.py to log_util.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/functional/fused_softmax.py to fused_softmax.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/functional/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/enums.py to enums.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/amp/grad_scaler.py to grad_scaler.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/amp/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/utils.py to utils.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/microbatches.py to microbatches.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel/mappings.py to mappings.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel/random.py to random.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel/layers.py to layers.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel/utils.py to utils.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel/data.py to data.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel/memory.py to memory.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel/cross_entropy.py to cross_entropy.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/tensor_parallel/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/layers/layer_norm.py to layer_norm.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/layers/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/_timers.py to _timers.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py to utils.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/p2p_communication.py to p2p_communication.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules/common.py to common.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py to fwd_bwd_no_pipelining.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py to fwd_bwd_pipelining_without_interleaving.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py to fwd_bwd_pipelining_with_interleaving.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/transformer/parallel_state.py to parallel_state.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fused_dense/fused_dense.py to fused_dense.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fused_dense/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/normalization/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/distributed.py to distributed.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/LARC.py to LARC.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/parallel/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/cudnn_gbn/batch_norm.py to batch_norm.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/cudnn_gbn/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/focal_loss/focal_loss.py to focal_loss.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/focal_loss/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/clip_grad/clip_grad.py to clip_grad.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/clip_grad/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py to call_permutation_search_kernels.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py to channel_swap.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py to exhaustive_search.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py to permutation_utilities.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_search_kernels/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/permutation_lib.py to permutation_lib.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/transducer/transducer.py to transducer.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/transducer/_transducer_ref.py to _transducer_ref.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/transducer/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/index_mul_2d/index_mul_2d.py to index_mul_2d.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/index_mul_2d/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/layer_norm/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py to test_cudnn_gbn_with_two_gpus.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/cudnn_gbn/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/focal_loss/test_focal_loss.py to test_focal_loss.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/focal_loss/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/clip_grad/test_clip_grad.py to test_clip_grad.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/clip_grad/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py to test_encdec_multihead_attn.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py to test_fast_self_multihead_attn_bias.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py to test_mha_fused_softmax.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py to test_encdec_multihead_attn_norm_add.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py to test_self_multihead_attn_norm_add.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn/test_self_multihead_attn.py to test_self_multihead_attn.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/multihead_attn/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/transducer/test_transducer_loss.py to test_transducer_loss.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/transducer/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/transducer/test_transducer_joint.py to test_transducer_joint.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/index_mul_2d/test_index_mul_2d.py to test_index_mul_2d.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/index_mul_2d/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/layer_norm/test_fast_layer_norm.py to test_fast_layer_norm.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/layer_norm/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/optimizers/test_distributed_fused_lamb.py to test_distributed_fused_lamb.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/optimizers/test_dist_adam.py to test_dist_adam.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/optimizers/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/xentropy/test_label_smoothing.py to test_label_smoothing.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/xentropy/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py to test_peer_halo_exchange_module.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/peer_memory/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/bottleneck/test_bottleneck_module.py to test_bottleneck_module.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/bottleneck/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py to test_conv_bias_relu.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/conv_bias_relu/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/fmha/test_fmha.py to test_fmha.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/fmha/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/test/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/peer_memory/peer_memory.py to peer_memory.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/peer_memory/peer_halo_exchanger_1d.py to peer_halo_exchanger_1d.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/peer_memory/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/bottleneck/halo_exchangers.py to halo_exchangers.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/bottleneck/test.py to test.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/bottleneck/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/conv_bias_relu/conv_bias_relu.py to conv_bias_relu.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/conv_bias_relu/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/fmha/fmha.py to fmha.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/fmha/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/contrib/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/RNN/models.py to models.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/RNN/cells.py to cells.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/RNN/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/fused_mixed_precision_lamb.py to fused_mixed_precision_lamb.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/optimizers/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/mlp/mlp.py to mlp.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/mlp/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/scaler.py to scaler.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/opt.py to opt.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/handle.py to handle.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/utils.py to utils.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/_initialize.py to _initialize.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/__version__.py to __version__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/frontend.py to frontend.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/amp.py to amp.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/compat.py to compat.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/amp/wrap.py to wrap.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/_autocast_utils.py to _autocast_utils.cpython-38.pyc\n",
      "  byte-compiling /usr/local/lib/python3.8/dist-packages/apex/__init__.py to __init__.cpython-38.pyc\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  creating apex.egg-info\n",
      "  writing apex.egg-info/PKG-INFO\n",
      "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "  writing requirements to apex.egg-info/requires.txt\n",
      "  writing top-level names to apex.egg-info/top_level.txt\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  Copying apex.egg-info to /usr/local/lib/python3.8/dist-packages/apex-0.1-py3.8.egg-info\n",
      "  running install_scripts\n",
      "  writing list of installed files to '/tmp/pip-record-1o6bwauo/install-record.txt'\n",
      "  Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
      "Successfully installed apex-0.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ObaBHw6wWCD0",
   "metadata": {
    "id": "ObaBHw6wWCD0"
   },
   "outputs": [],
   "source": [
    "# reload modules in .py files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999c2bc6",
   "metadata": {
    "id": "999c2bc6",
    "outputId": "c8b1c71b-5390-4daa-cc8b-ca56cc95cf61",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'sparsity'...\n",
      "remote: Enumerating objects: 158, done.\u001b[K\n",
      "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
      "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
      "remote: Total 158 (delta 74), reused 138 (delta 57), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (158/158), 59.31 KiB | 5.93 MiB/s, done.\n",
      "Resolving deltas: 100% (74/74), done.\n"
     ]
    }
   ],
   "source": [
    "# pull repo\n",
    "!git clone https://github.com/char-tan/sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "FhffvuErVyVk",
   "metadata": {
    "id": "FhffvuErVyVk"
   },
   "outputs": [],
   "source": [
    "# change working directory, make dir for models\n",
    "import os\n",
    "\n",
    "os.chdir(\"sparsity\")\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4K8AFJTcYtt",
   "metadata": {
    "id": "a4K8AFJTcYtt",
    "outputId": "b9cd0c7c-12c4-4c7e-eb63-e77538ee8421",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Branch 'ct_dev' set up to track remote branch 'ct_dev' from 'origin'.\n",
      "Switched to a new branch 'ct_dev'\n"
     ]
    }
   ],
   "source": [
    "# checkout branch\n",
    "!git checkout ct_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training config"
   ],
   "metadata": {
    "id": "vEXGHaURg5qF"
   },
   "id": "vEXGHaURg5qF"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1fb111",
   "metadata": {
    "id": "fe1fb111",
    "outputId": "d27e5bd8-6b87-48f2-f9eb-f1f6dda9f14e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found permutation search CUDA kernels\n",
      "[ASP][Info] permutation_search_kernels can be imported.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from training.training import *\n",
    "from training.utils import *\n",
    "\n",
    "from apex.contrib.sparsity import ASP"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config = Config(num_epochs=20)\n",
    "\n",
    "torch.manual_seed(config.seed)\n",
    "\n",
    "model = resnet18_small_input().to(config.device)\n",
    "\n",
    "torch.save(model.state_dict(), \"models/init.pt\")\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=config.lr,\n",
    "    momentum=config.momentum,\n",
    "    weight_decay=config.weight_decay,\n",
    ")\n",
    "\n",
    "train_loader, test_loader = cifar10_dataloaders(config)"
   ],
   "metadata": {
    "id": "CEibiUghc2HX",
    "outputId": "6a7ddb8b-ef79-491f-d81d-773546238e3a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "44790ced69214a5db54c0d4a82fada9e",
      "3ef2ed8a259143438d9fbb348d25d08b",
      "328fad8e2f274598973d989d41840697",
      "c9a6673f367a4989bcc72663ca11030f",
      "201d3f71d5f046f0bc73e07763ad08a5",
      "b1fdcefb8a884c1b838e6d496539b841",
      "70e26b8f66724ac4a40e2d0c1dc10396",
      "0a0e2cb5419049c7ae5419a33492e279",
      "dbe3c9174254431a9974abab45f3cf0e",
      "2247aea0204e4a689b628d683a41e4f8",
      "e6b6140e2ea842709488ebf5df58d427"
     ]
    }
   },
   "id": "CEibiUghc2HX",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44790ced69214a5db54c0d4a82fada9e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Phase 1 training"
   ],
   "metadata": {
    "id": "2BZgWsfxgHn1"
   },
   "id": "2BZgWsfxgHn1"
  },
  {
   "cell_type": "code",
   "source": [
    "train_phase(model, optimizer, train_loader, test_loader, config)\n",
    "\n",
    "torch.save(model.state_dict(), \"models/phase1.pt\")"
   ],
   "metadata": {
    "id": "44eTeJ7YgG7r",
    "outputId": "c4f90fe6-ed54-4f32-f879-a2fd1adb9718",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "44eTeJ7YgG7r",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | time: 19.26 | train loss: 1.949 | train acc: 26.81 | test loss: 1.836 | test acc: 32.52 | \n",
      "epoch: 1 | time: 10.08 | train loss: 1.502 | train acc: 44.2 | test loss: 1.398 | test acc: 47.91 | \n",
      "epoch: 2 | time: 10.09 | train loss: 1.176 | train acc: 57.27 | test loss: 1.319 | test acc: 54.02 | \n",
      "epoch: 3 | time: 10.17 | train loss: 0.9565 | train acc: 65.59 | test loss: 1.335 | test acc: 58.1 | \n",
      "epoch: 4 | time: 10.55 | train loss: 0.8337 | train acc: 70.08 | test loss: 0.8892 | test acc: 69.19 | \n",
      "epoch: 5 | time: 10.28 | train loss: 0.7232 | train acc: 74.39 | test loss: 0.7767 | test acc: 72.95 | \n",
      "epoch: 6 | time: 10.14 | train loss: 0.6366 | train acc: 77.7 | test loss: 0.7102 | test acc: 74.39 | \n",
      "epoch: 7 | time: 10.18 | train loss: 0.5655 | train acc: 80.35 | test loss: 0.6108 | test acc: 79.52 | \n",
      "epoch: 8 | time: 10.36 | train loss: 0.5133 | train acc: 82.26 | test loss: 0.7268 | test acc: 76.55 | \n",
      "epoch: 9 | time: 10.28 | train loss: 0.4602 | train acc: 83.94 | test loss: 0.5903 | test acc: 80.08 | \n",
      "epoch: 10 | time: 10.17 | train loss: 0.4188 | train acc: 85.31 | test loss: 0.6977 | test acc: 78.71 | \n",
      "epoch: 11 | time: 10.09 | train loss: 0.3787 | train acc: 86.83 | test loss: 0.6549 | test acc: 79.22 | \n",
      "epoch: 12 | time: 10.45 | train loss: 0.3444 | train acc: 88.08 | test loss: 0.4265 | test acc: 86.01 | \n",
      "epoch: 13 | time: 10.43 | train loss: 0.3113 | train acc: 89.17 | test loss: 0.4707 | test acc: 85.06 | \n",
      "epoch: 14 | time: 10.3 | train loss: 0.2764 | train acc: 90.46 | test loss: 0.3656 | test acc: 88.14 | \n",
      "epoch: 15 | time: 10.2 | train loss: 0.2308 | train acc: 91.97 | test loss: 0.3296 | test acc: 89.25 | \n",
      "epoch: 16 | time: 10.37 | train loss: 0.1912 | train acc: 93.54 | test loss: 0.3212 | test acc: 89.94 | \n",
      "epoch: 17 | time: 10.28 | train loss: 0.1586 | train acc: 94.75 | test loss: 0.3089 | test acc: 90.16 | \n",
      "epoch: 18 | time: 10.17 | train loss: 0.1333 | train acc: 95.56 | test loss: 0.2997 | test acc: 90.51 | \n",
      "epoch: 19 | time: 10.37 | train loss: 0.1187 | train acc: 96.11 | test loss: 0.2996 | test acc: 90.72 | \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prune model, evaluate after pruning"
   ],
   "metadata": {
    "id": "AvnS7odcgMHa"
   },
   "id": "AvnS7odcgMHa"
  },
  {
   "cell_type": "code",
   "source": [
    "# prune model + applying mask s.t params stay zeroed\n",
    "ASP.prune_trained_model(model, optimizer)\n",
    "\n",
    "torch.save(model.state_dict(), \"models/phase1_pruned.pt\")"
   ],
   "metadata": {
    "id": "p_uJdAwwMYNr",
    "outputId": "de757ce4-48e1-4783-b6fe-24f8a1f29b79",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "p_uJdAwwMYNr",
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ASP] torchvision is imported, can work with the MaskRCNN/KeypointRCNN from torchvision.\n",
      "\n",
      "[set_permutation_params_from_asp] Set permutation needed parameters\n",
      "\n",
      "[set_identical_seed] Set the identical seed: 1 for all GPUs to make sure the same results generated in permutation search\n",
      "[ASP] Auto skipping pruning conv1::weight of size=torch.Size([64, 3, 3, 3]) and type=torch.float32 for sparsity\n",
      "[ASP] Auto skipping pruning fc::weight of size=torch.Size([10, 512]) and type=torch.float32 for sparsity\n",
      "\n",
      "[build_offline_permutation_graph] Further refine the model graph built by Torch.FX for offline permutation\n",
      "[build_fx_graph] The torch version is: 1.13.1+cu116, version major is: 1, version minor is: 13, version minimum is: 1+cu116\n",
      "[build_fx_graph] The Torch.FX is supported.\n",
      "\n",
      "[build_fx_graph] Print the model structure with pure PyTorch function\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "[build_fx_graph] Build the module name and type dictionary\n",
      "[build_fx_graph] module_name: , module type: <class 'torchvision.models.resnet.ResNet'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: maxpool, module type: <class 'torch.nn.modules.linear.Identity'>\n",
      "[build_fx_graph] module_name: layer1, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer1.0, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer1.0.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer1.0.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer1.0.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer1.0.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer1.0.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer1.1, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer1.1.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer1.1.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer1.1.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer1.1.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer1.1.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer2.0, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer2.0.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.0.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2.0.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer2.0.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.0.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2.0.downsample, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer2.0.downsample.0, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.0.downsample.1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2.1, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer2.1.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.1.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2.1.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer2.1.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.1.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer3.0, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer3.0.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.0.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3.0.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer3.0.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.0.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3.0.downsample, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer3.0.downsample.0, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.0.downsample.1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3.1, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer3.1.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.1.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3.1.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer3.1.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.1.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer4.0, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer4.0.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.0.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4.0.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer4.0.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.0.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4.0.downsample, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer4.0.downsample.0, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.0.downsample.1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4.1, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer4.1.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.1.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4.1.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer4.1.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.1.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: avgpool, module type: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>\n",
      "[build_fx_graph] module_name: fc, module type: <class 'torch.nn.modules.linear.Linear'>\n",
      "\n",
      "[print_raw_fx_graph] Print the intermediate representation (IR) with Torch.FX\n",
      "graph():\n",
      "    %x : torch.Tensor [#users=1] = placeholder[target=x]\n",
      "    %conv1 : [#users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    %bn1 : [#users=1] = call_module[target=bn1](args = (%conv1,), kwargs = {})\n",
      "    %relu : [#users=1] = call_module[target=relu](args = (%bn1,), kwargs = {})\n",
      "    %maxpool : [#users=2] = call_module[target=maxpool](args = (%relu,), kwargs = {})\n",
      "    %layer1_0_conv1 : [#users=1] = call_module[target=layer1.0.conv1](args = (%maxpool,), kwargs = {})\n",
      "    %layer1_0_bn1 : [#users=1] = call_module[target=layer1.0.bn1](args = (%layer1_0_conv1,), kwargs = {})\n",
      "    %layer1_0_relu : [#users=1] = call_module[target=layer1.0.relu](args = (%layer1_0_bn1,), kwargs = {})\n",
      "    %layer1_0_conv2 : [#users=1] = call_module[target=layer1.0.conv2](args = (%layer1_0_relu,), kwargs = {})\n",
      "    %layer1_0_bn2 : [#users=1] = call_module[target=layer1.0.bn2](args = (%layer1_0_conv2,), kwargs = {})\n",
      "    %add : [#users=1] = call_function[target=operator.add](args = (%layer1_0_bn2, %maxpool), kwargs = {})\n",
      "    %layer1_0_relu_1 : [#users=2] = call_module[target=layer1.0.relu](args = (%add,), kwargs = {})\n",
      "    %layer1_1_conv1 : [#users=1] = call_module[target=layer1.1.conv1](args = (%layer1_0_relu_1,), kwargs = {})\n",
      "    %layer1_1_bn1 : [#users=1] = call_module[target=layer1.1.bn1](args = (%layer1_1_conv1,), kwargs = {})\n",
      "    %layer1_1_relu : [#users=1] = call_module[target=layer1.1.relu](args = (%layer1_1_bn1,), kwargs = {})\n",
      "    %layer1_1_conv2 : [#users=1] = call_module[target=layer1.1.conv2](args = (%layer1_1_relu,), kwargs = {})\n",
      "    %layer1_1_bn2 : [#users=1] = call_module[target=layer1.1.bn2](args = (%layer1_1_conv2,), kwargs = {})\n",
      "    %add_1 : [#users=1] = call_function[target=operator.add](args = (%layer1_1_bn2, %layer1_0_relu_1), kwargs = {})\n",
      "    %layer1_1_relu_1 : [#users=2] = call_module[target=layer1.1.relu](args = (%add_1,), kwargs = {})\n",
      "    %layer2_0_conv1 : [#users=1] = call_module[target=layer2.0.conv1](args = (%layer1_1_relu_1,), kwargs = {})\n",
      "    %layer2_0_bn1 : [#users=1] = call_module[target=layer2.0.bn1](args = (%layer2_0_conv1,), kwargs = {})\n",
      "    %layer2_0_relu : [#users=1] = call_module[target=layer2.0.relu](args = (%layer2_0_bn1,), kwargs = {})\n",
      "    %layer2_0_conv2 : [#users=1] = call_module[target=layer2.0.conv2](args = (%layer2_0_relu,), kwargs = {})\n",
      "    %layer2_0_bn2 : [#users=1] = call_module[target=layer2.0.bn2](args = (%layer2_0_conv2,), kwargs = {})\n",
      "    %layer2_0_downsample_0 : [#users=1] = call_module[target=layer2.0.downsample.0](args = (%layer1_1_relu_1,), kwargs = {})\n",
      "    %layer2_0_downsample_1 : [#users=1] = call_module[target=layer2.0.downsample.1](args = (%layer2_0_downsample_0,), kwargs = {})\n",
      "    %add_2 : [#users=1] = call_function[target=operator.add](args = (%layer2_0_bn2, %layer2_0_downsample_1), kwargs = {})\n",
      "    %layer2_0_relu_1 : [#users=2] = call_module[target=layer2.0.relu](args = (%add_2,), kwargs = {})\n",
      "    %layer2_1_conv1 : [#users=1] = call_module[target=layer2.1.conv1](args = (%layer2_0_relu_1,), kwargs = {})\n",
      "    %layer2_1_bn1 : [#users=1] = call_module[target=layer2.1.bn1](args = (%layer2_1_conv1,), kwargs = {})\n",
      "    %layer2_1_relu : [#users=1] = call_module[target=layer2.1.relu](args = (%layer2_1_bn1,), kwargs = {})\n",
      "    %layer2_1_conv2 : [#users=1] = call_module[target=layer2.1.conv2](args = (%layer2_1_relu,), kwargs = {})\n",
      "    %layer2_1_bn2 : [#users=1] = call_module[target=layer2.1.bn2](args = (%layer2_1_conv2,), kwargs = {})\n",
      "    %add_3 : [#users=1] = call_function[target=operator.add](args = (%layer2_1_bn2, %layer2_0_relu_1), kwargs = {})\n",
      "    %layer2_1_relu_1 : [#users=2] = call_module[target=layer2.1.relu](args = (%add_3,), kwargs = {})\n",
      "    %layer3_0_conv1 : [#users=1] = call_module[target=layer3.0.conv1](args = (%layer2_1_relu_1,), kwargs = {})\n",
      "    %layer3_0_bn1 : [#users=1] = call_module[target=layer3.0.bn1](args = (%layer3_0_conv1,), kwargs = {})\n",
      "    %layer3_0_relu : [#users=1] = call_module[target=layer3.0.relu](args = (%layer3_0_bn1,), kwargs = {})\n",
      "    %layer3_0_conv2 : [#users=1] = call_module[target=layer3.0.conv2](args = (%layer3_0_relu,), kwargs = {})\n",
      "    %layer3_0_bn2 : [#users=1] = call_module[target=layer3.0.bn2](args = (%layer3_0_conv2,), kwargs = {})\n",
      "    %layer3_0_downsample_0 : [#users=1] = call_module[target=layer3.0.downsample.0](args = (%layer2_1_relu_1,), kwargs = {})\n",
      "    %layer3_0_downsample_1 : [#users=1] = call_module[target=layer3.0.downsample.1](args = (%layer3_0_downsample_0,), kwargs = {})\n",
      "    %add_4 : [#users=1] = call_function[target=operator.add](args = (%layer3_0_bn2, %layer3_0_downsample_1), kwargs = {})\n",
      "    %layer3_0_relu_1 : [#users=2] = call_module[target=layer3.0.relu](args = (%add_4,), kwargs = {})\n",
      "    %layer3_1_conv1 : [#users=1] = call_module[target=layer3.1.conv1](args = (%layer3_0_relu_1,), kwargs = {})\n",
      "    %layer3_1_bn1 : [#users=1] = call_module[target=layer3.1.bn1](args = (%layer3_1_conv1,), kwargs = {})\n",
      "    %layer3_1_relu : [#users=1] = call_module[target=layer3.1.relu](args = (%layer3_1_bn1,), kwargs = {})\n",
      "    %layer3_1_conv2 : [#users=1] = call_module[target=layer3.1.conv2](args = (%layer3_1_relu,), kwargs = {})\n",
      "    %layer3_1_bn2 : [#users=1] = call_module[target=layer3.1.bn2](args = (%layer3_1_conv2,), kwargs = {})\n",
      "    %add_5 : [#users=1] = call_function[target=operator.add](args = (%layer3_1_bn2, %layer3_0_relu_1), kwargs = {})\n",
      "    %layer3_1_relu_1 : [#users=2] = call_module[target=layer3.1.relu](args = (%add_5,), kwargs = {})\n",
      "    %layer4_0_conv1 : [#users=1] = call_module[target=layer4.0.conv1](args = (%layer3_1_relu_1,), kwargs = {})\n",
      "    %layer4_0_bn1 : [#users=1] = call_module[target=layer4.0.bn1](args = (%layer4_0_conv1,), kwargs = {})\n",
      "    %layer4_0_relu : [#users=1] = call_module[target=layer4.0.relu](args = (%layer4_0_bn1,), kwargs = {})\n",
      "    %layer4_0_conv2 : [#users=1] = call_module[target=layer4.0.conv2](args = (%layer4_0_relu,), kwargs = {})\n",
      "    %layer4_0_bn2 : [#users=1] = call_module[target=layer4.0.bn2](args = (%layer4_0_conv2,), kwargs = {})\n",
      "    %layer4_0_downsample_0 : [#users=1] = call_module[target=layer4.0.downsample.0](args = (%layer3_1_relu_1,), kwargs = {})\n",
      "    %layer4_0_downsample_1 : [#users=1] = call_module[target=layer4.0.downsample.1](args = (%layer4_0_downsample_0,), kwargs = {})\n",
      "    %add_6 : [#users=1] = call_function[target=operator.add](args = (%layer4_0_bn2, %layer4_0_downsample_1), kwargs = {})\n",
      "    %layer4_0_relu_1 : [#users=2] = call_module[target=layer4.0.relu](args = (%add_6,), kwargs = {})\n",
      "    %layer4_1_conv1 : [#users=1] = call_module[target=layer4.1.conv1](args = (%layer4_0_relu_1,), kwargs = {})\n",
      "    %layer4_1_bn1 : [#users=1] = call_module[target=layer4.1.bn1](args = (%layer4_1_conv1,), kwargs = {})\n",
      "    %layer4_1_relu : [#users=1] = call_module[target=layer4.1.relu](args = (%layer4_1_bn1,), kwargs = {})\n",
      "    %layer4_1_conv2 : [#users=1] = call_module[target=layer4.1.conv2](args = (%layer4_1_relu,), kwargs = {})\n",
      "    %layer4_1_bn2 : [#users=1] = call_module[target=layer4.1.bn2](args = (%layer4_1_conv2,), kwargs = {})\n",
      "    %add_7 : [#users=1] = call_function[target=operator.add](args = (%layer4_1_bn2, %layer4_0_relu_1), kwargs = {})\n",
      "    %layer4_1_relu_1 : [#users=1] = call_module[target=layer4.1.relu](args = (%add_7,), kwargs = {})\n",
      "    %avgpool : [#users=1] = call_module[target=avgpool](args = (%layer4_1_relu_1,), kwargs = {})\n",
      "    %flatten : [#users=1] = call_function[target=torch.flatten](args = (%avgpool, 1), kwargs = {})\n",
      "    %fc : [#users=1] = call_module[target=fc](args = (%flatten,), kwargs = {})\n",
      "    return fc\n",
      "\n",
      "[print_raw_fx_graph] Print the intermediate representation (IR) with Torch.FX in a table format\n",
      "opcode         name                   target                                                      args                                   kwargs\n",
      "-------------  ---------------------  ----------------------------------------------------------  -------------------------------------  --------\n",
      "placeholder    x                      x                                                           ()                                     {}\n",
      "call_module    conv1                  conv1                                                       (x,)                                   {}\n",
      "call_module    bn1                    bn1                                                         (conv1,)                               {}\n",
      "call_module    relu                   relu                                                        (bn1,)                                 {}\n",
      "call_module    maxpool                maxpool                                                     (relu,)                                {}\n",
      "call_module    layer1_0_conv1         layer1.0.conv1                                              (maxpool,)                             {}\n",
      "call_module    layer1_0_bn1           layer1.0.bn1                                                (layer1_0_conv1,)                      {}\n",
      "call_module    layer1_0_relu          layer1.0.relu                                               (layer1_0_bn1,)                        {}\n",
      "call_module    layer1_0_conv2         layer1.0.conv2                                              (layer1_0_relu,)                       {}\n",
      "call_module    layer1_0_bn2           layer1.0.bn2                                                (layer1_0_conv2,)                      {}\n",
      "call_function  add                    <built-in function add>                                     (layer1_0_bn2, maxpool)                {}\n",
      "call_module    layer1_0_relu_1        layer1.0.relu                                               (add,)                                 {}\n",
      "call_module    layer1_1_conv1         layer1.1.conv1                                              (layer1_0_relu_1,)                     {}\n",
      "call_module    layer1_1_bn1           layer1.1.bn1                                                (layer1_1_conv1,)                      {}\n",
      "call_module    layer1_1_relu          layer1.1.relu                                               (layer1_1_bn1,)                        {}\n",
      "call_module    layer1_1_conv2         layer1.1.conv2                                              (layer1_1_relu,)                       {}\n",
      "call_module    layer1_1_bn2           layer1.1.bn2                                                (layer1_1_conv2,)                      {}\n",
      "call_function  add_1                  <built-in function add>                                     (layer1_1_bn2, layer1_0_relu_1)        {}\n",
      "call_module    layer1_1_relu_1        layer1.1.relu                                               (add_1,)                               {}\n",
      "call_module    layer2_0_conv1         layer2.0.conv1                                              (layer1_1_relu_1,)                     {}\n",
      "call_module    layer2_0_bn1           layer2.0.bn1                                                (layer2_0_conv1,)                      {}\n",
      "call_module    layer2_0_relu          layer2.0.relu                                               (layer2_0_bn1,)                        {}\n",
      "call_module    layer2_0_conv2         layer2.0.conv2                                              (layer2_0_relu,)                       {}\n",
      "call_module    layer2_0_bn2           layer2.0.bn2                                                (layer2_0_conv2,)                      {}\n",
      "call_module    layer2_0_downsample_0  layer2.0.downsample.0                                       (layer1_1_relu_1,)                     {}\n",
      "call_module    layer2_0_downsample_1  layer2.0.downsample.1                                       (layer2_0_downsample_0,)               {}\n",
      "call_function  add_2                  <built-in function add>                                     (layer2_0_bn2, layer2_0_downsample_1)  {}\n",
      "call_module    layer2_0_relu_1        layer2.0.relu                                               (add_2,)                               {}\n",
      "call_module    layer2_1_conv1         layer2.1.conv1                                              (layer2_0_relu_1,)                     {}\n",
      "call_module    layer2_1_bn1           layer2.1.bn1                                                (layer2_1_conv1,)                      {}\n",
      "call_module    layer2_1_relu          layer2.1.relu                                               (layer2_1_bn1,)                        {}\n",
      "call_module    layer2_1_conv2         layer2.1.conv2                                              (layer2_1_relu,)                       {}\n",
      "call_module    layer2_1_bn2           layer2.1.bn2                                                (layer2_1_conv2,)                      {}\n",
      "call_function  add_3                  <built-in function add>                                     (layer2_1_bn2, layer2_0_relu_1)        {}\n",
      "call_module    layer2_1_relu_1        layer2.1.relu                                               (add_3,)                               {}\n",
      "call_module    layer3_0_conv1         layer3.0.conv1                                              (layer2_1_relu_1,)                     {}\n",
      "call_module    layer3_0_bn1           layer3.0.bn1                                                (layer3_0_conv1,)                      {}\n",
      "call_module    layer3_0_relu          layer3.0.relu                                               (layer3_0_bn1,)                        {}\n",
      "call_module    layer3_0_conv2         layer3.0.conv2                                              (layer3_0_relu,)                       {}\n",
      "call_module    layer3_0_bn2           layer3.0.bn2                                                (layer3_0_conv2,)                      {}\n",
      "call_module    layer3_0_downsample_0  layer3.0.downsample.0                                       (layer2_1_relu_1,)                     {}\n",
      "call_module    layer3_0_downsample_1  layer3.0.downsample.1                                       (layer3_0_downsample_0,)               {}\n",
      "call_function  add_4                  <built-in function add>                                     (layer3_0_bn2, layer3_0_downsample_1)  {}\n",
      "call_module    layer3_0_relu_1        layer3.0.relu                                               (add_4,)                               {}\n",
      "call_module    layer3_1_conv1         layer3.1.conv1                                              (layer3_0_relu_1,)                     {}\n",
      "call_module    layer3_1_bn1           layer3.1.bn1                                                (layer3_1_conv1,)                      {}\n",
      "call_module    layer3_1_relu          layer3.1.relu                                               (layer3_1_bn1,)                        {}\n",
      "call_module    layer3_1_conv2         layer3.1.conv2                                              (layer3_1_relu,)                       {}\n",
      "call_module    layer3_1_bn2           layer3.1.bn2                                                (layer3_1_conv2,)                      {}\n",
      "call_function  add_5                  <built-in function add>                                     (layer3_1_bn2, layer3_0_relu_1)        {}\n",
      "call_module    layer3_1_relu_1        layer3.1.relu                                               (add_5,)                               {}\n",
      "call_module    layer4_0_conv1         layer4.0.conv1                                              (layer3_1_relu_1,)                     {}\n",
      "call_module    layer4_0_bn1           layer4.0.bn1                                                (layer4_0_conv1,)                      {}\n",
      "call_module    layer4_0_relu          layer4.0.relu                                               (layer4_0_bn1,)                        {}\n",
      "call_module    layer4_0_conv2         layer4.0.conv2                                              (layer4_0_relu,)                       {}\n",
      "call_module    layer4_0_bn2           layer4.0.bn2                                                (layer4_0_conv2,)                      {}\n",
      "call_module    layer4_0_downsample_0  layer4.0.downsample.0                                       (layer3_1_relu_1,)                     {}\n",
      "call_module    layer4_0_downsample_1  layer4.0.downsample.1                                       (layer4_0_downsample_0,)               {}\n",
      "call_function  add_6                  <built-in function add>                                     (layer4_0_bn2, layer4_0_downsample_1)  {}\n",
      "call_module    layer4_0_relu_1        layer4.0.relu                                               (add_6,)                               {}\n",
      "call_module    layer4_1_conv1         layer4.1.conv1                                              (layer4_0_relu_1,)                     {}\n",
      "call_module    layer4_1_bn1           layer4.1.bn1                                                (layer4_1_conv1,)                      {}\n",
      "call_module    layer4_1_relu          layer4.1.relu                                               (layer4_1_bn1,)                        {}\n",
      "call_module    layer4_1_conv2         layer4.1.conv2                                              (layer4_1_relu,)                       {}\n",
      "call_module    layer4_1_bn2           layer4.1.bn2                                                (layer4_1_conv2,)                      {}\n",
      "call_function  add_7                  <built-in function add>                                     (layer4_1_bn2, layer4_0_relu_1)        {}\n",
      "call_module    layer4_1_relu_1        layer4.1.relu                                               (add_7,)                               {}\n",
      "call_module    avgpool                avgpool                                                     (layer4_1_relu_1,)                     {}\n",
      "call_function  flatten                <built-in method flatten of type object at 0x7f825723f420>  (avgpool, 1)                           {}\n",
      "call_module    fc                     fc                                                          (flatten,)                             {}\n",
      "output         output                 output                                                      (fc,)                                  {}\n",
      "\n",
      "[build_fx_graph] Print the children and parents relationship for each layer\n",
      "[build_fx_graph] This is the 'input' node: x\n",
      "[build_fx_graph] This is the 'call_module' node: conv1, its parent list: ['x'], its children list: ['bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: bn1, its parent list: ['conv1'], its children list: ['relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: relu, its parent list: ['bn1'], its children list: ['maxpool'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: maxpool, its parent list: ['relu'], its children list: ['layer1.0.conv1', 'add'], its type: torch.nn.modules.linear.Identity\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.conv1, its parent list: ['maxpool'], its children list: ['layer1.0.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.bn1, its parent list: ['layer1.0.conv1'], its children list: ['layer1.0.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.relu, its parent list: ['layer1.0.bn1'], its children list: ['layer1.0.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.conv2, its parent list: ['layer1.0.relu'], its children list: ['layer1.0.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.bn2, its parent list: ['layer1.0.conv2'], its children list: ['add'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add, its parent list: ['layer1.0.bn2', 'maxpool'], its children list: ['layer1.0.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer1.0.relu', the manually converted node name is 'layer1.0.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.relu.1, its parent list: ['add'], its children list: ['layer1.1.conv1', 'add.1'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.conv1, its parent list: ['layer1.0.relu.1'], its children list: ['layer1.1.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.bn1, its parent list: ['layer1.1.conv1'], its children list: ['layer1.1.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.relu, its parent list: ['layer1.1.bn1'], its children list: ['layer1.1.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.conv2, its parent list: ['layer1.1.relu'], its children list: ['layer1.1.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.bn2, its parent list: ['layer1.1.conv2'], its children list: ['add.1'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.1, its parent list: ['layer1.1.bn2', 'layer1.0.relu.1'], its children list: ['layer1.1.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer1.1.relu', the manually converted node name is 'layer1.1.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.relu.1, its parent list: ['add.1'], its children list: ['layer2.0.conv1', 'layer2.0.downsample.0'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.conv1, its parent list: ['layer1.1.relu.1'], its children list: ['layer2.0.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.bn1, its parent list: ['layer2.0.conv1'], its children list: ['layer2.0.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.relu, its parent list: ['layer2.0.bn1'], its children list: ['layer2.0.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.conv2, its parent list: ['layer2.0.relu'], its children list: ['layer2.0.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.bn2, its parent list: ['layer2.0.conv2'], its children list: ['add.2'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.downsample.0, its parent list: ['layer1.1.relu.1'], its children list: ['layer2.0.downsample.1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.downsample.1, its parent list: ['layer2.0.downsample.0'], its children list: ['add.2'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.2, its parent list: ['layer2.0.bn2', 'layer2.0.downsample.1'], its children list: ['layer2.0.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer2.0.relu', the manually converted node name is 'layer2.0.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.relu.1, its parent list: ['add.2'], its children list: ['layer2.1.conv1', 'add.3'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.conv1, its parent list: ['layer2.0.relu.1'], its children list: ['layer2.1.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.bn1, its parent list: ['layer2.1.conv1'], its children list: ['layer2.1.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.relu, its parent list: ['layer2.1.bn1'], its children list: ['layer2.1.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.conv2, its parent list: ['layer2.1.relu'], its children list: ['layer2.1.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.bn2, its parent list: ['layer2.1.conv2'], its children list: ['add.3'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.3, its parent list: ['layer2.1.bn2', 'layer2.0.relu.1'], its children list: ['layer2.1.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer2.1.relu', the manually converted node name is 'layer2.1.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.relu.1, its parent list: ['add.3'], its children list: ['layer3.0.conv1', 'layer3.0.downsample.0'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.conv1, its parent list: ['layer2.1.relu.1'], its children list: ['layer3.0.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.bn1, its parent list: ['layer3.0.conv1'], its children list: ['layer3.0.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.relu, its parent list: ['layer3.0.bn1'], its children list: ['layer3.0.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.conv2, its parent list: ['layer3.0.relu'], its children list: ['layer3.0.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.bn2, its parent list: ['layer3.0.conv2'], its children list: ['add.4'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.downsample.0, its parent list: ['layer2.1.relu.1'], its children list: ['layer3.0.downsample.1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.downsample.1, its parent list: ['layer3.0.downsample.0'], its children list: ['add.4'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.4, its parent list: ['layer3.0.bn2', 'layer3.0.downsample.1'], its children list: ['layer3.0.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer3.0.relu', the manually converted node name is 'layer3.0.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.relu.1, its parent list: ['add.4'], its children list: ['layer3.1.conv1', 'add.5'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.conv1, its parent list: ['layer3.0.relu.1'], its children list: ['layer3.1.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.bn1, its parent list: ['layer3.1.conv1'], its children list: ['layer3.1.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.relu, its parent list: ['layer3.1.bn1'], its children list: ['layer3.1.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.conv2, its parent list: ['layer3.1.relu'], its children list: ['layer3.1.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.bn2, its parent list: ['layer3.1.conv2'], its children list: ['add.5'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.5, its parent list: ['layer3.1.bn2', 'layer3.0.relu.1'], its children list: ['layer3.1.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer3.1.relu', the manually converted node name is 'layer3.1.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.relu.1, its parent list: ['add.5'], its children list: ['layer4.0.conv1', 'layer4.0.downsample.0'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.conv1, its parent list: ['layer3.1.relu.1'], its children list: ['layer4.0.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.bn1, its parent list: ['layer4.0.conv1'], its children list: ['layer4.0.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.relu, its parent list: ['layer4.0.bn1'], its children list: ['layer4.0.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.conv2, its parent list: ['layer4.0.relu'], its children list: ['layer4.0.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.bn2, its parent list: ['layer4.0.conv2'], its children list: ['add.6'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.downsample.0, its parent list: ['layer3.1.relu.1'], its children list: ['layer4.0.downsample.1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.downsample.1, its parent list: ['layer4.0.downsample.0'], its children list: ['add.6'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.6, its parent list: ['layer4.0.bn2', 'layer4.0.downsample.1'], its children list: ['layer4.0.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer4.0.relu', the manually converted node name is 'layer4.0.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.relu.1, its parent list: ['add.6'], its children list: ['layer4.1.conv1', 'add.7'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.conv1, its parent list: ['layer4.0.relu.1'], its children list: ['layer4.1.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.bn1, its parent list: ['layer4.1.conv1'], its children list: ['layer4.1.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.relu, its parent list: ['layer4.1.bn1'], its children list: ['layer4.1.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.conv2, its parent list: ['layer4.1.relu'], its children list: ['layer4.1.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.bn2, its parent list: ['layer4.1.conv2'], its children list: ['add.7'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.7, its parent list: ['layer4.1.bn2', 'layer4.0.relu.1'], its children list: ['layer4.1.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer4.1.relu', the manually converted node name is 'layer4.1.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.relu.1, its parent list: ['add.7'], its children list: ['avgpool'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: avgpool, its parent list: ['layer4.1.relu.1'], its children list: ['flatten'], its type: torch.nn.modules.pooling.AdaptiveAvgPool2d\n",
      "[build_fx_graph] This is the 'call_function' node: flatten, its parent list: ['avgpool'], its children list: ['fc']\n",
      "[build_fx_graph] This is the 'call_module' node: fc, its parent list: ['flatten'], its children list: ['output'], its type: torch.nn.modules.linear.Linear\n",
      "[build_fx_graph] This is the 'output' node: output\n",
      "\n",
      "[find_real_parents] Find the real parents for each node according to the whole network graph built with Torch.FX\n",
      "[find_real_parents] node_name: 'conv1', parents num: 1\n",
      "[find_real_parents] node_name: 'conv1', has no real parent because this is the first node.\n",
      "[find_real_parents] node_name: 'bn1', parents num: 1\n",
      "[find_real_parents] node_name: 'bn1', has one real parent: 'conv1', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'relu', parents num: 1\n",
      "[find_real_parents] node_name: 'relu', has one/several real parent(s): '['conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'maxpool', parents num: 1\n",
      "[find_real_parents] node_name: 'maxpool', has one/several real parent(s): '['conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.0.conv1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.0.conv1', has one/several real parent(s): '['conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.0.bn1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.0.bn1', has one real parent: 'layer1.0.conv1', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer1.0.relu', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.0.relu', has one/several real parent(s): '['layer1.0.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.0.conv2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.0.conv2', has one/several real parent(s): '['layer1.0.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.0.bn2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.0.bn2', has one real parent: 'layer1.0.conv2', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'add', parents num: 2\n",
      "[find_real_parents] node_name: 'add', has one/several real parent(s): '['layer1.0.conv2']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'add', has one/several real parent(s): '['conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.0.relu.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.0.relu.1', has one/several real parent(s): '['layer1.0.conv2', 'conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.1.conv1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.1.conv1', has one/several real parent(s): '['layer1.0.conv2', 'conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.1.bn1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.1.bn1', has one real parent: 'layer1.1.conv1', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer1.1.relu', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.1.relu', has one/several real parent(s): '['layer1.1.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.1.conv2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.1.conv2', has one/several real parent(s): '['layer1.1.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.1.bn2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.1.bn2', has one real parent: 'layer1.1.conv2', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'add.1', parents num: 2\n",
      "[find_real_parents] node_name: 'add.1', has one/several real parent(s): '['layer1.1.conv2']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'add.1', has one/several real parent(s): '['layer1.0.conv2', 'conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer1.1.relu.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer1.1.relu.1', has one/several real parent(s): '['layer1.1.conv2', 'layer1.0.conv2', 'conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.0.conv1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.0.conv1', has one/several real parent(s): '['layer1.1.conv2', 'layer1.0.conv2', 'conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.0.bn1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.0.bn1', has one real parent: 'layer2.0.conv1', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer2.0.relu', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.0.relu', has one/several real parent(s): '['layer2.0.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.0.conv2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.0.conv2', has one/several real parent(s): '['layer2.0.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.0.bn2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.0.bn2', has one real parent: 'layer2.0.conv2', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer2.0.downsample.0', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.0.downsample.0', has one/several real parent(s): '['layer1.1.conv2', 'layer1.0.conv2', 'conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.0.downsample.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.0.downsample.1', has one real parent: 'layer2.0.downsample.0', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'add.2', parents num: 2\n",
      "[find_real_parents] node_name: 'add.2', has one/several real parent(s): '['layer2.0.conv2']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'add.2', has one/several real parent(s): '['layer2.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.0.relu.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.0.relu.1', has one/several real parent(s): '['layer2.0.conv2', 'layer2.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.1.conv1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.1.conv1', has one/several real parent(s): '['layer2.0.conv2', 'layer2.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.1.bn1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.1.bn1', has one real parent: 'layer2.1.conv1', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer2.1.relu', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.1.relu', has one/several real parent(s): '['layer2.1.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.1.conv2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.1.conv2', has one/several real parent(s): '['layer2.1.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.1.bn2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.1.bn2', has one real parent: 'layer2.1.conv2', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'add.3', parents num: 2\n",
      "[find_real_parents] node_name: 'add.3', has one/several real parent(s): '['layer2.1.conv2']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'add.3', has one/several real parent(s): '['layer2.0.conv2', 'layer2.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer2.1.relu.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer2.1.relu.1', has one/several real parent(s): '['layer2.1.conv2', 'layer2.0.conv2', 'layer2.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.0.conv1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.0.conv1', has one/several real parent(s): '['layer2.1.conv2', 'layer2.0.conv2', 'layer2.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.0.bn1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.0.bn1', has one real parent: 'layer3.0.conv1', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer3.0.relu', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.0.relu', has one/several real parent(s): '['layer3.0.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.0.conv2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.0.conv2', has one/several real parent(s): '['layer3.0.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.0.bn2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.0.bn2', has one real parent: 'layer3.0.conv2', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer3.0.downsample.0', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.0.downsample.0', has one/several real parent(s): '['layer2.1.conv2', 'layer2.0.conv2', 'layer2.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.0.downsample.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.0.downsample.1', has one real parent: 'layer3.0.downsample.0', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'add.4', parents num: 2\n",
      "[find_real_parents] node_name: 'add.4', has one/several real parent(s): '['layer3.0.conv2']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'add.4', has one/several real parent(s): '['layer3.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.0.relu.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.0.relu.1', has one/several real parent(s): '['layer3.0.conv2', 'layer3.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.1.conv1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.1.conv1', has one/several real parent(s): '['layer3.0.conv2', 'layer3.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.1.bn1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.1.bn1', has one real parent: 'layer3.1.conv1', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer3.1.relu', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.1.relu', has one/several real parent(s): '['layer3.1.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.1.conv2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.1.conv2', has one/several real parent(s): '['layer3.1.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.1.bn2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.1.bn2', has one real parent: 'layer3.1.conv2', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'add.5', parents num: 2\n",
      "[find_real_parents] node_name: 'add.5', has one/several real parent(s): '['layer3.1.conv2']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'add.5', has one/several real parent(s): '['layer3.0.conv2', 'layer3.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer3.1.relu.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer3.1.relu.1', has one/several real parent(s): '['layer3.1.conv2', 'layer3.0.conv2', 'layer3.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.0.conv1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.0.conv1', has one/several real parent(s): '['layer3.1.conv2', 'layer3.0.conv2', 'layer3.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.0.bn1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.0.bn1', has one real parent: 'layer4.0.conv1', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer4.0.relu', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.0.relu', has one/several real parent(s): '['layer4.0.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.0.conv2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.0.conv2', has one/several real parent(s): '['layer4.0.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.0.bn2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.0.bn2', has one real parent: 'layer4.0.conv2', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer4.0.downsample.0', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.0.downsample.0', has one/several real parent(s): '['layer3.1.conv2', 'layer3.0.conv2', 'layer3.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.0.downsample.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.0.downsample.1', has one real parent: 'layer4.0.downsample.0', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'add.6', parents num: 2\n",
      "[find_real_parents] node_name: 'add.6', has one/several real parent(s): '['layer4.0.conv2']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'add.6', has one/several real parent(s): '['layer4.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.0.relu.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.0.relu.1', has one/several real parent(s): '['layer4.0.conv2', 'layer4.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.1.conv1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.1.conv1', has one/several real parent(s): '['layer4.0.conv2', 'layer4.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.1.bn1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.1.bn1', has one real parent: 'layer4.1.conv1', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'layer4.1.relu', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.1.relu', has one/several real parent(s): '['layer4.1.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.1.conv2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.1.conv2', has one/several real parent(s): '['layer4.1.conv1']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.1.bn2', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.1.bn2', has one real parent: 'layer4.1.conv2', its real parent module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_parents] node_name: 'add.7', parents num: 2\n",
      "[find_real_parents] node_name: 'add.7', has one/several real parent(s): '['layer4.1.conv2']', its real parent module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'add.7', has one/several real parent(s): '['layer4.0.conv2', 'layer4.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'layer4.1.relu.1', parents num: 1\n",
      "[find_real_parents] node_name: 'layer4.1.relu.1', has one/several real parent(s): '['layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'avgpool', parents num: 1\n",
      "[find_real_parents] node_name: 'avgpool', has one/several real parent(s): '['layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'flatten', parents num: 1\n",
      "[find_real_parents] node_name: 'flatten', has one/several real parent(s): '['layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[find_real_parents] node_name: 'fc', parents num: 1\n",
      "[find_real_parents] node_name: 'fc', has one/several real parent(s): '['layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0']', its real parent module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "\n",
      "[find_real_children] Find the real children for each node according to the whole network graph built with Torch.FX\n",
      "\n",
      "[find_real_children] node_name: 'fc', node module type: 'torch.nn.modules.linear.Linear', children num: 1, can directly find real children.\n",
      "\n",
      "[find_real_children] node_name: 'flatten', node module type: 'None', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'flatten', has one real child: 'fc', its real child module type: 'torch.nn.modules.linear.Linear'.\n",
      "\n",
      "[find_real_children] node_name: 'avgpool', node module type: 'torch.nn.modules.pooling.AdaptiveAvgPool2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'avgpool', its child: 'flatten' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer4.1.relu.1', its child: 'avgpool' with module type: 'torch.nn.modules.pooling.AdaptiveAvgPool2d', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'add.7', node module type: 'None', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'add.7', its child: 'layer4.1.relu.1' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer4.1.bn2', its child: 'add.7' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer4.1.conv2', has one real child: 'fc', its real child module type: 'torch.nn.modules.linear.Linear'.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.1.relu', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer4.1.relu', has one real child: 'layer4.1.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer4.1.bn1', its child: 'layer4.1.relu' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer4.1.conv1', has one real child: 'layer4.1.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', children num: 2, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer4.0.relu.1', has one real child: 'layer4.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[recursive_find_real_children] node_name: 'layer4.0.relu.1', its child: 'add.7' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'add.6', node module type: 'None', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'add.6', its child: 'layer4.0.relu.1' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer4.0.downsample.1', its child: 'add.6' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer4.0.downsample.0', has one real child: 'layer4.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer4.0.downsample.0', has one real child: 'fc', its real child module type: 'torch.nn.modules.linear.Linear'.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer4.0.bn2', its child: 'add.6' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer4.0.conv2', has one real child: 'layer4.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer4.0.conv2', has one real child: 'fc', its real child module type: 'torch.nn.modules.linear.Linear'.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.0.relu', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer4.0.relu', has one real child: 'layer4.0.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer4.0.bn1', its child: 'layer4.0.relu' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer4.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer4.0.conv1', has one real child: 'layer4.0.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', children num: 2, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer3.1.relu.1', has one real child: 'layer4.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[recursive_find_real_children] node_name: 'layer3.1.relu.1', has one real child: 'layer4.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'add.5', node module type: 'None', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'add.5', its child: 'layer3.1.relu.1' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer3.1.bn2', its child: 'add.5' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer3.1.conv2', has one real child: 'layer4.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer3.1.conv2', has one real child: 'layer4.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.1.relu', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer3.1.relu', has one real child: 'layer3.1.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer3.1.bn1', its child: 'layer3.1.relu' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer3.1.conv1', has one real child: 'layer3.1.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', children num: 2, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer3.0.relu.1', has one real child: 'layer3.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[recursive_find_real_children] node_name: 'layer3.0.relu.1', its child: 'add.5' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'add.4', node module type: 'None', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'add.4', its child: 'layer3.0.relu.1' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer3.0.downsample.1', its child: 'add.4' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer3.0.downsample.0', has one real child: 'layer3.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer3.0.downsample.0', has one real child: 'layer4.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer3.0.downsample.0', has one real child: 'layer4.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer3.0.bn2', its child: 'add.4' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer3.0.conv2', has one real child: 'layer3.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer3.0.conv2', has one real child: 'layer4.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer3.0.conv2', has one real child: 'layer4.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.0.relu', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer3.0.relu', has one real child: 'layer3.0.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer3.0.bn1', its child: 'layer3.0.relu' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer3.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer3.0.conv1', has one real child: 'layer3.0.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', children num: 2, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer2.1.relu.1', has one real child: 'layer3.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[recursive_find_real_children] node_name: 'layer2.1.relu.1', has one real child: 'layer3.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'add.3', node module type: 'None', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'add.3', its child: 'layer2.1.relu.1' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer2.1.bn2', its child: 'add.3' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer2.1.conv2', has one real child: 'layer3.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer2.1.conv2', has one real child: 'layer3.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.1.relu', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer2.1.relu', has one real child: 'layer2.1.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer2.1.bn1', its child: 'layer2.1.relu' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer2.1.conv1', has one real child: 'layer2.1.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', children num: 2, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer2.0.relu.1', has one real child: 'layer2.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[recursive_find_real_children] node_name: 'layer2.0.relu.1', its child: 'add.3' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'add.2', node module type: 'None', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'add.2', its child: 'layer2.0.relu.1' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer2.0.downsample.1', its child: 'add.2' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer2.0.downsample.0', has one real child: 'layer2.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer2.0.downsample.0', has one real child: 'layer3.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer2.0.downsample.0', has one real child: 'layer3.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer2.0.bn2', its child: 'add.2' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer2.0.conv2', has one real child: 'layer2.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer2.0.conv2', has one real child: 'layer3.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer2.0.conv2', has one real child: 'layer3.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.0.relu', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer2.0.relu', has one real child: 'layer2.0.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer2.0.bn1', its child: 'layer2.0.relu' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer2.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer2.0.conv1', has one real child: 'layer2.0.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', children num: 2, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer1.1.relu.1', has one real child: 'layer2.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[recursive_find_real_children] node_name: 'layer1.1.relu.1', has one real child: 'layer2.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'add.1', node module type: 'None', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'add.1', its child: 'layer1.1.relu.1' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer1.1.bn2', its child: 'add.1' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer1.1.conv2', has one real child: 'layer2.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer1.1.conv2', has one real child: 'layer2.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.1.relu', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer1.1.relu', has one real child: 'layer1.1.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer1.1.bn1', its child: 'layer1.1.relu' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer1.1.conv1', has one real child: 'layer1.1.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', children num: 2, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer1.0.relu.1', has one real child: 'layer1.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[recursive_find_real_children] node_name: 'layer1.0.relu.1', its child: 'add.1' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'add', node module type: 'None', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'add', its child: 'layer1.0.relu.1' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer1.0.bn2', its child: 'add' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer1.0.conv2', has one real child: 'layer1.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer1.0.conv2', has one real child: 'layer2.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'layer1.0.conv2', has one real child: 'layer2.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.0.relu', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer1.0.relu', has one real child: 'layer1.0.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'layer1.0.bn1', its child: 'layer1.0.relu' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'layer1.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'layer1.0.conv1', has one real child: 'layer1.0.conv2', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_children] node_name: 'maxpool', node module type: 'torch.nn.modules.linear.Identity', children num: 2, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'maxpool', has one real child: 'layer1.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[recursive_find_real_children] node_name: 'maxpool', its child: 'add' with module type: 'None', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'relu', node module type: 'torch.nn.modules.activation.ReLU', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'relu', its child: 'maxpool' with module type: 'torch.nn.modules.linear.Identity', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', children num: 1, recursive to find real children.\n",
      "[recursive_find_real_children] node_name: 'bn1', its child: 'relu' with module type: 'torch.nn.modules.activation.ReLU', needs recursive search.\n",
      "\n",
      "[find_real_children] node_name: 'conv1', node module type: 'torch.nn.modules.conv.Conv2d', children num: 1, can directly find real children.\n",
      "[find_real_children] node_name: 'conv1', has one real child: 'layer1.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'conv1', has one real child: 'layer1.1.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'conv1', has one real child: 'layer2.0.conv1', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_children] node_name: 'conv1', has one real child: 'layer2.0.downsample.0', its real child module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "\n",
      "[find_real_siblings] Find all siblings for each node according to the whole network graph built with Torch.FX\n",
      "[find_real_siblings] node_name: 'conv1', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'maxpool', node module type: 'torch.nn.modules.linear.Identity', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.0.conv1', has one real sibling: 'layer1.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer1.0.conv1', has one real sibling: 'layer2.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer1.0.conv1', has one real sibling: 'layer2.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer1.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.0.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'add', node module type: 'None', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.1.conv1', has one real sibling: 'layer2.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer1.1.conv1', has one real sibling: 'layer2.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer1.1.conv1', has one real sibling: 'layer1.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer1.1.conv1', has one real sibling: 'layer2.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer1.1.conv1', has one real sibling: 'layer2.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer1.1.conv1', remove 2 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.1.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'add.1', node module type: 'None', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer1.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.conv1', has one real sibling: 'layer2.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.conv1', has one real sibling: 'layer1.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.conv1', has one real sibling: 'layer2.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.conv1', has one real sibling: 'layer1.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.conv1', has one real sibling: 'layer1.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.conv1', has one real sibling: 'layer2.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.conv1', remove 3 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.downsample.0', has one real sibling: 'layer2.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.downsample.0', has one real sibling: 'layer1.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.downsample.0', has one real sibling: 'layer2.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.downsample.0', has one real sibling: 'layer1.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.downsample.0', has one real sibling: 'layer1.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.downsample.0', has one real sibling: 'layer2.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.0.downsample.0', remove 3 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'add.2', node module type: 'None', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.1.conv1', has one real sibling: 'layer3.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.1.conv1', has one real sibling: 'layer3.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.1.conv1', has one real sibling: 'layer3.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.1.conv1', has one real sibling: 'layer3.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer2.1.conv1', remove 2 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.1.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'add.3', node module type: 'None', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer2.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.conv1', has one real sibling: 'layer3.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.conv1', has one real sibling: 'layer2.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.conv1', has one real sibling: 'layer3.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.conv1', has one real sibling: 'layer2.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.conv1', has one real sibling: 'layer3.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.conv1', remove 3 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.downsample.0', has one real sibling: 'layer3.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.downsample.0', has one real sibling: 'layer2.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.downsample.0', has one real sibling: 'layer3.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.downsample.0', has one real sibling: 'layer2.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.downsample.0', has one real sibling: 'layer3.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.0.downsample.0', remove 3 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'add.4', node module type: 'None', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.1.conv1', has one real sibling: 'layer4.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.1.conv1', has one real sibling: 'layer4.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.1.conv1', has one real sibling: 'layer4.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.1.conv1', has one real sibling: 'layer4.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer3.1.conv1', remove 2 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.1.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'add.5', node module type: 'None', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer3.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.conv1', has one real sibling: 'layer4.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.conv1', has one real sibling: 'layer3.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.conv1', has one real sibling: 'layer4.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.conv1', has one real sibling: 'layer3.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.conv1', has one real sibling: 'layer4.0.downsample.0', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.conv1', remove 3 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.downsample.0', has one real sibling: 'layer4.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.downsample.0', has one real sibling: 'layer3.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.downsample.0', has one real sibling: 'layer4.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.downsample.0', has one real sibling: 'layer3.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.downsample.0', has one real sibling: 'layer4.0.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'layer4.0.downsample.0', remove 3 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'add.6', node module type: 'None', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.1.conv1', has one real sibling: 'fc', its real sibling module type: 'torch.nn.modules.linear.Linear'.\n",
      "[find_real_siblings] node_name: 'layer4.1.conv1', has one real sibling: 'fc', its real sibling module type: 'torch.nn.modules.linear.Linear'.\n",
      "[find_real_siblings] node_name: 'layer4.1.conv1', remove 1 duplicated real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.1.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', may have real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'add.7', node module type: 'None', has no real siblings.\n",
      "[find_real_siblings] node_name: 'layer4.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[find_real_siblings] node_name: 'avgpool', node module type: 'torch.nn.modules.pooling.AdaptiveAvgPool2d', has no real siblings.\n",
      "[find_real_siblings] node_name: 'flatten', node module type: 'None', has no real siblings.\n",
      "[find_real_siblings] node_name: 'fc', node module type: 'torch.nn.modules.linear.Linear', may have real siblings.\n",
      "[find_real_siblings] node_name: 'fc', has one real sibling: 'layer4.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'fc', has one real sibling: 'layer4.1.conv1', its real sibling module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[find_real_siblings] node_name: 'fc', remove 1 duplicated real siblings.\n",
      "\n",
      "[extract_all_unique_siblings] Extract all unique siblings for the whole network graph built with Torch.FX\n",
      "[extract_all_unique_siblings] node_name: 'conv1', node module type: 'torch.nn.modules.conv.Conv2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'maxpool', node module type: 'torch.nn.modules.linear.Identity', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', has 3 real siblings: '['layer1.1.conv1', 'layer2.0.conv1', 'layer2.0.downsample.0']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.0.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'add', node module type: 'None', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', has 3 real siblings: '['layer2.0.conv1', 'layer2.0.downsample.0', 'layer1.0.conv1']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.1.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'add.1', node module type: 'None', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer1.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', has 3 real siblings: '['layer2.0.downsample.0', 'layer1.1.conv1', 'layer1.0.conv1']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.0.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', has 3 real siblings: '['layer2.0.conv1', 'layer1.1.conv1', 'layer1.0.conv1']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'add.2', node module type: 'None', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', has 2 real siblings: '['layer3.0.conv1', 'layer3.0.downsample.0']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.1.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'add.3', node module type: 'None', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer2.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', has 2 real siblings: '['layer3.0.downsample.0', 'layer2.1.conv1']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.0.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', has 2 real siblings: '['layer3.0.conv1', 'layer2.1.conv1']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'add.4', node module type: 'None', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', has 2 real siblings: '['layer4.0.conv1', 'layer4.0.downsample.0']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.1.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'add.5', node module type: 'None', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer3.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', has 2 real siblings: '['layer4.0.downsample.0', 'layer3.1.conv1']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.0.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', has 2 real siblings: '['layer4.0.conv1', 'layer3.1.conv1']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'add.6', node module type: 'None', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.0.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', has 1 real siblings: '['fc']'.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.1.relu', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'add.7', node module type: 'None', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'layer4.1.relu.1', node module type: 'torch.nn.modules.activation.ReLU', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'avgpool', node module type: 'torch.nn.modules.pooling.AdaptiveAvgPool2d', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'flatten', node module type: 'None', has no real siblings.\n",
      "[extract_all_unique_siblings] node_name: 'fc', node module type: 'torch.nn.modules.linear.Linear', has 1 real siblings: '['layer4.1.conv1']'.\n",
      "\n",
      "[init_permutation_flag] Init the permutation flag for each node according to the whole network graph built with Torch.FX\n",
      "\n",
      "[init_permutation_flag] Post-processing Step No.1.\n",
      "[init_permutation_flag] node_name: 'layer1.0.conv1', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer1.0.conv1', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer1.1.conv1', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer1.1.conv1', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer2.0.conv1', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer2.0.conv1', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer2.0.downsample.0', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer2.0.downsample.0', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer2.1.conv1', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer2.1.conv1', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer3.0.conv1', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer3.0.conv1', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer3.0.downsample.0', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer3.0.downsample.0', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer3.1.conv1', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer3.1.conv1', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer4.0.conv1', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer4.0.conv1', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer4.0.downsample.0', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'layer4.0.downsample.0', its original permutation: 'KC' already includes C dim, no need to do No.1 post-processing change.\n",
      "[init_permutation_flag] node_name: 'fc', one of its real siblings need do offline permutation in C dim.\n",
      "[init_permutation_flag] node_name: 'fc', change its original permutation: 'None' to new permutation: 'C'.\n",
      "\n",
      "[init_permutation_flag] Post-processing Step No.2.\n",
      "[init_permutation_flag] node_name: 'layer4.0.conv2', one of its real children has changed permutation due to its siblings.\n",
      "[init_permutation_flag] node_name: 'layer4.0.conv2', its original permutation: 'KC' already includes K dim, no need to do No.2 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer4.0.bn2', one of its real children has changed permutation due to its siblings.\n",
      "[init_permutation_flag] node_name: 'layer4.0.bn2', its original permutation: 'K' already includes K dim, no need to do No.2 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer4.0.downsample.0', one of its real children has changed permutation due to its siblings.\n",
      "[init_permutation_flag] node_name: 'layer4.0.downsample.0', its original permutation: 'KC' already includes K dim, no need to do No.2 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer4.0.downsample.1', one of its real children has changed permutation due to its siblings.\n",
      "[init_permutation_flag] node_name: 'layer4.0.downsample.1', its original permutation: 'K' already includes K dim, no need to do No.2 post-processing change.\n",
      "[init_permutation_flag] node_name: 'layer4.1.conv2', one of its real children has changed permutation due to its siblings.\n",
      "[init_permutation_flag] node_name: 'layer4.1.conv2', change its original permutation: 'C' to new permutation: 'KC'.\n",
      "[init_permutation_flag] node_name: 'layer4.1.bn2', one of its real children has changed permutation due to its siblings.\n",
      "[init_permutation_flag] node_name: 'layer4.1.bn2', change its original permutation: 'None' to new permutation: 'K'.\n",
      "\n",
      "[search_for_good_permutation] Search for the good permutation sequence for each node according to the whole network graph built with Torch.FX\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 1 real siblings: '['conv1']', with module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'conv1', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] cannot find the node: 'conv1' in cls.__sparse_parameters, no need to merge its weight for permutation.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '0' for permutation search sequence of this unique_siblings_group.\n",
      "[search_for_good_permutation] no need to search the permutation_sequence for empty matrix_group.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 4 real siblings: '['layer1.0.conv1', 'layer1.1.conv1', 'layer2.0.conv1', 'layer2.0.downsample.0']', with module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer1.0.conv1', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer1.0.conv1' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer1.0.conv1', with its weight shape: 'torch.Size([576, 64])', the matrix_group shape: 'torch.Size([576, 64])'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer1.1.conv1', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer1.1.conv1' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer1.1.conv1', with its weight shape: 'torch.Size([576, 64])', the matrix_group shape: 'torch.Size([1152, 64])'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer2.0.conv1', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer2.0.conv1' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.0.conv1', with its weight shape: 'torch.Size([1152, 64])', the matrix_group shape: 'torch.Size([2304, 64])'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer2.0.downsample.0', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer2.0.downsample.0' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.0.downsample.0', with its weight shape: 'torch.Size([128, 64])', the matrix_group shape: 'torch.Size([2432, 64])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '64' for permutation search sequence of this unique_siblings_group.\n",
      "Found 1 gpus\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 3917.7577711712106, Pruned element abs sum: 2937.902587890625, Diff ratio: 0.2501061169454738\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(2432, 64)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.8958 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.8987 seconds to finish accelerated_search_for_good_permutation function with final magnitude 2956.81640625.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 1 real siblings: '['layer1.0.conv2']', with module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer1.0.conv2', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer1.0.conv2' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer1.0.conv2', with its weight shape: 'torch.Size([576, 64])', the matrix_group shape: 'torch.Size([576, 64])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '64' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 980.9030504708859, Pruned element abs sum: 731.2800903320312, Diff ratio: 0.2544828054301822\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(576, 64)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.2505 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.2523 seconds to finish accelerated_search_for_good_permutation function with final magnitude 741.521240234375.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 1 real siblings: '['layer1.1.conv2']', with module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer1.1.conv2', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer1.1.conv2' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer1.1.conv2', with its weight shape: 'torch.Size([576, 64])', the matrix_group shape: 'torch.Size([576, 64])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '64' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 971.1058291505165, Pruned element abs sum: 723.4371948242188, Diff ratio: 0.25503773831009546\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(576, 64)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.2408 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.2419 seconds to finish accelerated_search_for_good_permutation function with final magnitude 733.2819213867188.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 1 real siblings: '['layer2.0.conv2']', with module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer2.0.conv2', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer2.0.conv2' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.0.conv2', with its weight shape: 'torch.Size([1152, 128])', the matrix_group shape: 'torch.Size([1152, 128])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '128' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 2548.602898637606, Pruned element abs sum: 1897.58984375, Diff ratio: 0.25543918797063864\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(1152, 128)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.6042 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.6060 seconds to finish accelerated_search_for_good_permutation function with final magnitude 1914.2440185546875.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 3 real siblings: '['layer2.1.conv1', 'layer3.0.conv1', 'layer3.0.downsample.0']', with module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer2.1.conv1', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer2.1.conv1' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.1.conv1', with its weight shape: 'torch.Size([1152, 128])', the matrix_group shape: 'torch.Size([1152, 128])'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer3.0.conv1', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer3.0.conv1' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.0.conv1', with its weight shape: 'torch.Size([2304, 128])', the matrix_group shape: 'torch.Size([3456, 128])'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer3.0.downsample.0', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer3.0.downsample.0' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.0.downsample.0', with its weight shape: 'torch.Size([256, 128])', the matrix_group shape: 'torch.Size([3712, 128])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '128' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 8163.671067474821, Pruned element abs sum: 6091.54052734375, Diff ratio: 0.25382337468087385\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(3712, 128)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 1.5135 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 1.5159 seconds to finish accelerated_search_for_good_permutation function with final magnitude 6127.2685546875.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 1 real siblings: '['layer2.1.conv2']', with module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer2.1.conv2', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer2.1.conv2' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.1.conv2', with its weight shape: 'torch.Size([1152, 128])', the matrix_group shape: 'torch.Size([1152, 128])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '128' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 2754.1499362550985, Pruned element abs sum: 2048.423583984375, Diff ratio: 0.2562410793184053\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(1152, 128)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.5703 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.5723 seconds to finish accelerated_search_for_good_permutation function with final magnitude 2067.40576171875.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 1 real siblings: '['layer3.0.conv2']', with module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer3.0.conv2', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer3.0.conv2' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.0.conv2', with its weight shape: 'torch.Size([2304, 256])', the matrix_group shape: 'torch.Size([2304, 256])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '256' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 6901.489644390041, Pruned element abs sum: 5138.5947265625, Diff ratio: 0.25543687068494425\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(2304, 256)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 1.5369 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 1.5403 seconds to finish accelerated_search_for_good_permutation function with final magnitude 5173.2509765625.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 3 real siblings: '['layer3.1.conv1', 'layer4.0.conv1', 'layer4.0.downsample.0']', with module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d', 'torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer3.1.conv1', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer3.1.conv1' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.1.conv1', with its weight shape: 'torch.Size([2304, 256])', the matrix_group shape: 'torch.Size([2304, 256])'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer4.0.conv1', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer4.0.conv1' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.0.conv1', with its weight shape: 'torch.Size([4608, 256])', the matrix_group shape: 'torch.Size([6912, 256])'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer4.0.downsample.0', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer4.0.downsample.0' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.0.downsample.0', with its weight shape: 'torch.Size([512, 256])', the matrix_group shape: 'torch.Size([7424, 256])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '256' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 19719.05961276514, Pruned element abs sum: 14706.673828125, Diff ratio: 0.2541898996742913\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(7424, 256)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 4.0370 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 4.0430 seconds to finish accelerated_search_for_good_permutation function with final magnitude 14768.298828125.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 1 real siblings: '['layer3.1.conv2']', with module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer3.1.conv2', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer3.1.conv2' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.1.conv2', with its weight shape: 'torch.Size([2304, 256])', the matrix_group shape: 'torch.Size([2304, 256])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '256' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 6879.493712753325, Pruned element abs sum: 5122.1201171875, Diff ratio: 0.2554510068535967\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(2304, 256)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 1.5873 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 1.5904 seconds to finish accelerated_search_for_good_permutation function with final magnitude 5158.3408203125.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 1 real siblings: '['layer4.0.conv2']', with module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer4.0.conv2', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer4.0.conv2' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.0.conv2', with its weight shape: 'torch.Size([4608, 512])', the matrix_group shape: 'torch.Size([4608, 512])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '512' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 17211.541097083904, Pruned element abs sum: 12811.6787109375, Diff ratio: 0.25563442351433935\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(4608, 512)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 5.9631 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 5.9711 seconds to finish accelerated_search_for_good_permutation function with final magnitude 12879.7421875.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 2 real siblings: '['layer4.1.conv1', 'fc']', with module type: '['torch.nn.modules.conv.Conv2d', 'torch.nn.modules.linear.Linear']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer4.1.conv1', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer4.1.conv1' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.1.conv1', with its weight shape: 'torch.Size([4608, 512])', the matrix_group shape: 'torch.Size([4608, 512])'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'fc', with module type: 'torch.nn.modules.linear.Linear'.\n",
      "[search_for_good_permutation] cannot find the node: 'fc' in cls.__sparse_parameters, no need to merge its weight for permutation.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '512' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 17295.68661322803, Pruned element abs sum: 12877.4189453125, Diff ratio: 0.25545488691593\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(4608, 512)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 5.8821 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 5.8910 seconds to finish accelerated_search_for_good_permutation function with final magnitude 12944.8427734375.\n",
      "\n",
      "[search_for_good_permutation] this unique_siblings_group has 1 real siblings: '['layer4.1.conv2']', with module type: '['torch.nn.modules.conv.Conv2d']'.\n",
      "[search_for_good_permutation] try to merge the weight for node: 'layer4.1.conv2', with module type: 'torch.nn.modules.conv.Conv2d'.\n",
      "[search_for_good_permutation] find the node: 'layer4.1.conv2' in cls.__sparse_parameters, module type match: 'True'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.1.conv2', with its weight shape: 'torch.Size([4608, 512])', the matrix_group shape: 'torch.Size([4608, 512])'.\n",
      "\n",
      "[search_for_good_permutation] init the all-zero list with length '512' for permutation search sequence of this unique_siblings_group.\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 17194.921620502155, Pruned element abs sum: 12801.6826171875, Diff ratio: 0.2554963087517904\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(4608, 512)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 6.0266 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 6.0350 seconds to finish accelerated_search_for_good_permutation function with final magnitude 12864.5556640625.\n",
      "\n",
      "[build_offline_permutation_graph] Take 29.5724 seconds to finish search_for_good_permutation function.\n",
      "\n",
      "[compute_sparse_masks] build offline permutation graph on none-distributed model.\n",
      "[compute_sparse_masks] Take 29.7504 seconds to finish build_offline_permutation_graph function.\n",
      "\n",
      "[apply_offline_permutation] Offline permutation for each node according to the the whole network graph built with Torch.FX\n",
      "\n",
      "[apply_offline_permutation] node_name: 'conv1', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'conv1' with shape: 'torch.Size([64, 3, 3, 3])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer1.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer1.0.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer1.0.conv1' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.conv1' with shape: 'torch.Size([64, 64, 3, 3])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer1.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer1.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer1.0.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer1.0.conv2' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.conv2' with shape: 'torch.Size([64, 64, 3, 3])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer1.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer1.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer1.1.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer1.1.conv1' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.conv1' with shape: 'torch.Size([64, 64, 3, 3])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer1.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer1.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer1.1.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer1.1.conv2' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.conv2' with shape: 'torch.Size([64, 64, 3, 3])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer1.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.0.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.0.conv1' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.conv1' with shape: 'torch.Size([128, 64, 3, 3])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.0.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.0.conv2' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.conv2' with shape: 'torch.Size([128, 128, 3, 3])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.0.downsample.0' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.0.downsample.0' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.downsample.0' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.0' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.0' with shape: 'torch.Size([128, 64, 1, 1])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.downsample.1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.1.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.1.conv1' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.conv1' with shape: 'torch.Size([128, 128, 3, 3])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.1.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.1.conv2' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.conv2' with shape: 'torch.Size([128, 128, 3, 3])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer2.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.0.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.0.conv1' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.conv1' with shape: 'torch.Size([256, 128, 3, 3])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.0.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.0.conv2' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.conv2' with shape: 'torch.Size([256, 256, 3, 3])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.0.downsample.0' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.0.downsample.0' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.downsample.0' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.0' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.0' with shape: 'torch.Size([256, 128, 1, 1])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.downsample.1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.1.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.1.conv1' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.conv1' with shape: 'torch.Size([256, 256, 3, 3])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.1.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.1.conv2' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.conv2' with shape: 'torch.Size([256, 256, 3, 3])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer3.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.0.conv1', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.0.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.0.conv1' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.conv1' with shape: 'torch.Size([512, 256, 3, 3])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.0.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.0.conv2', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.0.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.0.conv2' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.conv2' with shape: 'torch.Size([512, 512, 3, 3])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.0.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.0.downsample.0', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.0.downsample.0' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.0.downsample.0' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.downsample.0' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.0' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.0' with shape: 'torch.Size([512, 256, 1, 1])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.0.downsample.1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.downsample.1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.1.conv1', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.1.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.1.conv1' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.conv1' with shape: 'torch.Size([512, 512, 3, 3])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.1.bn1', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.1.conv2', node module type: 'torch.nn.modules.conv.Conv2d', need to do offline permutation in K and C dims.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.1.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.1.conv2' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.conv2' with shape: 'torch.Size([512, 512, 3, 3])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'layer4.1.bn2', node module type: 'torch.nn.modules.batchnorm.BatchNorm2d', need to do offline permutation in K dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "\n",
      "[apply_offline_permutation] node_name: 'fc', node module type: 'torch.nn.modules.linear.Linear', need to do offline permutation in C dim.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'fc' in C dim\n",
      "[apply_permutation_in_C_dim] cannot find the node: 'fc' in cls.__sparse_parameters, but can find in cls.__all_parameters.\n",
      "[apply_permutation_in_C_dim] cannot find the node: 'fc' in cls.__sparse_parameters, after trying with cls.__all_parameters, succeed to apply permutation in C dim.\n",
      "\n",
      "[compute_sparse_masks] apply offline permutation on none-distributed model.\n",
      "[compute_sparse_masks] Take 0.1419 seconds to finish apply_offline_permutation function.\n",
      "\n",
      "[ASP] Enabled 50.00% sparsity for layer1.0.conv1::weight of size=torch.Size([64, 64, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer1.0.conv2::weight of size=torch.Size([64, 64, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer1.1.conv1::weight of size=torch.Size([64, 64, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer1.1.conv2::weight of size=torch.Size([64, 64, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer2.0.conv1::weight of size=torch.Size([128, 64, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer2.0.conv2::weight of size=torch.Size([128, 128, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer2.0.downsample.0::weight of size=torch.Size([128, 64, 1, 1]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer2.1.conv1::weight of size=torch.Size([128, 128, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer2.1.conv2::weight of size=torch.Size([128, 128, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer3.0.conv1::weight of size=torch.Size([256, 128, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer3.0.conv2::weight of size=torch.Size([256, 256, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer3.0.downsample.0::weight of size=torch.Size([256, 128, 1, 1]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer3.1.conv1::weight of size=torch.Size([256, 256, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer3.1.conv2::weight of size=torch.Size([256, 256, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer4.0.conv1::weight of size=torch.Size([512, 256, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer4.0.conv2::weight of size=torch.Size([512, 512, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer4.0.downsample.0::weight of size=torch.Size([512, 256, 1, 1]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer4.1.conv1::weight of size=torch.Size([512, 512, 3, 3]) and type=torch.float32\n",
      "[ASP] Enabled 50.00% sparsity for layer4.1.conv2::weight of size=torch.Size([512, 512, 3, 3]) and type=torch.float32\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# evaluate on train + test data\n",
    "train_loss, train_acc = test_epoch(model, train_loader, config.device)\n",
    "test_loss, test_acc = test_epoch(model, test_loader, config.device)\n",
    "\n",
    "epoch_summary(\n",
    "    {\n",
    "        \"train loss\": train_loss,\n",
    "        \"train acc\": train_acc,\n",
    "        \"test loss\": test_loss,\n",
    "        \"test acc\": test_acc,\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "id": "VwLzoTgIitpg",
    "outputId": "17d88e8e-b018-4a2c-bcc5-8061ff4a22ee",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "VwLzoTgIitpg",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train loss: 0.5173 | train acc: 81.64 | test loss: 0.6731 | test acc: 78.19 | \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Phase 2 training"
   ],
   "metadata": {
    "id": "ys-25Hkjgcos"
   },
   "id": "ys-25Hkjgcos"
  },
  {
   "cell_type": "code",
   "source": [
    "train_phase(model, optimizer, train_loader, test_loader, config)\n",
    "\n",
    "torch.save(model.state_dict(), \"models/phase2.pt\")"
   ],
   "metadata": {
    "id": "VH9NrXiIMb6p",
    "outputId": "16152cda-22d3-4efd-8a1f-b234114fc89f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "VH9NrXiIMb6p",
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | time: 10.3 | train loss: 0.2686 | train acc: 90.54 | test loss: 0.6183 | test acc: 80.48 | \n",
      "epoch: 1 | time: 10.37 | train loss: 0.3285 | train acc: 88.59 | test loss: 0.4762 | test acc: 84.07 | \n",
      "epoch: 2 | time: 10.37 | train loss: 0.3081 | train acc: 89.18 | test loss: 0.5399 | test acc: 83.15 | \n",
      "epoch: 3 | time: 10.59 | train loss: 0.2935 | train acc: 89.86 | test loss: 0.5265 | test acc: 83.6 | \n",
      "epoch: 4 | time: 10.34 | train loss: 0.2807 | train acc: 90.17 | test loss: 0.5158 | test acc: 83.87 | \n",
      "epoch: 5 | time: 10.44 | train loss: 0.2684 | train acc: 90.64 | test loss: 0.4854 | test acc: 84.56 | \n",
      "epoch: 6 | time: 10.27 | train loss: 0.2559 | train acc: 91.16 | test loss: 0.4198 | test acc: 86.19 | \n",
      "epoch: 7 | time: 10.13 | train loss: 0.2502 | train acc: 91.3 | test loss: 0.4047 | test acc: 87.23 | \n",
      "epoch: 8 | time: 10.18 | train loss: 0.2317 | train acc: 91.93 | test loss: 0.4608 | test acc: 85.73 | \n",
      "epoch: 9 | time: 10.47 | train loss: 0.2242 | train acc: 92.14 | test loss: 0.4494 | test acc: 85.96 | \n",
      "epoch: 10 | time: 10.53 | train loss: 0.2065 | train acc: 92.84 | test loss: 0.4719 | test acc: 85.31 | \n",
      "epoch: 11 | time: 10.39 | train loss: 0.1866 | train acc: 93.52 | test loss: 0.3768 | test acc: 88.23 | \n",
      "epoch: 12 | time: 10.75 | train loss: 0.1684 | train acc: 94.19 | test loss: 0.3692 | test acc: 88.54 | \n",
      "epoch: 13 | time: 10.2 | train loss: 0.1472 | train acc: 94.93 | test loss: 0.3693 | test acc: 88.4 | \n",
      "epoch: 14 | time: 10.17 | train loss: 0.1204 | train acc: 95.88 | test loss: 0.317 | test acc: 90.54 | \n",
      "epoch: 15 | time: 10.18 | train loss: 0.08982 | train acc: 96.92 | test loss: 0.2866 | test acc: 91.22 | \n",
      "epoch: 16 | time: 10.26 | train loss: 0.06516 | train acc: 97.92 | test loss: 0.2975 | test acc: 91.26 | \n",
      "epoch: 17 | time: 10.28 | train loss: 0.04861 | train acc: 98.46 | test loss: 0.2709 | test acc: 92.14 | \n",
      "epoch: 18 | time: 10.55 | train loss: 0.03609 | train acc: 98.96 | test loss: 0.267 | test acc: 92.4 | \n",
      "epoch: 19 | time: 10.31 | train loss: 0.03232 | train acc: 99.12 | test loss: 0.2654 | test acc: 92.33 | \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train from original init with mask (LTH)"
   ],
   "metadata": {
    "id": "rroi_bAzgfXY"
   },
   "id": "rroi_bAzgfXY"
  },
  {
   "cell_type": "code",
   "source": [
    "# apply mask to init params then load into model\n",
    "model.load_state_dict(\n",
    "    mask_checkpoint(torch.load(\"models/init.pt\"), model), strict=False\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), \"models/init_pruned.pt\")\n",
    "\n",
    "train_phase(model, optimizer, train_loader, test_loader, config)\n",
    "\n",
    "torch.save(model.state_dict(), \"models/lottery_ticket.pt\")"
   ],
   "metadata": {
    "id": "WuXJurWnX62K",
    "outputId": "1bb56c5e-34ae-47ab-ad70-439cacc278f6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "WuXJurWnX62K",
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | time: 10.25 | train loss: 1.938 | train acc: 27.15 | test loss: 1.865 | test acc: 33.6 | \n",
      "epoch: 1 | time: 10.18 | train loss: 1.497 | train acc: 44.13 | test loss: 1.411 | test acc: 49.3 | \n",
      "epoch: 2 | time: 10.34 | train loss: 1.192 | train acc: 56.6 | test loss: 1.15 | test acc: 59.26 | \n",
      "epoch: 3 | time: 10.3 | train loss: 0.9747 | train acc: 64.91 | test loss: 0.965 | test acc: 66.34 | \n",
      "epoch: 4 | time: 10.41 | train loss: 0.8397 | train acc: 70.29 | test loss: 0.8474 | test acc: 70.34 | \n",
      "epoch: 5 | time: 10.16 | train loss: 0.7176 | train acc: 74.74 | test loss: 0.8993 | test acc: 69.88 | \n",
      "epoch: 6 | time: 10.26 | train loss: 0.6375 | train acc: 77.76 | test loss: 0.8328 | test acc: 73.17 | \n",
      "epoch: 7 | time: 10.44 | train loss: 0.5684 | train acc: 80.35 | test loss: 0.7879 | test acc: 73.92 | \n",
      "epoch: 8 | time: 10.29 | train loss: 0.5142 | train acc: 82.09 | test loss: 0.5979 | test acc: 79.67 | \n",
      "epoch: 9 | time: 10.38 | train loss: 0.4717 | train acc: 83.78 | test loss: 0.5156 | test acc: 82.27 | \n",
      "epoch: 10 | time: 10.15 | train loss: 0.4335 | train acc: 85.13 | test loss: 0.5606 | test acc: 81.74 | \n",
      "epoch: 11 | time: 10.28 | train loss: 0.3919 | train acc: 86.6 | test loss: 0.6786 | test acc: 78.71 | \n",
      "epoch: 12 | time: 10.5 | train loss: 0.3604 | train acc: 87.55 | test loss: 0.491 | test acc: 83.3 | \n",
      "epoch: 13 | time: 10.21 | train loss: 0.3244 | train acc: 88.77 | test loss: 0.4409 | test acc: 85.56 | \n",
      "epoch: 14 | time: 10.08 | train loss: 0.2796 | train acc: 90.33 | test loss: 0.4736 | test acc: 84.98 | \n",
      "epoch: 15 | time: 10.25 | train loss: 0.2441 | train acc: 91.63 | test loss: 0.3742 | test acc: 88.16 | \n",
      "epoch: 16 | time: 10.15 | train loss: 0.21 | train acc: 92.68 | test loss: 0.3295 | test acc: 89.31 | \n",
      "epoch: 17 | time: 10.19 | train loss: 0.1731 | train acc: 94.16 | test loss: 0.3076 | test acc: 90.04 | \n",
      "epoch: 18 | time: 10.28 | train loss: 0.149 | train acc: 95.01 | test loss: 0.3007 | test acc: 90.52 | \n",
      "epoch: 19 | time: 10.19 | train loss: 0.1355 | train acc: 95.54 | test loss: 0.298 | test acc: 90.63 | \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train from random init with mask"
   ],
   "metadata": {
    "id": "CUcOsL1hglXs"
   },
   "id": "CUcOsL1hglXs"
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(config.seed + 1)\n",
    "\n",
    "# produce new initalisation\n",
    "new_init_params = resnet18_small_input().cuda().state_dict()\n",
    "\n",
    "torch.save(new_init_params, \"models/new_init.pt\")\n",
    "\n",
    "# apply mask to params then load into model\n",
    "model.load_state_dict(mask_checkpoint(new_init_params, model), strict=False)\n",
    "\n",
    "torch.save(model.state_dict(), \"models/new_init_pruned.pt\")\n",
    "\n",
    "train_phase(model, optimizer, train_loader, test_loader, config)\n",
    "\n",
    "torch.save(model.state_dict(), \"models/random_lottery_ticket.pt\")"
   ],
   "metadata": {
    "id": "EdiettL2gyjU",
    "outputId": "3b9b6a2c-01e2-4a2c-c209-59831666145a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "EdiettL2gyjU",
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | time: 10.45 | train loss: 1.941 | train acc: 26.95 | test loss: 1.808 | test acc: 35 | \n",
      "epoch: 1 | time: 10.49 | train loss: 1.484 | train acc: 44.94 | test loss: 1.528 | test acc: 48.21 | \n",
      "epoch: 2 | time: 10.36 | train loss: 1.15 | train acc: 58.39 | test loss: 1.243 | test acc: 56.54 | \n",
      "epoch: 3 | time: 10.43 | train loss: 0.9589 | train acc: 65.73 | test loss: 1.002 | test acc: 65.65 | \n",
      "epoch: 4 | time: 10.36 | train loss: 0.8356 | train acc: 70.68 | test loss: 0.9978 | test acc: 65.29 | \n",
      "epoch: 5 | time: 10.31 | train loss: 0.7177 | train acc: 74.69 | test loss: 0.8093 | test acc: 73.48 | \n",
      "epoch: 6 | time: 10.3 | train loss: 0.6273 | train acc: 78.32 | test loss: 0.7156 | test acc: 76.09 | \n",
      "epoch: 7 | time: 10.34 | train loss: 0.5643 | train acc: 80.48 | test loss: 0.845 | test acc: 73.15 | \n",
      "epoch: 8 | time: 10.22 | train loss: 0.5104 | train acc: 82.42 | test loss: 0.6858 | test acc: 77.65 | \n",
      "epoch: 9 | time: 10.23 | train loss: 0.4635 | train acc: 84.13 | test loss: 0.7078 | test acc: 78.52 | \n",
      "epoch: 10 | time: 10.49 | train loss: 0.4253 | train acc: 85.32 | test loss: 0.5059 | test acc: 83.28 | \n",
      "epoch: 11 | time: 10.23 | train loss: 0.3869 | train acc: 86.66 | test loss: 0.5714 | test acc: 81.16 | \n",
      "epoch: 12 | time: 10.45 | train loss: 0.3487 | train acc: 87.98 | test loss: 0.4642 | test acc: 84.49 | \n",
      "epoch: 13 | time: 10.17 | train loss: 0.3141 | train acc: 89.27 | test loss: 0.57 | test acc: 81.49 | \n",
      "epoch: 14 | time: 10.38 | train loss: 0.2728 | train acc: 90.67 | test loss: 0.3881 | test acc: 87.41 | \n",
      "epoch: 15 | time: 10.21 | train loss: 0.2375 | train acc: 91.87 | test loss: 0.3921 | test acc: 87.65 | \n",
      "epoch: 16 | time: 10.17 | train loss: 0.1985 | train acc: 93.25 | test loss: 0.3224 | test acc: 89.67 | \n",
      "epoch: 17 | time: 10.4 | train loss: 0.1656 | train acc: 94.5 | test loss: 0.2995 | test acc: 90.4 | \n",
      "epoch: 18 | time: 10.45 | train loss: 0.1398 | train acc: 95.36 | test loss: 0.2905 | test acc: 90.86 | \n",
      "epoch: 19 | time: 10.21 | train loss: 0.1294 | train acc: 95.67 | test loss: 0.2884 | test acc: 90.75 | \n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "533dc1b5f6751e9c738350df3cd1b0ef5f569dd461507537431de13a6c09381e"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "44790ced69214a5db54c0d4a82fada9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ef2ed8a259143438d9fbb348d25d08b",
       "IPY_MODEL_328fad8e2f274598973d989d41840697",
       "IPY_MODEL_c9a6673f367a4989bcc72663ca11030f"
      ],
      "layout": "IPY_MODEL_201d3f71d5f046f0bc73e07763ad08a5"
     }
    },
    "3ef2ed8a259143438d9fbb348d25d08b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1fdcefb8a884c1b838e6d496539b841",
      "placeholder": "​",
      "style": "IPY_MODEL_70e26b8f66724ac4a40e2d0c1dc10396",
      "value": "100%"
     }
    },
    "328fad8e2f274598973d989d41840697": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a0e2cb5419049c7ae5419a33492e279",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dbe3c9174254431a9974abab45f3cf0e",
      "value": 170498071
     }
    },
    "c9a6673f367a4989bcc72663ca11030f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2247aea0204e4a689b628d683a41e4f8",
      "placeholder": "​",
      "style": "IPY_MODEL_e6b6140e2ea842709488ebf5df58d427",
      "value": " 170498071/170498071 [00:02&lt;00:00, 88197792.46it/s]"
     }
    },
    "201d3f71d5f046f0bc73e07763ad08a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1fdcefb8a884c1b838e6d496539b841": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70e26b8f66724ac4a40e2d0c1dc10396": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a0e2cb5419049c7ae5419a33492e279": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbe3c9174254431a9974abab45f3cf0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2247aea0204e4a689b628d683a41e4f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6b6140e2ea842709488ebf5df58d427": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}