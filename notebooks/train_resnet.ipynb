{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0ox72K94Tk_f",
      "metadata": {
        "id": "0ox72K94Tk_f"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "EoU7-e4NcM4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoU7-e4NcM4c",
        "outputId": "aedbb75d-312b-4ca2-ae4e-cfa909ac416b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 10 23:34:52 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    29W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ObaBHw6wWCD0",
      "metadata": {
        "id": "ObaBHw6wWCD0"
      },
      "outputs": [],
      "source": [
        "# reload modules in .py files\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "999c2bc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "999c2bc6",
        "outputId": "d799f7b3-3b84-4576-a6d8-85099d9c4687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sparsity' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# pull repo\n",
        "!git clone https://github.com/char-tan/sparsity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "FhffvuErVyVk",
      "metadata": {
        "id": "FhffvuErVyVk"
      },
      "outputs": [],
      "source": [
        "# change working directory\n",
        "import os\n",
        "os.chdir('sparsity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a4K8AFJTcYtt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4K8AFJTcYtt",
        "outputId": "744b9f8a-411c-4b23-b1f5-f33ecf671420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M\ttraining/train_model.py\n",
            "Already on 'ct_dev'\n",
            "Your branch is up to date with 'origin/ct_dev'.\n"
          ]
        }
      ],
      "source": [
        "# checkout branch\n",
        "!git checkout ct_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fe1fb111",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fe1fb111",
        "outputId": "5af50b2f-87cd-4d4d-c20f-4d73d6956730"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "391\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "Adjusting learning rate of group 0 to 1.0072e-06.\n",
            "iteration 0 | loss 7.321969985961914\n",
            "Adjusting learning rate of group 0 to 1.0287e-06.\n",
            "iteration 1 | loss 7.430234909057617\n",
            "Adjusting learning rate of group 0 to 1.0646e-06.\n",
            "iteration 2 | loss 7.446775436401367\n",
            "Adjusting learning rate of group 0 to 1.1148e-06.\n",
            "iteration 3 | loss 7.246356010437012\n",
            "Adjusting learning rate of group 0 to 1.1794e-06.\n",
            "iteration 4 | loss 7.33271598815918\n",
            "Adjusting learning rate of group 0 to 1.2583e-06.\n",
            "iteration 5 | loss 7.416540145874023\n",
            "Adjusting learning rate of group 0 to 1.3516e-06.\n",
            "iteration 6 | loss 7.404571533203125\n",
            "Adjusting learning rate of group 0 to 1.4592e-06.\n",
            "iteration 7 | loss 7.2996506690979\n",
            "Adjusting learning rate of group 0 to 1.5812e-06.\n",
            "iteration 8 | loss 7.365245342254639\n",
            "Adjusting learning rate of group 0 to 1.7175e-06.\n",
            "iteration 9 | loss 7.328067302703857\n",
            "Adjusting learning rate of group 0 to 1.8682e-06.\n",
            "iteration 10 | loss 7.271821022033691\n",
            "Adjusting learning rate of group 0 to 2.0333e-06.\n",
            "iteration 11 | loss 7.3513031005859375\n",
            "Adjusting learning rate of group 0 to 2.2126e-06.\n",
            "iteration 12 | loss 7.287802219390869\n",
            "Adjusting learning rate of group 0 to 2.4064e-06.\n",
            "iteration 13 | loss 7.319914817810059\n",
            "Adjusting learning rate of group 0 to 2.6145e-06.\n",
            "iteration 14 | loss 7.289396286010742\n",
            "Adjusting learning rate of group 0 to 2.8369e-06.\n",
            "iteration 15 | loss 7.2873029708862305\n",
            "Adjusting learning rate of group 0 to 3.0737e-06.\n",
            "iteration 16 | loss 7.234389781951904\n",
            "Adjusting learning rate of group 0 to 3.3248e-06.\n",
            "iteration 17 | loss 7.280449867248535\n",
            "Adjusting learning rate of group 0 to 3.5903e-06.\n",
            "iteration 18 | loss 7.287572383880615\n",
            "Adjusting learning rate of group 0 to 3.8701e-06.\n",
            "iteration 19 | loss 7.192943572998047\n",
            "Adjusting learning rate of group 0 to 4.1643e-06.\n",
            "iteration 20 | loss 7.301328182220459\n",
            "Adjusting learning rate of group 0 to 4.4729e-06.\n",
            "iteration 21 | loss 7.285704612731934\n",
            "Adjusting learning rate of group 0 to 4.7958e-06.\n",
            "iteration 22 | loss 7.025597095489502\n",
            "Adjusting learning rate of group 0 to 5.1330e-06.\n",
            "iteration 23 | loss 7.125874996185303\n",
            "Adjusting learning rate of group 0 to 5.4846e-06.\n",
            "iteration 24 | loss 7.203210353851318\n",
            "Adjusting learning rate of group 0 to 5.8505e-06.\n",
            "iteration 25 | loss 7.0139288902282715\n",
            "Adjusting learning rate of group 0 to 6.2308e-06.\n",
            "iteration 26 | loss 7.030095100402832\n",
            "Adjusting learning rate of group 0 to 6.6254e-06.\n",
            "iteration 27 | loss 6.960354804992676\n",
            "Adjusting learning rate of group 0 to 7.0344e-06.\n",
            "iteration 28 | loss 6.857706546783447\n",
            "Adjusting learning rate of group 0 to 7.4577e-06.\n",
            "iteration 29 | loss 6.773951053619385\n",
            "Adjusting learning rate of group 0 to 7.8954e-06.\n",
            "iteration 30 | loss 6.821871757507324\n",
            "Adjusting learning rate of group 0 to 8.3475e-06.\n",
            "iteration 31 | loss 6.643355369567871\n",
            "Adjusting learning rate of group 0 to 8.8138e-06.\n",
            "iteration 32 | loss 6.594238758087158\n",
            "Adjusting learning rate of group 0 to 9.2946e-06.\n",
            "iteration 33 | loss 6.520406723022461\n",
            "Adjusting learning rate of group 0 to 9.7896e-06.\n",
            "iteration 34 | loss 6.365542411804199\n",
            "Adjusting learning rate of group 0 to 1.0299e-05.\n",
            "iteration 35 | loss 6.235301971435547\n",
            "Adjusting learning rate of group 0 to 1.0823e-05.\n",
            "iteration 36 | loss 5.873777866363525\n",
            "Adjusting learning rate of group 0 to 1.1361e-05.\n",
            "iteration 37 | loss 5.8004655838012695\n",
            "Adjusting learning rate of group 0 to 1.1913e-05.\n",
            "iteration 38 | loss 5.704086780548096\n",
            "Adjusting learning rate of group 0 to 1.2480e-05.\n",
            "iteration 39 | loss 5.561039924621582\n",
            "Adjusting learning rate of group 0 to 1.3061e-05.\n",
            "iteration 40 | loss 5.178984642028809\n",
            "Adjusting learning rate of group 0 to 1.3657e-05.\n",
            "iteration 41 | loss 5.213768005371094\n",
            "Adjusting learning rate of group 0 to 1.4267e-05.\n",
            "iteration 42 | loss 4.988568305969238\n",
            "Adjusting learning rate of group 0 to 1.4891e-05.\n",
            "iteration 43 | loss 4.728596210479736\n",
            "Adjusting learning rate of group 0 to 1.5530e-05.\n",
            "iteration 44 | loss 4.452016353607178\n",
            "Adjusting learning rate of group 0 to 1.6182e-05.\n",
            "iteration 45 | loss 4.288194179534912\n",
            "Adjusting learning rate of group 0 to 1.6850e-05.\n",
            "iteration 46 | loss 4.0774383544921875\n",
            "Adjusting learning rate of group 0 to 1.7531e-05.\n",
            "iteration 47 | loss 3.771812915802002\n",
            "Adjusting learning rate of group 0 to 1.8227e-05.\n",
            "iteration 48 | loss 3.544713020324707\n",
            "Adjusting learning rate of group 0 to 1.8937e-05.\n",
            "iteration 49 | loss 3.1438798904418945\n",
            "Adjusting learning rate of group 0 to 1.9662e-05.\n",
            "iteration 50 | loss 3.1269948482513428\n",
            "Adjusting learning rate of group 0 to 2.0401e-05.\n",
            "iteration 51 | loss 3.1827645301818848\n",
            "Adjusting learning rate of group 0 to 2.1154e-05.\n",
            "iteration 52 | loss 2.916545867919922\n",
            "Adjusting learning rate of group 0 to 2.1922e-05.\n",
            "iteration 53 | loss 2.8660051822662354\n",
            "Adjusting learning rate of group 0 to 2.2704e-05.\n",
            "iteration 54 | loss 2.587392568588257\n",
            "Adjusting learning rate of group 0 to 2.3500e-05.\n",
            "iteration 55 | loss 2.512963056564331\n",
            "Adjusting learning rate of group 0 to 2.4311e-05.\n",
            "iteration 56 | loss 2.5124385356903076\n",
            "Adjusting learning rate of group 0 to 2.5136e-05.\n",
            "iteration 57 | loss 2.532606363296509\n",
            "Adjusting learning rate of group 0 to 2.5976e-05.\n",
            "iteration 58 | loss 2.5983028411865234\n",
            "Adjusting learning rate of group 0 to 2.6829e-05.\n",
            "iteration 59 | loss 2.6001107692718506\n",
            "Adjusting learning rate of group 0 to 2.7697e-05.\n",
            "iteration 60 | loss 2.4664323329925537\n",
            "Adjusting learning rate of group 0 to 2.8580e-05.\n",
            "iteration 61 | loss 2.5173983573913574\n",
            "Adjusting learning rate of group 0 to 2.9477e-05.\n",
            "iteration 62 | loss 2.2757866382598877\n",
            "Adjusting learning rate of group 0 to 3.0388e-05.\n",
            "iteration 63 | loss 2.6351542472839355\n",
            "Adjusting learning rate of group 0 to 3.1313e-05.\n",
            "iteration 64 | loss 2.5176682472229004\n",
            "Adjusting learning rate of group 0 to 3.2253e-05.\n",
            "iteration 65 | loss 2.309985637664795\n",
            "Adjusting learning rate of group 0 to 3.3207e-05.\n",
            "iteration 66 | loss 2.6446726322174072\n",
            "Adjusting learning rate of group 0 to 3.4175e-05.\n",
            "iteration 67 | loss 2.6882619857788086\n",
            "Adjusting learning rate of group 0 to 3.5158e-05.\n",
            "iteration 68 | loss 2.4621520042419434\n",
            "Adjusting learning rate of group 0 to 3.6155e-05.\n",
            "iteration 69 | loss 2.5361788272857666\n",
            "Adjusting learning rate of group 0 to 3.7167e-05.\n",
            "iteration 70 | loss 2.5809459686279297\n",
            "Adjusting learning rate of group 0 to 3.8193e-05.\n",
            "iteration 71 | loss 2.529144048690796\n",
            "Adjusting learning rate of group 0 to 3.9233e-05.\n",
            "iteration 72 | loss 2.5457732677459717\n",
            "Adjusting learning rate of group 0 to 4.0287e-05.\n",
            "iteration 73 | loss 2.741774559020996\n",
            "Adjusting learning rate of group 0 to 4.1356e-05.\n",
            "iteration 74 | loss 2.860856294631958\n",
            "Adjusting learning rate of group 0 to 4.2440e-05.\n",
            "iteration 75 | loss 2.7479825019836426\n",
            "Adjusting learning rate of group 0 to 4.3537e-05.\n",
            "iteration 76 | loss 3.011335611343384\n",
            "Adjusting learning rate of group 0 to 4.4649e-05.\n",
            "iteration 77 | loss 2.926136016845703\n",
            "Adjusting learning rate of group 0 to 4.5775e-05.\n",
            "iteration 78 | loss 2.7925310134887695\n",
            "Adjusting learning rate of group 0 to 4.6916e-05.\n",
            "iteration 79 | loss 3.026181936264038\n",
            "Adjusting learning rate of group 0 to 4.8071e-05.\n",
            "iteration 80 | loss 3.1109871864318848\n",
            "Adjusting learning rate of group 0 to 4.9240e-05.\n",
            "iteration 81 | loss 3.4832940101623535\n",
            "Adjusting learning rate of group 0 to 5.0423e-05.\n",
            "iteration 82 | loss 2.8618311882019043\n",
            "Adjusting learning rate of group 0 to 5.1621e-05.\n",
            "iteration 83 | loss 3.01472806930542\n",
            "Adjusting learning rate of group 0 to 5.2833e-05.\n",
            "iteration 84 | loss 3.0701417922973633\n",
            "Adjusting learning rate of group 0 to 5.4060e-05.\n",
            "iteration 85 | loss 3.6315627098083496\n",
            "Adjusting learning rate of group 0 to 5.5301e-05.\n",
            "iteration 86 | loss 3.4292151927948\n",
            "Adjusting learning rate of group 0 to 5.6556e-05.\n",
            "iteration 87 | loss 3.1174590587615967\n",
            "Adjusting learning rate of group 0 to 5.7826e-05.\n",
            "iteration 88 | loss 3.6070969104766846\n",
            "Adjusting learning rate of group 0 to 5.9110e-05.\n",
            "iteration 89 | loss 3.5085418224334717\n",
            "Adjusting learning rate of group 0 to 6.0408e-05.\n",
            "iteration 90 | loss 3.6556334495544434\n",
            "Adjusting learning rate of group 0 to 6.1720e-05.\n",
            "iteration 91 | loss 3.9370813369750977\n",
            "Adjusting learning rate of group 0 to 6.3047e-05.\n",
            "iteration 92 | loss 4.130853652954102\n",
            "Adjusting learning rate of group 0 to 6.4389e-05.\n",
            "iteration 93 | loss 3.8731894493103027\n",
            "Adjusting learning rate of group 0 to 6.5744e-05.\n",
            "iteration 94 | loss 4.754654884338379\n",
            "Adjusting learning rate of group 0 to 6.7114e-05.\n",
            "iteration 95 | loss 5.233935356140137\n",
            "Adjusting learning rate of group 0 to 6.8498e-05.\n",
            "iteration 96 | loss 5.126384735107422\n",
            "Adjusting learning rate of group 0 to 6.9897e-05.\n",
            "iteration 97 | loss 5.371180534362793\n",
            "Adjusting learning rate of group 0 to 7.1310e-05.\n",
            "iteration 98 | loss 5.9075846672058105\n",
            "Adjusting learning rate of group 0 to 7.2737e-05.\n",
            "iteration 99 | loss 6.430187702178955\n",
            "Adjusting learning rate of group 0 to 7.4179e-05.\n",
            "iteration 100 | loss 6.587846755981445\n",
            "Adjusting learning rate of group 0 to 7.5635e-05.\n",
            "iteration 101 | loss 5.835836887359619\n",
            "Adjusting learning rate of group 0 to 7.7105e-05.\n",
            "iteration 102 | loss 7.439769268035889\n",
            "Adjusting learning rate of group 0 to 7.8589e-05.\n",
            "iteration 103 | loss 6.2624664306640625\n",
            "Adjusting learning rate of group 0 to 8.0088e-05.\n",
            "iteration 104 | loss 6.530163288116455\n",
            "Adjusting learning rate of group 0 to 8.1601e-05.\n",
            "iteration 105 | loss 6.990357875823975\n",
            "Adjusting learning rate of group 0 to 8.3129e-05.\n",
            "iteration 106 | loss 5.788701057434082\n",
            "Adjusting learning rate of group 0 to 8.4671e-05.\n",
            "iteration 107 | loss 7.252050876617432\n",
            "Adjusting learning rate of group 0 to 8.6227e-05.\n",
            "iteration 108 | loss 6.836554050445557\n",
            "Adjusting learning rate of group 0 to 8.7797e-05.\n",
            "iteration 109 | loss 6.125908374786377\n",
            "Adjusting learning rate of group 0 to 8.9382e-05.\n",
            "iteration 110 | loss 5.940696716308594\n",
            "Adjusting learning rate of group 0 to 9.0981e-05.\n",
            "iteration 111 | loss 6.270747661590576\n",
            "Adjusting learning rate of group 0 to 9.2595e-05.\n",
            "iteration 112 | loss 6.22832727432251\n",
            "Adjusting learning rate of group 0 to 9.4223e-05.\n",
            "iteration 113 | loss 7.333380222320557\n",
            "Adjusting learning rate of group 0 to 9.5865e-05.\n",
            "iteration 114 | loss 6.850183486938477\n",
            "Adjusting learning rate of group 0 to 9.7521e-05.\n",
            "iteration 115 | loss 6.526492595672607\n",
            "Adjusting learning rate of group 0 to 9.9192e-05.\n",
            "iteration 116 | loss 5.878780841827393\n",
            "Adjusting learning rate of group 0 to 1.0088e-04.\n",
            "iteration 117 | loss 7.265984535217285\n",
            "Adjusting learning rate of group 0 to 1.0258e-04.\n",
            "iteration 118 | loss 8.117681503295898\n",
            "Adjusting learning rate of group 0 to 1.0429e-04.\n",
            "iteration 119 | loss 7.798727035522461\n",
            "Adjusting learning rate of group 0 to 1.0602e-04.\n",
            "iteration 120 | loss 7.173066139221191\n",
            "Adjusting learning rate of group 0 to 1.0776e-04.\n",
            "iteration 121 | loss 8.577013969421387\n",
            "Adjusting learning rate of group 0 to 1.0952e-04.\n",
            "iteration 122 | loss 10.31029224395752\n",
            "Adjusting learning rate of group 0 to 1.1129e-04.\n",
            "iteration 123 | loss 10.063392639160156\n",
            "Adjusting learning rate of group 0 to 1.1307e-04.\n",
            "iteration 124 | loss 9.479537963867188\n",
            "Adjusting learning rate of group 0 to 1.1487e-04.\n",
            "iteration 125 | loss 10.409281730651855\n",
            "Adjusting learning rate of group 0 to 1.1669e-04.\n",
            "iteration 126 | loss 11.659783363342285\n",
            "Adjusting learning rate of group 0 to 1.1852e-04.\n",
            "iteration 127 | loss 14.06931209564209\n",
            "Adjusting learning rate of group 0 to 1.2036e-04.\n",
            "iteration 128 | loss 13.920906066894531\n",
            "Adjusting learning rate of group 0 to 1.2222e-04.\n",
            "iteration 129 | loss 15.515785217285156\n",
            "Adjusting learning rate of group 0 to 1.2409e-04.\n",
            "iteration 130 | loss 16.642623901367188\n",
            "Adjusting learning rate of group 0 to 1.2597e-04.\n",
            "iteration 131 | loss 17.121639251708984\n",
            "Adjusting learning rate of group 0 to 1.2787e-04.\n",
            "iteration 132 | loss 14.237475395202637\n",
            "Adjusting learning rate of group 0 to 1.2979e-04.\n",
            "iteration 133 | loss 16.158605575561523\n",
            "Adjusting learning rate of group 0 to 1.3172e-04.\n",
            "iteration 134 | loss 15.166858673095703\n",
            "Adjusting learning rate of group 0 to 1.3366e-04.\n",
            "iteration 135 | loss 18.780550003051758\n",
            "Adjusting learning rate of group 0 to 1.3562e-04.\n",
            "iteration 136 | loss 20.179271697998047\n",
            "Adjusting learning rate of group 0 to 1.3759e-04.\n",
            "iteration 137 | loss 19.033363342285156\n",
            "Adjusting learning rate of group 0 to 1.3957e-04.\n",
            "iteration 138 | loss 20.80356216430664\n",
            "Adjusting learning rate of group 0 to 1.4157e-04.\n",
            "iteration 139 | loss 20.993942260742188\n",
            "Adjusting learning rate of group 0 to 1.4359e-04.\n",
            "iteration 140 | loss 18.55830955505371\n",
            "Adjusting learning rate of group 0 to 1.4562e-04.\n",
            "iteration 141 | loss 22.62188720703125\n",
            "Adjusting learning rate of group 0 to 1.4766e-04.\n",
            "iteration 142 | loss 23.794448852539062\n",
            "Adjusting learning rate of group 0 to 1.4972e-04.\n",
            "iteration 143 | loss 23.607131958007812\n",
            "Adjusting learning rate of group 0 to 1.5179e-04.\n",
            "iteration 144 | loss 20.414405822753906\n",
            "Adjusting learning rate of group 0 to 1.5387e-04.\n",
            "iteration 145 | loss 22.8425350189209\n",
            "Adjusting learning rate of group 0 to 1.5597e-04.\n",
            "iteration 146 | loss 26.640090942382812\n",
            "Adjusting learning rate of group 0 to 1.5809e-04.\n",
            "iteration 147 | loss 20.914329528808594\n",
            "Adjusting learning rate of group 0 to 1.6022e-04.\n",
            "iteration 148 | loss 20.91267204284668\n",
            "Adjusting learning rate of group 0 to 1.6236e-04.\n",
            "iteration 149 | loss 20.88590431213379\n",
            "Adjusting learning rate of group 0 to 1.6452e-04.\n",
            "iteration 150 | loss 22.770206451416016\n",
            "Adjusting learning rate of group 0 to 1.6669e-04.\n",
            "iteration 151 | loss 21.727436065673828\n",
            "Adjusting learning rate of group 0 to 1.6888e-04.\n",
            "iteration 152 | loss 25.407272338867188\n",
            "Adjusting learning rate of group 0 to 1.7108e-04.\n",
            "iteration 153 | loss 19.793596267700195\n",
            "Adjusting learning rate of group 0 to 1.7329e-04.\n",
            "iteration 154 | loss 23.52820587158203\n",
            "Adjusting learning rate of group 0 to 1.7552e-04.\n",
            "iteration 155 | loss 20.752971649169922\n",
            "Adjusting learning rate of group 0 to 1.7776e-04.\n",
            "iteration 156 | loss 25.12322425842285\n",
            "Adjusting learning rate of group 0 to 1.8002e-04.\n",
            "iteration 157 | loss 24.354785919189453\n",
            "Adjusting learning rate of group 0 to 1.8229e-04.\n",
            "iteration 158 | loss 26.4316349029541\n",
            "Adjusting learning rate of group 0 to 1.8458e-04.\n",
            "iteration 159 | loss 26.892959594726562\n",
            "Adjusting learning rate of group 0 to 1.8688e-04.\n",
            "iteration 160 | loss 27.66520881652832\n",
            "Adjusting learning rate of group 0 to 1.8919e-04.\n",
            "iteration 161 | loss 30.24744415283203\n",
            "Adjusting learning rate of group 0 to 1.9152e-04.\n",
            "iteration 162 | loss 31.487133026123047\n",
            "Adjusting learning rate of group 0 to 1.9387e-04.\n",
            "iteration 163 | loss 32.00516128540039\n",
            "Adjusting learning rate of group 0 to 1.9622e-04.\n",
            "iteration 164 | loss 30.145448684692383\n",
            "Adjusting learning rate of group 0 to 1.9860e-04.\n",
            "iteration 165 | loss 34.78847885131836\n",
            "Adjusting learning rate of group 0 to 2.0098e-04.\n",
            "iteration 166 | loss 27.571760177612305\n",
            "Adjusting learning rate of group 0 to 2.0338e-04.\n",
            "iteration 167 | loss 27.89364242553711\n",
            "Adjusting learning rate of group 0 to 2.0580e-04.\n",
            "iteration 168 | loss 32.71976852416992\n",
            "Adjusting learning rate of group 0 to 2.0823e-04.\n",
            "iteration 169 | loss 30.987823486328125\n",
            "Adjusting learning rate of group 0 to 2.1067e-04.\n",
            "iteration 170 | loss 29.04477882385254\n",
            "Adjusting learning rate of group 0 to 2.1313e-04.\n",
            "iteration 171 | loss 27.00444793701172\n",
            "Adjusting learning rate of group 0 to 2.1560e-04.\n",
            "iteration 172 | loss 26.14142417907715\n",
            "Adjusting learning rate of group 0 to 2.1809e-04.\n",
            "iteration 173 | loss 27.673324584960938\n",
            "Adjusting learning rate of group 0 to 2.2059e-04.\n",
            "iteration 174 | loss 33.04723358154297\n",
            "Adjusting learning rate of group 0 to 2.2310e-04.\n",
            "iteration 175 | loss 32.12405776977539\n",
            "Adjusting learning rate of group 0 to 2.2563e-04.\n",
            "iteration 176 | loss 32.403018951416016\n",
            "Adjusting learning rate of group 0 to 2.2817e-04.\n",
            "iteration 177 | loss 29.938047409057617\n",
            "Adjusting learning rate of group 0 to 2.3073e-04.\n",
            "iteration 178 | loss 26.350194931030273\n",
            "Adjusting learning rate of group 0 to 2.3330e-04.\n",
            "iteration 179 | loss 28.984804153442383\n",
            "Adjusting learning rate of group 0 to 2.3589e-04.\n",
            "iteration 180 | loss 31.065309524536133\n",
            "Adjusting learning rate of group 0 to 2.3849e-04.\n",
            "iteration 181 | loss 29.004688262939453\n",
            "Adjusting learning rate of group 0 to 2.4111e-04.\n",
            "iteration 182 | loss 27.758445739746094\n",
            "Adjusting learning rate of group 0 to 2.4373e-04.\n",
            "iteration 183 | loss 28.123106002807617\n",
            "Adjusting learning rate of group 0 to 2.4638e-04.\n",
            "iteration 184 | loss 22.240079879760742\n",
            "Adjusting learning rate of group 0 to 2.4904e-04.\n",
            "iteration 185 | loss 23.39332389831543\n",
            "Adjusting learning rate of group 0 to 2.5171e-04.\n",
            "iteration 186 | loss 23.902746200561523\n",
            "Adjusting learning rate of group 0 to 2.5439e-04.\n",
            "iteration 187 | loss 24.266599655151367\n",
            "Adjusting learning rate of group 0 to 2.5709e-04.\n",
            "iteration 188 | loss 28.762348175048828\n",
            "Adjusting learning rate of group 0 to 2.5981e-04.\n",
            "iteration 189 | loss 21.77369499206543\n",
            "Adjusting learning rate of group 0 to 2.6254e-04.\n",
            "iteration 190 | loss 18.881620407104492\n",
            "Adjusting learning rate of group 0 to 2.6528e-04.\n",
            "iteration 191 | loss 20.26067543029785\n",
            "Adjusting learning rate of group 0 to 2.6804e-04.\n",
            "iteration 192 | loss 16.538562774658203\n",
            "Adjusting learning rate of group 0 to 2.7081e-04.\n",
            "iteration 193 | loss 16.103498458862305\n",
            "Adjusting learning rate of group 0 to 2.7360e-04.\n",
            "iteration 194 | loss 16.650320053100586\n",
            "Adjusting learning rate of group 0 to 2.7640e-04.\n",
            "iteration 195 | loss 19.516511917114258\n",
            "Adjusting learning rate of group 0 to 2.7921e-04.\n",
            "iteration 196 | loss 14.314065933227539\n",
            "Adjusting learning rate of group 0 to 2.8204e-04.\n",
            "iteration 197 | loss 16.82403564453125\n",
            "Adjusting learning rate of group 0 to 2.8488e-04.\n",
            "iteration 198 | loss 11.012598037719727\n",
            "Adjusting learning rate of group 0 to 2.8774e-04.\n",
            "iteration 199 | loss 11.969795227050781\n",
            "Adjusting learning rate of group 0 to 2.9061e-04.\n",
            "iteration 200 | loss 17.247955322265625\n",
            "Adjusting learning rate of group 0 to 2.9350e-04.\n",
            "iteration 201 | loss 20.964488983154297\n",
            "Adjusting learning rate of group 0 to 2.9640e-04.\n",
            "iteration 202 | loss 10.664722442626953\n",
            "Adjusting learning rate of group 0 to 2.9932e-04.\n",
            "iteration 203 | loss 17.73264503479004\n",
            "Adjusting learning rate of group 0 to 3.0224e-04.\n",
            "iteration 204 | loss 9.575456619262695\n",
            "Adjusting learning rate of group 0 to 3.0519e-04.\n",
            "iteration 205 | loss 10.135613441467285\n",
            "Adjusting learning rate of group 0 to 3.0814e-04.\n",
            "iteration 206 | loss 7.480310916900635\n",
            "Adjusting learning rate of group 0 to 3.1112e-04.\n",
            "iteration 207 | loss 6.932837009429932\n",
            "Adjusting learning rate of group 0 to 3.1410e-04.\n",
            "iteration 208 | loss 9.608658790588379\n",
            "Adjusting learning rate of group 0 to 3.1710e-04.\n",
            "iteration 209 | loss 16.750234603881836\n",
            "Adjusting learning rate of group 0 to 3.2012e-04.\n",
            "iteration 210 | loss 16.574417114257812\n",
            "Adjusting learning rate of group 0 to 3.2315e-04.\n",
            "iteration 211 | loss 18.836233139038086\n",
            "Adjusting learning rate of group 0 to 3.2619e-04.\n",
            "iteration 212 | loss 12.265631675720215\n",
            "Adjusting learning rate of group 0 to 3.2925e-04.\n",
            "iteration 213 | loss 17.552780151367188\n",
            "Adjusting learning rate of group 0 to 3.3232e-04.\n",
            "iteration 214 | loss 15.8511381149292\n",
            "Adjusting learning rate of group 0 to 3.3540e-04.\n",
            "iteration 215 | loss 16.385055541992188\n",
            "Adjusting learning rate of group 0 to 3.3850e-04.\n",
            "iteration 216 | loss 17.213701248168945\n",
            "Adjusting learning rate of group 0 to 3.4162e-04.\n",
            "iteration 217 | loss 13.201826095581055\n",
            "Adjusting learning rate of group 0 to 3.4475e-04.\n",
            "iteration 218 | loss 17.36979866027832\n",
            "Adjusting learning rate of group 0 to 3.4789e-04.\n",
            "iteration 219 | loss 9.186727523803711\n",
            "Adjusting learning rate of group 0 to 3.5105e-04.\n",
            "iteration 220 | loss 8.997602462768555\n",
            "Adjusting learning rate of group 0 to 3.5422e-04.\n",
            "iteration 221 | loss 5.45142936706543\n",
            "Adjusting learning rate of group 0 to 3.5740e-04.\n",
            "iteration 222 | loss 18.882423400878906\n",
            "Adjusting learning rate of group 0 to 3.6060e-04.\n",
            "iteration 223 | loss 9.904953956604004\n",
            "Adjusting learning rate of group 0 to 3.6382e-04.\n",
            "iteration 224 | loss 6.420366287231445\n",
            "Adjusting learning rate of group 0 to 3.6704e-04.\n",
            "iteration 225 | loss 3.9398117065429688\n",
            "Adjusting learning rate of group 0 to 3.7029e-04.\n",
            "iteration 226 | loss 8.117830276489258\n",
            "Adjusting learning rate of group 0 to 3.7354e-04.\n",
            "iteration 227 | loss 7.1371846199035645\n",
            "Adjusting learning rate of group 0 to 3.7681e-04.\n",
            "iteration 228 | loss 18.624141693115234\n",
            "Adjusting learning rate of group 0 to 3.8010e-04.\n",
            "iteration 229 | loss 7.237024307250977\n",
            "Adjusting learning rate of group 0 to 3.8340e-04.\n",
            "iteration 230 | loss 3.9864609241485596\n",
            "Adjusting learning rate of group 0 to 3.8671e-04.\n",
            "iteration 231 | loss 3.841444730758667\n",
            "Adjusting learning rate of group 0 to 3.9004e-04.\n",
            "iteration 232 | loss 6.9069647789001465\n",
            "Adjusting learning rate of group 0 to 3.9338e-04.\n",
            "iteration 233 | loss 9.532620429992676\n",
            "Adjusting learning rate of group 0 to 3.9674e-04.\n",
            "iteration 234 | loss 15.46306037902832\n",
            "Adjusting learning rate of group 0 to 4.0011e-04.\n",
            "iteration 235 | loss 13.897610664367676\n",
            "Adjusting learning rate of group 0 to 4.0350e-04.\n",
            "iteration 236 | loss 8.381174087524414\n",
            "Adjusting learning rate of group 0 to 4.0689e-04.\n",
            "iteration 237 | loss 14.941421508789062\n",
            "Adjusting learning rate of group 0 to 4.1031e-04.\n",
            "iteration 238 | loss 7.712433815002441\n",
            "Adjusting learning rate of group 0 to 4.1374e-04.\n",
            "iteration 239 | loss 4.756857872009277\n",
            "Adjusting learning rate of group 0 to 4.1718e-04.\n",
            "iteration 240 | loss 7.826361179351807\n",
            "Adjusting learning rate of group 0 to 4.2063e-04.\n",
            "iteration 241 | loss 5.610789775848389\n",
            "Adjusting learning rate of group 0 to 4.2410e-04.\n",
            "iteration 242 | loss 7.544558525085449\n",
            "Adjusting learning rate of group 0 to 4.2759e-04.\n",
            "iteration 243 | loss 7.074269771575928\n",
            "Adjusting learning rate of group 0 to 4.3109e-04.\n",
            "iteration 244 | loss 6.561190605163574\n",
            "Adjusting learning rate of group 0 to 4.3460e-04.\n",
            "iteration 245 | loss 8.051924705505371\n",
            "Adjusting learning rate of group 0 to 4.3813e-04.\n",
            "iteration 246 | loss 10.514870643615723\n",
            "Adjusting learning rate of group 0 to 4.4167e-04.\n",
            "iteration 247 | loss 15.722454071044922\n",
            "Adjusting learning rate of group 0 to 4.4522e-04.\n",
            "iteration 248 | loss 8.732441902160645\n",
            "Adjusting learning rate of group 0 to 4.4879e-04.\n",
            "iteration 249 | loss 7.561603546142578\n",
            "Adjusting learning rate of group 0 to 4.5238e-04.\n",
            "iteration 250 | loss 9.451951026916504\n",
            "Adjusting learning rate of group 0 to 4.5598e-04.\n",
            "iteration 251 | loss 20.55914878845215\n",
            "Adjusting learning rate of group 0 to 4.5959e-04.\n",
            "iteration 252 | loss 6.932514190673828\n",
            "Adjusting learning rate of group 0 to 4.6322e-04.\n",
            "iteration 253 | loss 16.221704483032227\n",
            "Adjusting learning rate of group 0 to 4.6686e-04.\n",
            "iteration 254 | loss 6.327256202697754\n",
            "Adjusting learning rate of group 0 to 4.7051e-04.\n",
            "iteration 255 | loss 23.702791213989258\n",
            "Adjusting learning rate of group 0 to 4.7418e-04.\n",
            "iteration 256 | loss 12.711435317993164\n",
            "Adjusting learning rate of group 0 to 4.7786e-04.\n",
            "iteration 257 | loss 12.95642375946045\n",
            "Adjusting learning rate of group 0 to 4.8156e-04.\n",
            "iteration 258 | loss 22.144407272338867\n",
            "Adjusting learning rate of group 0 to 4.8527e-04.\n",
            "iteration 259 | loss 17.38797378540039\n",
            "Adjusting learning rate of group 0 to 4.8900e-04.\n",
            "iteration 260 | loss 24.91176986694336\n",
            "Adjusting learning rate of group 0 to 4.9274e-04.\n",
            "iteration 261 | loss 14.208992004394531\n",
            "Adjusting learning rate of group 0 to 4.9650e-04.\n",
            "iteration 262 | loss 19.235031127929688\n",
            "Adjusting learning rate of group 0 to 5.0027e-04.\n",
            "iteration 263 | loss 27.72806739807129\n",
            "Adjusting learning rate of group 0 to 5.0405e-04.\n",
            "iteration 264 | loss 24.842819213867188\n",
            "Adjusting learning rate of group 0 to 5.0785e-04.\n",
            "iteration 265 | loss 23.58274269104004\n",
            "Adjusting learning rate of group 0 to 5.1166e-04.\n",
            "iteration 266 | loss 25.1656436920166\n",
            "Adjusting learning rate of group 0 to 5.1548e-04.\n",
            "iteration 267 | loss 34.39200973510742\n",
            "Adjusting learning rate of group 0 to 5.1932e-04.\n",
            "iteration 268 | loss 33.11497116088867\n",
            "Adjusting learning rate of group 0 to 5.2318e-04.\n",
            "iteration 269 | loss 33.415401458740234\n",
            "Adjusting learning rate of group 0 to 5.2705e-04.\n",
            "iteration 270 | loss 31.456584930419922\n",
            "Adjusting learning rate of group 0 to 5.3093e-04.\n",
            "iteration 271 | loss 10.639484405517578\n",
            "Adjusting learning rate of group 0 to 5.3482e-04.\n",
            "iteration 272 | loss 26.83637809753418\n",
            "Adjusting learning rate of group 0 to 5.3874e-04.\n",
            "iteration 273 | loss 33.55435562133789\n",
            "Adjusting learning rate of group 0 to 5.4266e-04.\n",
            "iteration 274 | loss 39.246952056884766\n",
            "Adjusting learning rate of group 0 to 5.4660e-04.\n",
            "iteration 275 | loss 22.468263626098633\n",
            "Adjusting learning rate of group 0 to 5.5055e-04.\n",
            "iteration 276 | loss 43.74799728393555\n",
            "Adjusting learning rate of group 0 to 5.5452e-04.\n",
            "iteration 277 | loss 32.14991760253906\n",
            "Adjusting learning rate of group 0 to 5.5850e-04.\n",
            "iteration 278 | loss 39.74293899536133\n",
            "Adjusting learning rate of group 0 to 5.6250e-04.\n",
            "iteration 279 | loss 52.62117004394531\n",
            "Adjusting learning rate of group 0 to 5.6651e-04.\n",
            "iteration 280 | loss 12.744369506835938\n",
            "Adjusting learning rate of group 0 to 5.7053e-04.\n",
            "iteration 281 | loss 49.128944396972656\n",
            "Adjusting learning rate of group 0 to 5.7457e-04.\n",
            "iteration 282 | loss 30.620437622070312\n",
            "Adjusting learning rate of group 0 to 5.7863e-04.\n",
            "iteration 283 | loss 34.893821716308594\n",
            "Adjusting learning rate of group 0 to 5.8269e-04.\n",
            "iteration 284 | loss 38.27971267700195\n",
            "Adjusting learning rate of group 0 to 5.8677e-04.\n",
            "iteration 285 | loss 34.79972457885742\n",
            "Adjusting learning rate of group 0 to 5.9087e-04.\n",
            "iteration 286 | loss 15.17595100402832\n",
            "Adjusting learning rate of group 0 to 5.9498e-04.\n",
            "iteration 287 | loss 34.102508544921875\n",
            "Adjusting learning rate of group 0 to 5.9910e-04.\n",
            "iteration 288 | loss 21.50845718383789\n",
            "Adjusting learning rate of group 0 to 6.0324e-04.\n",
            "iteration 289 | loss 14.018341064453125\n",
            "Adjusting learning rate of group 0 to 6.0739e-04.\n",
            "iteration 290 | loss 32.42650604248047\n",
            "Adjusting learning rate of group 0 to 6.1156e-04.\n",
            "iteration 291 | loss 25.12215232849121\n",
            "Adjusting learning rate of group 0 to 6.1574e-04.\n",
            "iteration 292 | loss 17.237571716308594\n",
            "Adjusting learning rate of group 0 to 6.1993e-04.\n",
            "iteration 293 | loss 19.223600387573242\n",
            "Adjusting learning rate of group 0 to 6.2414e-04.\n",
            "iteration 294 | loss 33.01685333251953\n",
            "Adjusting learning rate of group 0 to 6.2837e-04.\n",
            "iteration 295 | loss 31.436717987060547\n",
            "Adjusting learning rate of group 0 to 6.3260e-04.\n",
            "iteration 296 | loss 24.2637939453125\n",
            "Adjusting learning rate of group 0 to 6.3685e-04.\n",
            "iteration 297 | loss 13.28665542602539\n",
            "Adjusting learning rate of group 0 to 6.4112e-04.\n",
            "iteration 298 | loss 26.847301483154297\n",
            "Adjusting learning rate of group 0 to 6.4540e-04.\n",
            "iteration 299 | loss 25.67186164855957\n",
            "Adjusting learning rate of group 0 to 6.4969e-04.\n",
            "iteration 300 | loss 27.610048294067383\n",
            "Adjusting learning rate of group 0 to 6.5400e-04.\n",
            "iteration 301 | loss 24.04269027709961\n",
            "Adjusting learning rate of group 0 to 6.5832e-04.\n",
            "iteration 302 | loss 21.017356872558594\n",
            "Adjusting learning rate of group 0 to 6.6266e-04.\n",
            "iteration 303 | loss 32.250213623046875\n",
            "Adjusting learning rate of group 0 to 6.6701e-04.\n",
            "iteration 304 | loss 18.567777633666992\n",
            "Adjusting learning rate of group 0 to 6.7137e-04.\n",
            "iteration 305 | loss 23.629568099975586\n",
            "Adjusting learning rate of group 0 to 6.7575e-04.\n",
            "iteration 306 | loss 33.68345260620117\n",
            "Adjusting learning rate of group 0 to 6.8015e-04.\n",
            "iteration 307 | loss 18.138486862182617\n",
            "Adjusting learning rate of group 0 to 6.8455e-04.\n",
            "iteration 308 | loss 49.45067596435547\n",
            "Adjusting learning rate of group 0 to 6.8897e-04.\n",
            "iteration 309 | loss 34.09913635253906\n",
            "Adjusting learning rate of group 0 to 6.9341e-04.\n",
            "iteration 310 | loss 42.82670974731445\n",
            "Adjusting learning rate of group 0 to 6.9786e-04.\n",
            "iteration 311 | loss 39.132591247558594\n",
            "Adjusting learning rate of group 0 to 7.0232e-04.\n",
            "iteration 312 | loss 11.091614723205566\n",
            "Adjusting learning rate of group 0 to 7.0680e-04.\n",
            "iteration 313 | loss 55.825801849365234\n",
            "Adjusting learning rate of group 0 to 7.1129e-04.\n",
            "iteration 314 | loss 17.6832332611084\n",
            "Adjusting learning rate of group 0 to 7.1580e-04.\n",
            "iteration 315 | loss 76.68301391601562\n",
            "Adjusting learning rate of group 0 to 7.2032e-04.\n",
            "iteration 316 | loss 11.97818374633789\n",
            "Adjusting learning rate of group 0 to 7.2485e-04.\n",
            "iteration 317 | loss 35.737945556640625\n",
            "Adjusting learning rate of group 0 to 7.2940e-04.\n",
            "iteration 318 | loss 43.23946762084961\n",
            "Adjusting learning rate of group 0 to 7.3397e-04.\n",
            "iteration 319 | loss 5.37879753112793\n",
            "Adjusting learning rate of group 0 to 7.3854e-04.\n",
            "iteration 320 | loss 22.039630889892578\n",
            "Adjusting learning rate of group 0 to 7.4313e-04.\n",
            "iteration 321 | loss 74.411865234375\n",
            "Adjusting learning rate of group 0 to 7.4774e-04.\n",
            "iteration 322 | loss 77.96533203125\n",
            "Adjusting learning rate of group 0 to 7.5236e-04.\n",
            "iteration 323 | loss 21.807401657104492\n",
            "Adjusting learning rate of group 0 to 7.5699e-04.\n",
            "iteration 324 | loss 85.28235626220703\n",
            "Adjusting learning rate of group 0 to 7.6164e-04.\n",
            "iteration 325 | loss 69.90656280517578\n",
            "Adjusting learning rate of group 0 to 7.6630e-04.\n",
            "iteration 326 | loss 33.98210144042969\n",
            "Adjusting learning rate of group 0 to 7.7098e-04.\n",
            "iteration 327 | loss 7.088234901428223\n",
            "Adjusting learning rate of group 0 to 7.7567e-04.\n",
            "iteration 328 | loss 8.952167510986328\n",
            "Adjusting learning rate of group 0 to 7.8037e-04.\n",
            "iteration 329 | loss 37.713623046875\n",
            "Adjusting learning rate of group 0 to 7.8509e-04.\n",
            "iteration 330 | loss 26.351810455322266\n",
            "Adjusting learning rate of group 0 to 7.8982e-04.\n",
            "iteration 331 | loss 55.041282653808594\n",
            "Adjusting learning rate of group 0 to 7.9457e-04.\n",
            "iteration 332 | loss 8.781636238098145\n",
            "Adjusting learning rate of group 0 to 7.9933e-04.\n",
            "iteration 333 | loss 11.518204689025879\n",
            "Adjusting learning rate of group 0 to 8.0410e-04.\n",
            "iteration 334 | loss 36.702152252197266\n",
            "Adjusting learning rate of group 0 to 8.0889e-04.\n",
            "iteration 335 | loss 31.893539428710938\n",
            "Adjusting learning rate of group 0 to 8.1369e-04.\n",
            "iteration 336 | loss 43.606483459472656\n",
            "Adjusting learning rate of group 0 to 8.1851e-04.\n",
            "iteration 337 | loss 10.651909828186035\n",
            "Adjusting learning rate of group 0 to 8.2334e-04.\n",
            "iteration 338 | loss 35.923011779785156\n",
            "Adjusting learning rate of group 0 to 8.2819e-04.\n",
            "iteration 339 | loss 34.56564712524414\n",
            "Adjusting learning rate of group 0 to 8.3305e-04.\n",
            "iteration 340 | loss 9.272638320922852\n",
            "Adjusting learning rate of group 0 to 8.3792e-04.\n",
            "iteration 341 | loss 8.456192970275879\n",
            "Adjusting learning rate of group 0 to 8.4281e-04.\n",
            "iteration 342 | loss 15.73358154296875\n",
            "Adjusting learning rate of group 0 to 8.4771e-04.\n",
            "iteration 343 | loss 8.487675666809082\n",
            "Adjusting learning rate of group 0 to 8.5263e-04.\n",
            "iteration 344 | loss 29.030399322509766\n",
            "Adjusting learning rate of group 0 to 8.5756e-04.\n",
            "iteration 345 | loss 11.358129501342773\n",
            "Adjusting learning rate of group 0 to 8.6250e-04.\n",
            "iteration 346 | loss 39.52961730957031\n",
            "Adjusting learning rate of group 0 to 8.6746e-04.\n",
            "iteration 347 | loss 4.8803558349609375\n",
            "Adjusting learning rate of group 0 to 8.7243e-04.\n",
            "iteration 348 | loss 39.65788269042969\n",
            "Adjusting learning rate of group 0 to 8.7742e-04.\n",
            "iteration 349 | loss 33.5749626159668\n",
            "Adjusting learning rate of group 0 to 8.8242e-04.\n",
            "iteration 350 | loss 5.652103900909424\n",
            "Adjusting learning rate of group 0 to 8.8743e-04.\n",
            "iteration 351 | loss 55.261104583740234\n",
            "Adjusting learning rate of group 0 to 8.9246e-04.\n",
            "iteration 352 | loss 83.58931732177734\n",
            "Adjusting learning rate of group 0 to 8.9750e-04.\n",
            "iteration 353 | loss 49.62086486816406\n",
            "Adjusting learning rate of group 0 to 9.0256e-04.\n",
            "iteration 354 | loss 107.90951538085938\n",
            "Adjusting learning rate of group 0 to 9.0763e-04.\n",
            "iteration 355 | loss 5.533586025238037\n",
            "Adjusting learning rate of group 0 to 9.1272e-04.\n",
            "iteration 356 | loss 104.50333404541016\n",
            "Adjusting learning rate of group 0 to 9.1782e-04.\n",
            "iteration 357 | loss 13.993688583374023\n",
            "Adjusting learning rate of group 0 to 9.2293e-04.\n",
            "iteration 358 | loss 120.37995910644531\n",
            "Adjusting learning rate of group 0 to 9.2806e-04.\n",
            "iteration 359 | loss 23.203697204589844\n",
            "Adjusting learning rate of group 0 to 9.3320e-04.\n",
            "iteration 360 | loss 135.17581176757812\n",
            "Adjusting learning rate of group 0 to 9.3835e-04.\n",
            "iteration 361 | loss 124.76470947265625\n",
            "Adjusting learning rate of group 0 to 9.4352e-04.\n",
            "iteration 362 | loss 127.98241424560547\n",
            "Adjusting learning rate of group 0 to 9.4871e-04.\n",
            "iteration 363 | loss 8.563821792602539\n",
            "Adjusting learning rate of group 0 to 9.5390e-04.\n",
            "iteration 364 | loss 134.54067993164062\n",
            "Adjusting learning rate of group 0 to 9.5912e-04.\n",
            "iteration 365 | loss 133.79336547851562\n",
            "Adjusting learning rate of group 0 to 9.6434e-04.\n",
            "iteration 366 | loss 132.5410919189453\n",
            "Adjusting learning rate of group 0 to 9.6958e-04.\n",
            "iteration 367 | loss 133.16702270507812\n",
            "Adjusting learning rate of group 0 to 9.7483e-04.\n",
            "iteration 368 | loss 133.0370330810547\n",
            "Adjusting learning rate of group 0 to 9.8010e-04.\n",
            "iteration 369 | loss 89.22624206542969\n",
            "Adjusting learning rate of group 0 to 9.8539e-04.\n",
            "iteration 370 | loss 25.694215774536133\n",
            "Adjusting learning rate of group 0 to 9.9068e-04.\n",
            "iteration 371 | loss 135.4748077392578\n",
            "Adjusting learning rate of group 0 to 9.9599e-04.\n",
            "iteration 372 | loss 72.68394470214844\n",
            "Adjusting learning rate of group 0 to 1.0013e-03.\n",
            "iteration 373 | loss 145.4036407470703\n",
            "Adjusting learning rate of group 0 to 1.0067e-03.\n",
            "iteration 374 | loss 31.73981285095215\n",
            "Adjusting learning rate of group 0 to 1.0120e-03.\n",
            "iteration 375 | loss 19.46576690673828\n",
            "Adjusting learning rate of group 0 to 1.0174e-03.\n",
            "iteration 376 | loss 17.749544143676758\n",
            "Adjusting learning rate of group 0 to 1.0228e-03.\n",
            "iteration 377 | loss 81.59664916992188\n",
            "Adjusting learning rate of group 0 to 1.0281e-03.\n",
            "iteration 378 | loss 82.45144653320312\n",
            "Adjusting learning rate of group 0 to 1.0336e-03.\n",
            "iteration 379 | loss 83.7919921875\n",
            "Adjusting learning rate of group 0 to 1.0390e-03.\n",
            "iteration 380 | loss 100.090576171875\n",
            "Adjusting learning rate of group 0 to 1.0444e-03.\n",
            "iteration 381 | loss 32.05881118774414\n",
            "Adjusting learning rate of group 0 to 1.0499e-03.\n",
            "iteration 382 | loss 93.5029525756836\n",
            "Adjusting learning rate of group 0 to 1.0553e-03.\n",
            "iteration 383 | loss 29.32977294921875\n",
            "Adjusting learning rate of group 0 to 1.0608e-03.\n",
            "iteration 384 | loss 60.378883361816406\n",
            "Adjusting learning rate of group 0 to 1.0663e-03.\n",
            "iteration 385 | loss 116.89269256591797\n",
            "Adjusting learning rate of group 0 to 1.0718e-03.\n",
            "iteration 386 | loss 65.45942687988281\n",
            "Adjusting learning rate of group 0 to 1.0773e-03.\n",
            "iteration 387 | loss 115.14627075195312\n",
            "Adjusting learning rate of group 0 to 1.0829e-03.\n",
            "iteration 388 | loss 42.31144332885742\n",
            "Adjusting learning rate of group 0 to 1.0884e-03.\n",
            "iteration 389 | loss 117.29342651367188\n",
            "Adjusting learning rate of group 0 to 1.0940e-03.\n",
            "iteration 390 | loss 22.630931854248047\n",
            "13.935449361801147\n",
            "Adjusting learning rate of group 0 to 1.0996e-03.\n",
            "iteration 0 | loss 70.1993179321289\n",
            "Adjusting learning rate of group 0 to 1.1051e-03.\n",
            "iteration 1 | loss 190.55352783203125\n",
            "Adjusting learning rate of group 0 to 1.1108e-03.\n",
            "iteration 2 | loss 6.330130577087402\n",
            "Adjusting learning rate of group 0 to 1.1164e-03.\n",
            "iteration 3 | loss 76.19682312011719\n",
            "Adjusting learning rate of group 0 to 1.1220e-03.\n",
            "iteration 4 | loss 72.49776458740234\n",
            "Adjusting learning rate of group 0 to 1.1277e-03.\n",
            "iteration 5 | loss 49.918418884277344\n",
            "Adjusting learning rate of group 0 to 1.1333e-03.\n",
            "iteration 6 | loss 182.8013916015625\n",
            "Adjusting learning rate of group 0 to 1.1390e-03.\n",
            "iteration 7 | loss 6.879096984863281\n",
            "Adjusting learning rate of group 0 to 1.1447e-03.\n",
            "iteration 8 | loss 132.70689392089844\n",
            "Adjusting learning rate of group 0 to 1.1504e-03.\n",
            "iteration 9 | loss 120.40623474121094\n",
            "Adjusting learning rate of group 0 to 1.1561e-03.\n",
            "iteration 10 | loss 72.26981353759766\n",
            "Adjusting learning rate of group 0 to 1.1618e-03.\n",
            "iteration 11 | loss 229.60232543945312\n",
            "Adjusting learning rate of group 0 to 1.1676e-03.\n",
            "iteration 12 | loss 123.1028823852539\n",
            "Adjusting learning rate of group 0 to 1.1733e-03.\n",
            "iteration 13 | loss 259.546142578125\n",
            "Adjusting learning rate of group 0 to 1.1791e-03.\n",
            "iteration 14 | loss 248.8511962890625\n",
            "Adjusting learning rate of group 0 to 1.1849e-03.\n",
            "iteration 15 | loss 318.3878479003906\n",
            "Adjusting learning rate of group 0 to 1.1907e-03.\n",
            "iteration 16 | loss 44.2506217956543\n",
            "Adjusting learning rate of group 0 to 1.1965e-03.\n",
            "iteration 17 | loss 21.386470794677734\n",
            "Adjusting learning rate of group 0 to 1.2023e-03.\n",
            "iteration 18 | loss 25.59575653076172\n",
            "Adjusting learning rate of group 0 to 1.2082e-03.\n",
            "iteration 19 | loss 62.08782958984375\n",
            "Adjusting learning rate of group 0 to 1.2140e-03.\n",
            "iteration 20 | loss 260.485107421875\n",
            "Adjusting learning rate of group 0 to 1.2199e-03.\n",
            "iteration 21 | loss 13.684773445129395\n",
            "Adjusting learning rate of group 0 to 1.2258e-03.\n",
            "iteration 22 | loss 7.861680030822754\n",
            "Adjusting learning rate of group 0 to 1.2317e-03.\n",
            "iteration 23 | loss 31.215007781982422\n",
            "Adjusting learning rate of group 0 to 1.2376e-03.\n",
            "iteration 24 | loss 56.67573928833008\n",
            "Adjusting learning rate of group 0 to 1.2435e-03.\n",
            "iteration 25 | loss 329.86767578125\n",
            "Adjusting learning rate of group 0 to 1.2495e-03.\n",
            "iteration 26 | loss 184.82200622558594\n",
            "Adjusting learning rate of group 0 to 1.2554e-03.\n",
            "iteration 27 | loss 42.703460693359375\n",
            "Adjusting learning rate of group 0 to 1.2614e-03.\n",
            "iteration 28 | loss 58.582603454589844\n",
            "Adjusting learning rate of group 0 to 1.2674e-03.\n",
            "iteration 29 | loss 388.0752258300781\n",
            "Adjusting learning rate of group 0 to 1.2734e-03.\n",
            "iteration 30 | loss 259.3843078613281\n",
            "Adjusting learning rate of group 0 to 1.2794e-03.\n",
            "iteration 31 | loss 413.254150390625\n",
            "Adjusting learning rate of group 0 to 1.2854e-03.\n",
            "iteration 32 | loss 141.56898498535156\n",
            "Adjusting learning rate of group 0 to 1.2915e-03.\n",
            "iteration 33 | loss 586.5724487304688\n",
            "Adjusting learning rate of group 0 to 1.2975e-03.\n",
            "iteration 34 | loss 553.8392944335938\n",
            "Adjusting learning rate of group 0 to 1.3036e-03.\n",
            "iteration 35 | loss 219.26133728027344\n",
            "Adjusting learning rate of group 0 to 1.3097e-03.\n",
            "iteration 36 | loss 34.683170318603516\n",
            "Adjusting learning rate of group 0 to 1.3158e-03.\n",
            "iteration 37 | loss 280.17919921875\n",
            "Adjusting learning rate of group 0 to 1.3219e-03.\n",
            "iteration 38 | loss 178.29611206054688\n",
            "Adjusting learning rate of group 0 to 1.3280e-03.\n",
            "iteration 39 | loss 156.2835693359375\n",
            "Adjusting learning rate of group 0 to 1.3341e-03.\n",
            "iteration 40 | loss 347.3335876464844\n",
            "Adjusting learning rate of group 0 to 1.3403e-03.\n",
            "iteration 41 | loss 33.05039596557617\n",
            "Adjusting learning rate of group 0 to 1.3465e-03.\n",
            "iteration 42 | loss 405.35321044921875\n",
            "Adjusting learning rate of group 0 to 1.3526e-03.\n",
            "iteration 43 | loss 329.95855712890625\n",
            "Adjusting learning rate of group 0 to 1.3588e-03.\n",
            "iteration 44 | loss 508.3510437011719\n",
            "Adjusting learning rate of group 0 to 1.3650e-03.\n",
            "iteration 45 | loss 6.6701459884643555\n",
            "Adjusting learning rate of group 0 to 1.3713e-03.\n",
            "iteration 46 | loss 349.60302734375\n",
            "Adjusting learning rate of group 0 to 1.3775e-03.\n",
            "iteration 47 | loss 115.66043853759766\n",
            "Adjusting learning rate of group 0 to 1.3837e-03.\n",
            "iteration 48 | loss 60.71772384643555\n",
            "Adjusting learning rate of group 0 to 1.3900e-03.\n",
            "iteration 49 | loss 336.5763244628906\n",
            "Adjusting learning rate of group 0 to 1.3963e-03.\n",
            "iteration 50 | loss 814.9215698242188\n",
            "Adjusting learning rate of group 0 to 1.4026e-03.\n",
            "iteration 51 | loss 525.9798583984375\n",
            "Adjusting learning rate of group 0 to 1.4089e-03.\n",
            "iteration 52 | loss 451.21417236328125\n",
            "Adjusting learning rate of group 0 to 1.4152e-03.\n",
            "iteration 53 | loss 474.2181091308594\n",
            "Adjusting learning rate of group 0 to 1.4215e-03.\n",
            "iteration 54 | loss 142.6201629638672\n",
            "Adjusting learning rate of group 0 to 1.4279e-03.\n",
            "iteration 55 | loss 597.2069702148438\n",
            "Adjusting learning rate of group 0 to 1.4342e-03.\n",
            "iteration 56 | loss 458.91790771484375\n",
            "Adjusting learning rate of group 0 to 1.4406e-03.\n",
            "iteration 57 | loss 457.0354919433594\n",
            "Adjusting learning rate of group 0 to 1.4470e-03.\n",
            "iteration 58 | loss 8.425127029418945\n",
            "Adjusting learning rate of group 0 to 1.4534e-03.\n",
            "iteration 59 | loss 551.70654296875\n",
            "Adjusting learning rate of group 0 to 1.4598e-03.\n",
            "iteration 60 | loss 432.259521484375\n",
            "Adjusting learning rate of group 0 to 1.4662e-03.\n",
            "iteration 61 | loss 118.77716064453125\n",
            "Adjusting learning rate of group 0 to 1.4727e-03.\n",
            "iteration 62 | loss 549.6870727539062\n",
            "Adjusting learning rate of group 0 to 1.4792e-03.\n",
            "iteration 63 | loss 449.4666442871094\n",
            "Adjusting learning rate of group 0 to 1.4856e-03.\n",
            "iteration 64 | loss 823.1152954101562\n",
            "Adjusting learning rate of group 0 to 1.4921e-03.\n",
            "iteration 65 | loss 476.7961730957031\n",
            "Adjusting learning rate of group 0 to 1.4986e-03.\n",
            "iteration 66 | loss 327.2788391113281\n",
            "Adjusting learning rate of group 0 to 1.5051e-03.\n",
            "iteration 67 | loss 373.1179504394531\n",
            "Adjusting learning rate of group 0 to 1.5117e-03.\n",
            "iteration 68 | loss 181.59471130371094\n",
            "Adjusting learning rate of group 0 to 1.5182e-03.\n",
            "iteration 69 | loss 150.2979736328125\n",
            "Adjusting learning rate of group 0 to 1.5247e-03.\n",
            "iteration 70 | loss 10.171485900878906\n",
            "Adjusting learning rate of group 0 to 1.5313e-03.\n",
            "iteration 71 | loss 53.50468063354492\n",
            "Adjusting learning rate of group 0 to 1.5379e-03.\n",
            "iteration 72 | loss 10.667303085327148\n",
            "Adjusting learning rate of group 0 to 1.5445e-03.\n",
            "iteration 73 | loss 9.788717269897461\n",
            "Adjusting learning rate of group 0 to 1.5511e-03.\n",
            "iteration 74 | loss 150.20147705078125\n",
            "Adjusting learning rate of group 0 to 1.5577e-03.\n",
            "iteration 75 | loss 787.4940185546875\n",
            "Adjusting learning rate of group 0 to 1.5644e-03.\n",
            "iteration 76 | loss 409.8935241699219\n",
            "Adjusting learning rate of group 0 to 1.5710e-03.\n",
            "iteration 77 | loss 640.8728637695312\n",
            "Adjusting learning rate of group 0 to 1.5777e-03.\n",
            "iteration 78 | loss 514.01416015625\n",
            "Adjusting learning rate of group 0 to 1.5844e-03.\n",
            "iteration 79 | loss 532.9273681640625\n",
            "Adjusting learning rate of group 0 to 1.5911e-03.\n",
            "iteration 80 | loss 370.5174560546875\n",
            "Adjusting learning rate of group 0 to 1.5978e-03.\n",
            "iteration 81 | loss 607.9689331054688\n",
            "Adjusting learning rate of group 0 to 1.6045e-03.\n",
            "iteration 82 | loss 565.5034790039062\n",
            "Adjusting learning rate of group 0 to 1.6112e-03.\n",
            "iteration 83 | loss 582.3756103515625\n",
            "Adjusting learning rate of group 0 to 1.6180e-03.\n",
            "iteration 84 | loss 268.75177001953125\n",
            "Adjusting learning rate of group 0 to 1.6248e-03.\n",
            "iteration 85 | loss 753.7651977539062\n",
            "Adjusting learning rate of group 0 to 1.6315e-03.\n",
            "iteration 86 | loss 678.6210327148438\n",
            "Adjusting learning rate of group 0 to 1.6383e-03.\n",
            "iteration 87 | loss 411.7996520996094\n",
            "Adjusting learning rate of group 0 to 1.6451e-03.\n",
            "iteration 88 | loss 696.1504516601562\n",
            "Adjusting learning rate of group 0 to 1.6519e-03.\n",
            "iteration 89 | loss 650.6277465820312\n",
            "Adjusting learning rate of group 0 to 1.6588e-03.\n",
            "iteration 90 | loss 756.4376831054688\n",
            "Adjusting learning rate of group 0 to 1.6656e-03.\n",
            "iteration 91 | loss 635.8497924804688\n",
            "Adjusting learning rate of group 0 to 1.6725e-03.\n",
            "iteration 92 | loss 592.4945068359375\n",
            "Adjusting learning rate of group 0 to 1.6794e-03.\n",
            "iteration 93 | loss 597.3604125976562\n",
            "Adjusting learning rate of group 0 to 1.6863e-03.\n",
            "iteration 94 | loss 379.0322570800781\n",
            "Adjusting learning rate of group 0 to 1.6932e-03.\n",
            "iteration 95 | loss 732.677001953125\n",
            "Adjusting learning rate of group 0 to 1.7001e-03.\n",
            "iteration 96 | loss 571.7194213867188\n",
            "Adjusting learning rate of group 0 to 1.7070e-03.\n",
            "iteration 97 | loss 534.4059448242188\n",
            "Adjusting learning rate of group 0 to 1.7139e-03.\n",
            "iteration 98 | loss 482.7729187011719\n",
            "Adjusting learning rate of group 0 to 1.7209e-03.\n",
            "iteration 99 | loss 504.5298156738281\n",
            "Adjusting learning rate of group 0 to 1.7279e-03.\n",
            "iteration 100 | loss 637.1489868164062\n",
            "Adjusting learning rate of group 0 to 1.7349e-03.\n",
            "iteration 101 | loss 762.9844360351562\n",
            "Adjusting learning rate of group 0 to 1.7419e-03.\n",
            "iteration 102 | loss 297.0382385253906\n",
            "Adjusting learning rate of group 0 to 1.7489e-03.\n",
            "iteration 103 | loss 24.612438201904297\n",
            "Adjusting learning rate of group 0 to 1.7559e-03.\n",
            "iteration 104 | loss 151.82708740234375\n",
            "Adjusting learning rate of group 0 to 1.7629e-03.\n",
            "iteration 105 | loss 216.93978881835938\n",
            "Adjusting learning rate of group 0 to 1.7700e-03.\n",
            "iteration 106 | loss 152.9386749267578\n",
            "Adjusting learning rate of group 0 to 1.7771e-03.\n",
            "iteration 107 | loss 139.08441162109375\n",
            "Adjusting learning rate of group 0 to 1.7842e-03.\n",
            "iteration 108 | loss 94.54556274414062\n",
            "Adjusting learning rate of group 0 to 1.7913e-03.\n",
            "iteration 109 | loss 110.53428649902344\n",
            "Adjusting learning rate of group 0 to 1.7984e-03.\n",
            "iteration 110 | loss 234.12318420410156\n",
            "Adjusting learning rate of group 0 to 1.8055e-03.\n",
            "iteration 111 | loss 17.28672218322754\n",
            "Adjusting learning rate of group 0 to 1.8126e-03.\n",
            "iteration 112 | loss 222.73719787597656\n",
            "Adjusting learning rate of group 0 to 1.8198e-03.\n",
            "iteration 113 | loss 176.69329833984375\n",
            "Adjusting learning rate of group 0 to 1.8269e-03.\n",
            "iteration 114 | loss 152.6896209716797\n",
            "Adjusting learning rate of group 0 to 1.8341e-03.\n",
            "iteration 115 | loss 42.20089340209961\n",
            "Adjusting learning rate of group 0 to 1.8413e-03.\n",
            "iteration 116 | loss 98.80936431884766\n",
            "Adjusting learning rate of group 0 to 1.8485e-03.\n",
            "iteration 117 | loss 120.38492584228516\n",
            "Adjusting learning rate of group 0 to 1.8557e-03.\n",
            "iteration 118 | loss 206.77793884277344\n",
            "Adjusting learning rate of group 0 to 1.8630e-03.\n",
            "iteration 119 | loss 93.70390319824219\n",
            "Adjusting learning rate of group 0 to 1.8702e-03.\n",
            "iteration 120 | loss 649.0569458007812\n",
            "Adjusting learning rate of group 0 to 1.8775e-03.\n",
            "iteration 121 | loss 315.5572509765625\n",
            "Adjusting learning rate of group 0 to 1.8848e-03.\n",
            "iteration 122 | loss 240.1692352294922\n",
            "Adjusting learning rate of group 0 to 1.8921e-03.\n",
            "iteration 123 | loss 165.26588439941406\n",
            "Adjusting learning rate of group 0 to 1.8994e-03.\n",
            "iteration 124 | loss 112.22837829589844\n",
            "Adjusting learning rate of group 0 to 1.9067e-03.\n",
            "iteration 125 | loss 712.0831909179688\n",
            "Adjusting learning rate of group 0 to 1.9140e-03.\n",
            "iteration 126 | loss 360.0600280761719\n",
            "Adjusting learning rate of group 0 to 1.9214e-03.\n",
            "iteration 127 | loss 713.7843627929688\n",
            "Adjusting learning rate of group 0 to 1.9287e-03.\n",
            "iteration 128 | loss 999.239990234375\n",
            "Adjusting learning rate of group 0 to 1.9361e-03.\n",
            "iteration 129 | loss 579.503662109375\n",
            "Adjusting learning rate of group 0 to 1.9435e-03.\n",
            "iteration 130 | loss 186.65798950195312\n",
            "Adjusting learning rate of group 0 to 1.9509e-03.\n",
            "iteration 131 | loss 333.6485595703125\n",
            "Adjusting learning rate of group 0 to 1.9583e-03.\n",
            "iteration 132 | loss 271.8709716796875\n",
            "Adjusting learning rate of group 0 to 1.9657e-03.\n",
            "iteration 133 | loss 246.24183654785156\n",
            "Adjusting learning rate of group 0 to 1.9732e-03.\n",
            "iteration 134 | loss 302.7651672363281\n",
            "Adjusting learning rate of group 0 to 1.9806e-03.\n",
            "iteration 135 | loss 712.3922729492188\n",
            "Adjusting learning rate of group 0 to 1.9881e-03.\n",
            "iteration 136 | loss 300.570068359375\n",
            "Adjusting learning rate of group 0 to 1.9956e-03.\n",
            "iteration 137 | loss 356.0990295410156\n",
            "Adjusting learning rate of group 0 to 2.0031e-03.\n",
            "iteration 138 | loss 170.92530822753906\n",
            "Adjusting learning rate of group 0 to 2.0106e-03.\n",
            "iteration 139 | loss 52.86572265625\n",
            "Adjusting learning rate of group 0 to 2.0181e-03.\n",
            "iteration 140 | loss 886.8299560546875\n",
            "Adjusting learning rate of group 0 to 2.0256e-03.\n",
            "iteration 141 | loss 120.60417938232422\n",
            "Adjusting learning rate of group 0 to 2.0332e-03.\n",
            "iteration 142 | loss 124.92964172363281\n",
            "Adjusting learning rate of group 0 to 2.0408e-03.\n",
            "iteration 143 | loss 303.4963073730469\n",
            "Adjusting learning rate of group 0 to 2.0483e-03.\n",
            "iteration 144 | loss 55.069026947021484\n",
            "Adjusting learning rate of group 0 to 2.0559e-03.\n",
            "iteration 145 | loss 61.629966735839844\n",
            "Adjusting learning rate of group 0 to 2.0635e-03.\n",
            "iteration 146 | loss 1628.6915283203125\n",
            "Adjusting learning rate of group 0 to 2.0712e-03.\n",
            "iteration 147 | loss 1181.2763671875\n",
            "Adjusting learning rate of group 0 to 2.0788e-03.\n",
            "iteration 148 | loss 251.16001892089844\n",
            "Adjusting learning rate of group 0 to 2.0864e-03.\n",
            "iteration 149 | loss 2106.868896484375\n",
            "Adjusting learning rate of group 0 to 2.0941e-03.\n",
            "iteration 150 | loss 882.1787109375\n",
            "Adjusting learning rate of group 0 to 2.1018e-03.\n",
            "iteration 151 | loss 652.4033813476562\n",
            "Adjusting learning rate of group 0 to 2.1095e-03.\n",
            "iteration 152 | loss 762.3212280273438\n",
            "Adjusting learning rate of group 0 to 2.1172e-03.\n",
            "iteration 153 | loss 883.4993896484375\n",
            "Adjusting learning rate of group 0 to 2.1249e-03.\n",
            "iteration 154 | loss 2045.624755859375\n",
            "Adjusting learning rate of group 0 to 2.1326e-03.\n",
            "iteration 155 | loss 275.44866943359375\n",
            "Adjusting learning rate of group 0 to 2.1404e-03.\n",
            "iteration 156 | loss 2065.778076171875\n",
            "Adjusting learning rate of group 0 to 2.1481e-03.\n",
            "iteration 157 | loss 752.9813842773438\n",
            "Adjusting learning rate of group 0 to 2.1559e-03.\n",
            "iteration 158 | loss 1299.8580322265625\n",
            "Adjusting learning rate of group 0 to 2.1637e-03.\n",
            "iteration 159 | loss 2415.3623046875\n",
            "Adjusting learning rate of group 0 to 2.1715e-03.\n",
            "iteration 160 | loss 675.1127319335938\n",
            "Adjusting learning rate of group 0 to 2.1793e-03.\n",
            "iteration 161 | loss 930.1448974609375\n",
            "Adjusting learning rate of group 0 to 2.1871e-03.\n",
            "iteration 162 | loss 360.910888671875\n",
            "Adjusting learning rate of group 0 to 2.1950e-03.\n",
            "iteration 163 | loss 1059.874755859375\n",
            "Adjusting learning rate of group 0 to 2.2028e-03.\n",
            "iteration 164 | loss 1677.1153564453125\n",
            "Adjusting learning rate of group 0 to 2.2107e-03.\n",
            "iteration 165 | loss 530.5062866210938\n",
            "Adjusting learning rate of group 0 to 2.2186e-03.\n",
            "iteration 166 | loss 191.94796752929688\n",
            "Adjusting learning rate of group 0 to 2.2265e-03.\n",
            "iteration 167 | loss 120.7011947631836\n",
            "Adjusting learning rate of group 0 to 2.2344e-03.\n",
            "iteration 168 | loss 429.3297119140625\n",
            "Adjusting learning rate of group 0 to 2.2423e-03.\n",
            "iteration 169 | loss 940.2156372070312\n",
            "Adjusting learning rate of group 0 to 2.2502e-03.\n",
            "iteration 170 | loss 385.4426574707031\n",
            "Adjusting learning rate of group 0 to 2.2582e-03.\n",
            "iteration 171 | loss 141.3874969482422\n",
            "Adjusting learning rate of group 0 to 2.2662e-03.\n",
            "iteration 172 | loss 209.39376831054688\n",
            "Adjusting learning rate of group 0 to 2.2741e-03.\n",
            "iteration 173 | loss 505.73529052734375\n",
            "Adjusting learning rate of group 0 to 2.2821e-03.\n",
            "iteration 174 | loss 727.5110473632812\n",
            "Adjusting learning rate of group 0 to 2.2901e-03.\n",
            "iteration 175 | loss 825.8092651367188\n",
            "Adjusting learning rate of group 0 to 2.2982e-03.\n",
            "iteration 176 | loss 318.199951171875\n",
            "Adjusting learning rate of group 0 to 2.3062e-03.\n",
            "iteration 177 | loss 120.04096984863281\n",
            "Adjusting learning rate of group 0 to 2.3142e-03.\n",
            "iteration 178 | loss 52.56630325317383\n",
            "Adjusting learning rate of group 0 to 2.3223e-03.\n",
            "iteration 179 | loss 49.64881134033203\n",
            "Adjusting learning rate of group 0 to 2.3304e-03.\n",
            "iteration 180 | loss 22.571056365966797\n",
            "Adjusting learning rate of group 0 to 2.3385e-03.\n",
            "iteration 181 | loss 847.7446899414062\n",
            "Adjusting learning rate of group 0 to 2.3466e-03.\n",
            "iteration 182 | loss 371.1707763671875\n",
            "Adjusting learning rate of group 0 to 2.3547e-03.\n",
            "iteration 183 | loss 100.89646911621094\n",
            "Adjusting learning rate of group 0 to 2.3628e-03.\n",
            "iteration 184 | loss 26.35010528564453\n",
            "Adjusting learning rate of group 0 to 2.3709e-03.\n",
            "iteration 185 | loss 289.4554748535156\n",
            "Adjusting learning rate of group 0 to 2.3791e-03.\n",
            "iteration 186 | loss 793.9964599609375\n",
            "Adjusting learning rate of group 0 to 2.3873e-03.\n",
            "iteration 187 | loss 326.1999816894531\n",
            "Adjusting learning rate of group 0 to 2.3955e-03.\n",
            "iteration 188 | loss 641.9077758789062\n",
            "Adjusting learning rate of group 0 to 2.4036e-03.\n",
            "iteration 189 | loss 434.4959411621094\n",
            "Adjusting learning rate of group 0 to 2.4119e-03.\n",
            "iteration 190 | loss 395.9265441894531\n",
            "Adjusting learning rate of group 0 to 2.4201e-03.\n",
            "iteration 191 | loss 46.30488967895508\n",
            "Adjusting learning rate of group 0 to 2.4283e-03.\n",
            "iteration 192 | loss 128.38247680664062\n",
            "Adjusting learning rate of group 0 to 2.4366e-03.\n",
            "iteration 193 | loss 110.3719482421875\n",
            "Adjusting learning rate of group 0 to 2.4448e-03.\n",
            "iteration 194 | loss 57.72126388549805\n",
            "Adjusting learning rate of group 0 to 2.4531e-03.\n",
            "iteration 195 | loss 102.71568298339844\n",
            "Adjusting learning rate of group 0 to 2.4614e-03.\n",
            "iteration 196 | loss 144.36544799804688\n",
            "Adjusting learning rate of group 0 to 2.4697e-03.\n",
            "iteration 197 | loss 129.243896484375\n",
            "Adjusting learning rate of group 0 to 2.4780e-03.\n",
            "iteration 198 | loss 150.479248046875\n",
            "Adjusting learning rate of group 0 to 2.4864e-03.\n",
            "iteration 199 | loss 104.59871673583984\n",
            "Adjusting learning rate of group 0 to 2.4947e-03.\n",
            "iteration 200 | loss 204.79830932617188\n",
            "Adjusting learning rate of group 0 to 2.5031e-03.\n",
            "iteration 201 | loss 210.4846649169922\n",
            "Adjusting learning rate of group 0 to 2.5115e-03.\n",
            "iteration 202 | loss 290.277099609375\n",
            "Adjusting learning rate of group 0 to 2.5198e-03.\n",
            "iteration 203 | loss 327.90850830078125\n",
            "Adjusting learning rate of group 0 to 2.5282e-03.\n",
            "iteration 204 | loss 671.2381591796875\n",
            "Adjusting learning rate of group 0 to 2.5367e-03.\n",
            "iteration 205 | loss 153.33599853515625\n",
            "Adjusting learning rate of group 0 to 2.5451e-03.\n",
            "iteration 206 | loss 32.19608688354492\n",
            "Adjusting learning rate of group 0 to 2.5535e-03.\n",
            "iteration 207 | loss 217.99330139160156\n",
            "Adjusting learning rate of group 0 to 2.5620e-03.\n",
            "iteration 208 | loss 491.8583679199219\n",
            "Adjusting learning rate of group 0 to 2.5705e-03.\n",
            "iteration 209 | loss 99.50251770019531\n",
            "Adjusting learning rate of group 0 to 2.5789e-03.\n",
            "iteration 210 | loss 351.95257568359375\n",
            "Adjusting learning rate of group 0 to 2.5874e-03.\n",
            "iteration 211 | loss 226.58668518066406\n",
            "Adjusting learning rate of group 0 to 2.5959e-03.\n",
            "iteration 212 | loss 64.60081481933594\n",
            "Adjusting learning rate of group 0 to 2.6045e-03.\n",
            "iteration 213 | loss 171.560791015625\n",
            "Adjusting learning rate of group 0 to 2.6130e-03.\n",
            "iteration 214 | loss 168.23033142089844\n",
            "Adjusting learning rate of group 0 to 2.6216e-03.\n",
            "iteration 215 | loss 108.1489486694336\n",
            "Adjusting learning rate of group 0 to 2.6301e-03.\n",
            "iteration 216 | loss 259.5457763671875\n",
            "Adjusting learning rate of group 0 to 2.6387e-03.\n",
            "iteration 217 | loss 292.1003112792969\n",
            "Adjusting learning rate of group 0 to 2.6473e-03.\n",
            "iteration 218 | loss 74.9388427734375\n",
            "Adjusting learning rate of group 0 to 2.6559e-03.\n",
            "iteration 219 | loss 379.26806640625\n",
            "Adjusting learning rate of group 0 to 2.6645e-03.\n",
            "iteration 220 | loss 293.25665283203125\n",
            "Adjusting learning rate of group 0 to 2.6732e-03.\n",
            "iteration 221 | loss 167.78927612304688\n",
            "Adjusting learning rate of group 0 to 2.6818e-03.\n",
            "iteration 222 | loss 343.426025390625\n",
            "Adjusting learning rate of group 0 to 2.6905e-03.\n",
            "iteration 223 | loss 220.01234436035156\n",
            "Adjusting learning rate of group 0 to 2.6991e-03.\n",
            "iteration 224 | loss 41.68219757080078\n",
            "Adjusting learning rate of group 0 to 2.7078e-03.\n",
            "iteration 225 | loss 332.7013854980469\n",
            "Adjusting learning rate of group 0 to 2.7165e-03.\n",
            "iteration 226 | loss 286.4648742675781\n",
            "Adjusting learning rate of group 0 to 2.7252e-03.\n",
            "iteration 227 | loss 204.1300048828125\n",
            "Adjusting learning rate of group 0 to 2.7340e-03.\n",
            "iteration 228 | loss 129.4963836669922\n",
            "Adjusting learning rate of group 0 to 2.7427e-03.\n",
            "iteration 229 | loss 287.9913635253906\n",
            "Adjusting learning rate of group 0 to 2.7515e-03.\n",
            "iteration 230 | loss 189.08250427246094\n",
            "Adjusting learning rate of group 0 to 2.7602e-03.\n",
            "iteration 231 | loss 212.95901489257812\n",
            "Adjusting learning rate of group 0 to 2.7690e-03.\n",
            "iteration 232 | loss 153.24600219726562\n",
            "Adjusting learning rate of group 0 to 2.7778e-03.\n",
            "iteration 233 | loss 172.13430786132812\n",
            "Adjusting learning rate of group 0 to 2.7866e-03.\n",
            "iteration 234 | loss 182.81137084960938\n",
            "Adjusting learning rate of group 0 to 2.7954e-03.\n",
            "iteration 235 | loss 237.40911865234375\n",
            "Adjusting learning rate of group 0 to 2.8043e-03.\n",
            "iteration 236 | loss 137.0128173828125\n",
            "Adjusting learning rate of group 0 to 2.8131e-03.\n",
            "iteration 237 | loss 96.28958129882812\n",
            "Adjusting learning rate of group 0 to 2.8220e-03.\n",
            "iteration 238 | loss 55.30531692504883\n",
            "Adjusting learning rate of group 0 to 2.8309e-03.\n",
            "iteration 239 | loss 109.05355834960938\n",
            "Adjusting learning rate of group 0 to 2.8398e-03.\n",
            "iteration 240 | loss 69.07829284667969\n",
            "Adjusting learning rate of group 0 to 2.8487e-03.\n",
            "iteration 241 | loss 143.0023193359375\n",
            "Adjusting learning rate of group 0 to 2.8576e-03.\n",
            "iteration 242 | loss 1618.98486328125\n",
            "Adjusting learning rate of group 0 to 2.8665e-03.\n",
            "iteration 243 | loss 68.88542938232422\n",
            "Adjusting learning rate of group 0 to 2.8755e-03.\n",
            "iteration 244 | loss 88.19731903076172\n",
            "Adjusting learning rate of group 0 to 2.8844e-03.\n",
            "iteration 245 | loss 99.48550415039062\n",
            "Adjusting learning rate of group 0 to 2.8934e-03.\n",
            "iteration 246 | loss 140.35035705566406\n",
            "Adjusting learning rate of group 0 to 2.9024e-03.\n",
            "iteration 247 | loss 82.7717056274414\n",
            "Adjusting learning rate of group 0 to 2.9114e-03.\n",
            "iteration 248 | loss 106.82134246826172\n",
            "Adjusting learning rate of group 0 to 2.9204e-03.\n",
            "iteration 249 | loss 100.7181396484375\n",
            "Adjusting learning rate of group 0 to 2.9294e-03.\n",
            "iteration 250 | loss 105.00562286376953\n",
            "Adjusting learning rate of group 0 to 2.9384e-03.\n",
            "iteration 251 | loss 64.6845703125\n",
            "Adjusting learning rate of group 0 to 2.9475e-03.\n",
            "iteration 252 | loss 137.7595977783203\n",
            "Adjusting learning rate of group 0 to 2.9566e-03.\n",
            "iteration 253 | loss 168.46580505371094\n",
            "Adjusting learning rate of group 0 to 2.9656e-03.\n",
            "iteration 254 | loss 94.31710815429688\n",
            "Adjusting learning rate of group 0 to 2.9747e-03.\n",
            "iteration 255 | loss 95.26652526855469\n",
            "Adjusting learning rate of group 0 to 2.9838e-03.\n",
            "iteration 256 | loss 132.79322814941406\n",
            "Adjusting learning rate of group 0 to 2.9930e-03.\n",
            "iteration 257 | loss 124.95341491699219\n",
            "Adjusting learning rate of group 0 to 3.0021e-03.\n",
            "iteration 258 | loss 53.86249923706055\n",
            "Adjusting learning rate of group 0 to 3.0113e-03.\n",
            "iteration 259 | loss 66.74552917480469\n",
            "Adjusting learning rate of group 0 to 3.0204e-03.\n",
            "iteration 260 | loss 84.41351318359375\n",
            "Adjusting learning rate of group 0 to 3.0296e-03.\n",
            "iteration 261 | loss 94.52215576171875\n",
            "Adjusting learning rate of group 0 to 3.0388e-03.\n",
            "iteration 262 | loss 68.42742156982422\n",
            "Adjusting learning rate of group 0 to 3.0480e-03.\n",
            "iteration 263 | loss 98.1492919921875\n",
            "Adjusting learning rate of group 0 to 3.0572e-03.\n",
            "iteration 264 | loss 83.94737243652344\n",
            "Adjusting learning rate of group 0 to 3.0664e-03.\n",
            "iteration 265 | loss 132.74844360351562\n",
            "Adjusting learning rate of group 0 to 3.0757e-03.\n",
            "iteration 266 | loss 1013.2408447265625\n",
            "Adjusting learning rate of group 0 to 3.0849e-03.\n",
            "iteration 267 | loss 45.82310104370117\n",
            "Adjusting learning rate of group 0 to 3.0942e-03.\n",
            "iteration 268 | loss 165.0735321044922\n",
            "Adjusting learning rate of group 0 to 3.1035e-03.\n",
            "iteration 269 | loss 95.70741271972656\n",
            "Adjusting learning rate of group 0 to 3.1128e-03.\n",
            "iteration 270 | loss 51.938594818115234\n",
            "Adjusting learning rate of group 0 to 3.1221e-03.\n",
            "iteration 271 | loss 47.96556854248047\n",
            "Adjusting learning rate of group 0 to 3.1314e-03.\n",
            "iteration 272 | loss 47.950439453125\n",
            "Adjusting learning rate of group 0 to 3.1407e-03.\n",
            "iteration 273 | loss 43.46487808227539\n",
            "Adjusting learning rate of group 0 to 3.1501e-03.\n",
            "iteration 274 | loss 164.485107421875\n",
            "Adjusting learning rate of group 0 to 3.1594e-03.\n",
            "iteration 275 | loss 67.12164306640625\n",
            "Adjusting learning rate of group 0 to 3.1688e-03.\n",
            "iteration 276 | loss 56.76095962524414\n",
            "Adjusting learning rate of group 0 to 3.1782e-03.\n",
            "iteration 277 | loss 98.4624252319336\n",
            "Adjusting learning rate of group 0 to 3.1876e-03.\n",
            "iteration 278 | loss 112.19837188720703\n",
            "Adjusting learning rate of group 0 to 3.1970e-03.\n",
            "iteration 279 | loss 65.00109100341797\n",
            "Adjusting learning rate of group 0 to 3.2065e-03.\n",
            "iteration 280 | loss 103.12693786621094\n",
            "Adjusting learning rate of group 0 to 3.2159e-03.\n",
            "iteration 281 | loss 58.411888122558594\n",
            "Adjusting learning rate of group 0 to 3.2254e-03.\n",
            "iteration 282 | loss 64.07898712158203\n",
            "Adjusting learning rate of group 0 to 3.2348e-03.\n",
            "iteration 283 | loss 59.393707275390625\n",
            "Adjusting learning rate of group 0 to 3.2443e-03.\n",
            "iteration 284 | loss 736.3970947265625\n",
            "Adjusting learning rate of group 0 to 3.2538e-03.\n",
            "iteration 285 | loss 200.69825744628906\n",
            "Adjusting learning rate of group 0 to 3.2633e-03.\n",
            "iteration 286 | loss 848.4205322265625\n",
            "Adjusting learning rate of group 0 to 3.2728e-03.\n",
            "iteration 287 | loss 65.48846435546875\n",
            "Adjusting learning rate of group 0 to 3.2824e-03.\n",
            "iteration 288 | loss 666.91748046875\n",
            "Adjusting learning rate of group 0 to 3.2919e-03.\n",
            "iteration 289 | loss 499.773193359375\n",
            "Adjusting learning rate of group 0 to 3.3015e-03.\n",
            "iteration 290 | loss 102.99181365966797\n",
            "Adjusting learning rate of group 0 to 3.3111e-03.\n",
            "iteration 291 | loss 477.6739501953125\n",
            "Adjusting learning rate of group 0 to 3.3207e-03.\n",
            "iteration 292 | loss 57.98968505859375\n",
            "Adjusting learning rate of group 0 to 3.3303e-03.\n",
            "iteration 293 | loss 65.37611389160156\n",
            "Adjusting learning rate of group 0 to 3.3399e-03.\n",
            "iteration 294 | loss 50.39988708496094\n",
            "Adjusting learning rate of group 0 to 3.3495e-03.\n",
            "iteration 295 | loss 56.95014953613281\n",
            "Adjusting learning rate of group 0 to 3.3592e-03.\n",
            "iteration 296 | loss 92.87312316894531\n",
            "Adjusting learning rate of group 0 to 3.3688e-03.\n",
            "iteration 297 | loss 56.71839141845703\n",
            "Adjusting learning rate of group 0 to 3.3785e-03.\n",
            "iteration 298 | loss 86.2359848022461\n",
            "Adjusting learning rate of group 0 to 3.3882e-03.\n",
            "iteration 299 | loss 90.59602355957031\n",
            "Adjusting learning rate of group 0 to 3.3979e-03.\n",
            "iteration 300 | loss 134.03106689453125\n",
            "Adjusting learning rate of group 0 to 3.4076e-03.\n",
            "iteration 301 | loss 58.92815017700195\n",
            "Adjusting learning rate of group 0 to 3.4173e-03.\n",
            "iteration 302 | loss 82.61505126953125\n",
            "Adjusting learning rate of group 0 to 3.4271e-03.\n",
            "iteration 303 | loss 74.99626922607422\n",
            "Adjusting learning rate of group 0 to 3.4368e-03.\n",
            "iteration 304 | loss 118.44830322265625\n",
            "Adjusting learning rate of group 0 to 3.4466e-03.\n",
            "iteration 305 | loss 98.03009033203125\n",
            "Adjusting learning rate of group 0 to 3.4563e-03.\n",
            "iteration 306 | loss 320.3985595703125\n",
            "Adjusting learning rate of group 0 to 3.4661e-03.\n",
            "iteration 307 | loss 58.422916412353516\n",
            "Adjusting learning rate of group 0 to 3.4759e-03.\n",
            "iteration 308 | loss 81.92893981933594\n",
            "Adjusting learning rate of group 0 to 3.4858e-03.\n",
            "iteration 309 | loss 60.58628463745117\n",
            "Adjusting learning rate of group 0 to 3.4956e-03.\n",
            "iteration 310 | loss 91.76226806640625\n",
            "Adjusting learning rate of group 0 to 3.5054e-03.\n",
            "iteration 311 | loss 74.00477600097656\n",
            "Adjusting learning rate of group 0 to 3.5153e-03.\n",
            "iteration 312 | loss 67.62256622314453\n",
            "Adjusting learning rate of group 0 to 3.5252e-03.\n",
            "iteration 313 | loss 79.76432800292969\n",
            "Adjusting learning rate of group 0 to 3.5351e-03.\n",
            "iteration 314 | loss 87.5992431640625\n",
            "Adjusting learning rate of group 0 to 3.5450e-03.\n",
            "iteration 315 | loss 101.79473876953125\n",
            "Adjusting learning rate of group 0 to 3.5549e-03.\n",
            "iteration 316 | loss 72.8985366821289\n",
            "Adjusting learning rate of group 0 to 3.5648e-03.\n",
            "iteration 317 | loss 88.64485168457031\n",
            "Adjusting learning rate of group 0 to 3.5747e-03.\n",
            "iteration 318 | loss 80.84717559814453\n",
            "Adjusting learning rate of group 0 to 3.5847e-03.\n",
            "iteration 319 | loss 63.70219039916992\n",
            "Adjusting learning rate of group 0 to 3.5946e-03.\n",
            "iteration 320 | loss 97.22769165039062\n",
            "Adjusting learning rate of group 0 to 3.6046e-03.\n",
            "iteration 321 | loss 77.14739227294922\n",
            "Adjusting learning rate of group 0 to 3.6146e-03.\n",
            "iteration 322 | loss 77.71439361572266\n",
            "Adjusting learning rate of group 0 to 3.6246e-03.\n",
            "iteration 323 | loss 67.08807373046875\n",
            "Adjusting learning rate of group 0 to 3.6346e-03.\n",
            "iteration 324 | loss 93.46464538574219\n",
            "Adjusting learning rate of group 0 to 3.6447e-03.\n",
            "iteration 325 | loss 105.70191192626953\n",
            "Adjusting learning rate of group 0 to 3.6547e-03.\n",
            "iteration 326 | loss 111.82908630371094\n",
            "Adjusting learning rate of group 0 to 3.6648e-03.\n",
            "iteration 327 | loss 74.04228973388672\n",
            "Adjusting learning rate of group 0 to 3.6748e-03.\n",
            "iteration 328 | loss 65.98420715332031\n",
            "Adjusting learning rate of group 0 to 3.6849e-03.\n",
            "iteration 329 | loss 77.06539154052734\n",
            "Adjusting learning rate of group 0 to 3.6950e-03.\n",
            "iteration 330 | loss 76.1175308227539\n",
            "Adjusting learning rate of group 0 to 3.7051e-03.\n",
            "iteration 331 | loss 69.34017944335938\n",
            "Adjusting learning rate of group 0 to 3.7153e-03.\n",
            "iteration 332 | loss 82.56301879882812\n",
            "Adjusting learning rate of group 0 to 3.7254e-03.\n",
            "iteration 333 | loss 81.29151153564453\n",
            "Adjusting learning rate of group 0 to 3.7356e-03.\n",
            "iteration 334 | loss 100.5476303100586\n",
            "Adjusting learning rate of group 0 to 3.7457e-03.\n",
            "iteration 335 | loss 83.93792724609375\n",
            "Adjusting learning rate of group 0 to 3.7559e-03.\n",
            "iteration 336 | loss 83.38980102539062\n",
            "Adjusting learning rate of group 0 to 3.7661e-03.\n",
            "iteration 337 | loss 114.7133560180664\n",
            "Adjusting learning rate of group 0 to 3.7763e-03.\n",
            "iteration 338 | loss 218.56900024414062\n",
            "Adjusting learning rate of group 0 to 3.7865e-03.\n",
            "iteration 339 | loss 100.07572174072266\n",
            "Adjusting learning rate of group 0 to 3.7967e-03.\n",
            "iteration 340 | loss 156.4479522705078\n",
            "Adjusting learning rate of group 0 to 3.8070e-03.\n",
            "iteration 341 | loss 82.91846466064453\n",
            "Adjusting learning rate of group 0 to 3.8172e-03.\n",
            "iteration 342 | loss 84.41595458984375\n",
            "Adjusting learning rate of group 0 to 3.8275e-03.\n",
            "iteration 343 | loss 103.80257415771484\n",
            "Adjusting learning rate of group 0 to 3.8378e-03.\n",
            "iteration 344 | loss 91.183349609375\n",
            "Adjusting learning rate of group 0 to 3.8481e-03.\n",
            "iteration 345 | loss 91.44750213623047\n",
            "Adjusting learning rate of group 0 to 3.8584e-03.\n",
            "iteration 346 | loss 95.72779083251953\n",
            "Adjusting learning rate of group 0 to 3.8687e-03.\n",
            "iteration 347 | loss 108.00244140625\n",
            "Adjusting learning rate of group 0 to 3.8791e-03.\n",
            "iteration 348 | loss 85.43196868896484\n",
            "Adjusting learning rate of group 0 to 3.8894e-03.\n",
            "iteration 349 | loss 120.05391693115234\n",
            "Adjusting learning rate of group 0 to 3.8998e-03.\n",
            "iteration 350 | loss 84.31271362304688\n",
            "Adjusting learning rate of group 0 to 3.9102e-03.\n",
            "iteration 351 | loss 74.44672393798828\n",
            "Adjusting learning rate of group 0 to 3.9205e-03.\n",
            "iteration 352 | loss 195.151611328125\n",
            "Adjusting learning rate of group 0 to 3.9309e-03.\n",
            "iteration 353 | loss 95.98011779785156\n",
            "Adjusting learning rate of group 0 to 3.9414e-03.\n",
            "iteration 354 | loss 121.58111572265625\n",
            "Adjusting learning rate of group 0 to 3.9518e-03.\n",
            "iteration 355 | loss 232.02886962890625\n",
            "Adjusting learning rate of group 0 to 3.9622e-03.\n",
            "iteration 356 | loss 235.69580078125\n",
            "Adjusting learning rate of group 0 to 3.9727e-03.\n",
            "iteration 357 | loss 203.42015075683594\n",
            "Adjusting learning rate of group 0 to 3.9832e-03.\n",
            "iteration 358 | loss 185.78042602539062\n",
            "Adjusting learning rate of group 0 to 3.9936e-03.\n",
            "iteration 359 | loss 151.1162109375\n",
            "Adjusting learning rate of group 0 to 4.0041e-03.\n",
            "iteration 360 | loss 650.3184814453125\n",
            "Adjusting learning rate of group 0 to 4.0147e-03.\n",
            "iteration 361 | loss 93.30743408203125\n",
            "Adjusting learning rate of group 0 to 4.0252e-03.\n",
            "iteration 362 | loss 90.14049530029297\n",
            "Adjusting learning rate of group 0 to 4.0357e-03.\n",
            "iteration 363 | loss 144.71197509765625\n",
            "Adjusting learning rate of group 0 to 4.0463e-03.\n",
            "iteration 364 | loss 97.80668640136719\n",
            "Adjusting learning rate of group 0 to 4.0568e-03.\n",
            "iteration 365 | loss 103.18586730957031\n",
            "Adjusting learning rate of group 0 to 4.0674e-03.\n",
            "iteration 366 | loss 88.14066314697266\n",
            "Adjusting learning rate of group 0 to 4.0780e-03.\n",
            "iteration 367 | loss 100.4271011352539\n",
            "Adjusting learning rate of group 0 to 4.0886e-03.\n",
            "iteration 368 | loss 92.87940216064453\n",
            "Adjusting learning rate of group 0 to 4.0992e-03.\n",
            "iteration 369 | loss 102.135009765625\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6aefcfb06554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/sparsity/training/train_model.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/sparsity/training/train_model.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRandomly\u001b[0m \u001b[0mflipped\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \"\"\"\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from training.train_model import main\n",
        "\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "533dc1b5f6751e9c738350df3cd1b0ef5f569dd461507537431de13a6c09381e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}