{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UouF1hDuRp76"
      },
      "source": [
        "# Brief Introduction to Compiling and Debugging CUDA in Colab\n",
        "\n",
        "This is a short summary of how to compile and debug CUDA programs in the Google Colab environment. Many thanks to Elisabeth Brunet for some of the example code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UgGjl7LSBeG"
      },
      "source": [
        "### Compiling\n",
        "1. Create a file with the program code. To do so, put your pogram into a code cell where the first line is<br>\n",
        "`%%writefile prog.cu` <br>\n",
        "Executing this cell with write its content to the file `prog.cu` (the name is arbitrary).\n",
        "2. Compile your file by calling the compiler `nvcc` from the shell:<br>\n",
        "```!nvcc -g -G -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include -lcublas -lcusolver  -arch=sm_35 -Wno-deprecated-gpu-targets prog.cu```\n",
        "3. Run your program:<br>\n",
        "`!./a.out`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E06o_A-JU457"
      },
      "source": [
        "Here's a quick example. First, the program:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ou-b1S9TYBp",
        "outputId": "eee6f2b1-9635-43e0-e347-7e690cee806f"
      },
      "source": [
        "%%writefile prog.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void add(int a, int b, int *res) {\n",
        "  *res = a + b;\n",
        "}\n",
        "int main() {\n",
        "  int res=0;\n",
        "  int *d_res;\n",
        "  // reserve memory for the result on the GPU\n",
        "  cudaMalloc((void**)&d_res, sizeof(int));\n",
        "  // Launch add() kernel on GPU, \n",
        "  // which writes its result to address d_res on GPU\n",
        "  add<<<1,1>>>(2, 2, d_res);\n",
        "  // wait for the GPU to finish\n",
        "  cudaDeviceSynchronize();\n",
        "  // copy result back to CPU\n",
        "  cudaMemcpy(&res, d_res, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  // print result\n",
        "  printf(\"2 + 2 = %d\\n\", res);\n",
        "  return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prog.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJyLAetKU-fl"
      },
      "source": [
        "Let's compile the program. We need to call `nvcc` with a shell command. In Jupyter, shell commands start with `!`. We need to include the directories for the Cuda include files (`-I`)  and Cuda libraries (`-L`). Let's link also the cuBlas and cuSolver libraries, since you might need them at some point. We don't specify the name of the executable, so it will be the default `a.out`.  If everything goes well, executing the cell does not give any output. If the compiler has problems, you will see the error messages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW4NEuImTzYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a71401-ed26-4c08-894c-10909f03cce4"
      },
      "source": [
        "!nvcc -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include -lcublas -lcusolver -arch=sm_35 -Wno-deprecated-gpu-targets prog.cu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0U1IkVlXMK7"
      },
      "source": [
        "Let's run the program. Again, `!` indicates a shell command, and we must prefix the name of the executable with `./` so the shell looks for it in the current directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8Nd1xU3XV4j",
        "outputId": "7f2d587a-1307-41b9-83e3-0f166e74ae98"
      },
      "source": [
        "!./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 + 2 = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMWBZOvNYXgJ"
      },
      "source": [
        "## Debugging\n",
        "Here are some tips on debugging if your program crashes:\n",
        "1. The interface between the Jupyter Notebook and the executed program is a little fragile. So if your program crashes, there might not be ANY output at all, even if you have `printf` everywhere.\n",
        "2. If you do use `printf`, be sure to flush the buffer by adding a line break at the end. This applies to any C program. Example:<br> `printf(\"Works up to here\\n);`\n",
        "2. Be sure to add error checks to EVERY cuda call (including cudaMalloc, cudaMemcpy, etc.) and call `cudaPeekAtLastError()` after kernel calls.\n",
        "2. A frequent mistake is to forget that the CPU doesn't wait for kernel calls to finish. To wait for the GPU after a kernel call, use `cudaDeviceSynchronize()`.\n",
        "If your program still crashes without output, the last resort is calling the debugger. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sCJ4lyEirM-"
      },
      "source": [
        "To debug with `cuda-gdb`, you need to compile as described above, adding the options \"-g -G\" so that debugging symbols are included:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6vP7KJ9iy_Y"
      },
      "source": [
        "!nvcc -g -G -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include -lcublas -lcusolver prog.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMP8kolvjEWp"
      },
      "source": [
        "The debugger is interactive (you are expected to type commands as you go along), but running programs in Jupyter Notebooks is not. So you need to write your commands to a file.\n",
        "Typical commands would go like this:\n",
        "1. set the debugger up to check lots of possible errors:\n",
        "  1. memory checks `memcheck on`,\n",
        "  2. stop in case of API failures `api_failures stop`,\n",
        "  3. stop on exceptions `catch throw`, \n",
        "2. run the program (possibly with command line options) `r option1 option2`\n",
        ", \n",
        "3. show the kernel call stack (GPU) `bt`, \n",
        "4. print all local variables `info locals`, \n",
        "5. switch to the host thread `thread 1` and show the host program call stack (CPU) `bt`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCCjhsV1fYQZ"
      },
      "source": [
        "You can use `%%writefile` to create a file `tmp.txt` with commands:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0UgPTODk9y2",
        "outputId": "aa681a2d-4181-41ea-b881-801f45d48f9d"
      },
      "source": [
        "%%writefile tmp.txt\n",
        "set cuda memcheck on\n",
        "set cuda api_failures stop\n",
        "catch throw\n",
        "r\n",
        "bt\n",
        "info locals\n",
        "thread 1\n",
        "bt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tmp.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTPMBSceli_Z"
      },
      "source": [
        "For a more compact solution, here's a one-liner shell command to write  commands to the file `tmp.txt`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKISb8ubjFI4"
      },
      "source": [
        "!printf \"set cuda memcheck on\\nset cuda api_failures stop\\ncatch throw\\nr\\nbt\\ninfo locals\\nthread 1\\nbt\\n\" > tmp.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrTXSqO4lKXj"
      },
      "source": [
        "Now call the debugger with your program and execute the commands from tmp.txt. If your program terminates fine, `cuda-gdb` will complain that there's no stack (since the program finished):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFtzA6dklJoh",
        "outputId": "31ae8f63-47c7-4912-df4b-5ab690940e5e"
      },
      "source": [
        "! cuda-gdb -batch -x tmp.txt ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Catchpoint 1 (throw)\n",
            "warning: Error disabling address space randomization: Operation not permitted\n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n",
            "[Detaching after fork from child process 505]\n",
            "[New Thread 0x7f33d491e700 (LWP 509)]\n",
            "[New Thread 0x7f33d411d700 (LWP 510)]\n",
            "Cuda API error detected: cudaLaunchKernel returned (0xd1)\n",
            "#0  0x00007f33d4d0e3e0 in cudbgReportDriverApiError () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#1  0x00007f33d4d17aa1 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#2  0x00007f33d4c6b1f6 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#3  0x00007f33d4c99373 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#4  0x00005627ac169475 in cudaLaunchKernel ()\n",
            "#5  0x00005627ac11f4b7 in cudaLaunchKernel<char> (func=0x5627ac11f38e <add(int, int, int*)> \"UH\\211\\345H\\203\\354\\020\\211}\\374\\211u\\370H\\211U\\360H\\213U\\360\\213M\\370\\213E\\374\\211풀\\307\\350\\206\\376\\377\\377\\220\\311\\303UH\\211\\345H\\203\\354\\020H\\211}\\370H\\213E\\370H\\211\\005\\023\\035(\", gridDim=..., blockDim=..., args=0x7ffe4824a580, sharedMem=0, stream=0x0) at /usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h:210\n",
            "#6  0x00005627ac11f36a in __device_stub__Z3addiiPi (__par0=2, __par1=2, __par2=0x703940000) at /tmp/tmpxft_000001d0_00000000-6_prog.cudafe1.stub.c:13\n",
            "#7  0x00005627ac11f3b3 in add (__cuda_0=2, __cuda_1=2, __cuda_2=0x703940000) at prog.cu:4\n",
            "#8  0x00005627ac11f18d in main () at prog.cu:14\n",
            "No symbol table info available.\n",
            "[Switching to thread 1 (Thread 0x7f33d7c06000 (LWP 500))]\n",
            "#0  0x00007f33d4d0e3e0 in cudbgReportDriverApiError () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#0  0x00007f33d4d0e3e0 in cudbgReportDriverApiError () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#1  0x00007f33d4d17aa1 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#2  0x00007f33d4c6b1f6 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#3  0x00007f33d4c99373 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#4  0x00005627ac169475 in cudaLaunchKernel ()\n",
            "#5  0x00005627ac11f4b7 in cudaLaunchKernel<char> (func=0x5627ac11f38e <add(int, int, int*)> \"UH\\211\\345H\\203\\354\\020\\211}\\374\\211u\\370H\\211U\\360H\\213U\\360\\213M\\370\\213E\\374\\211풀\\307\\350\\206\\376\\377\\377\\220\\311\\303UH\\211\\345H\\203\\354\\020H\\211}\\370H\\213E\\370H\\211\\005\\023\\035(\", gridDim=..., blockDim=..., args=0x7ffe4824a580, sharedMem=0, stream=0x0) at /usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h:210\n",
            "#6  0x00005627ac11f36a in __device_stub__Z3addiiPi (__par0=2, __par1=2, __par2=0x703940000) at /tmp/tmpxft_000001d0_00000000-6_prog.cudafe1.stub.c:13\n",
            "#7  0x00005627ac11f3b3 in add (__cuda_0=2, __cuda_1=2, __cuda_2=0x703940000) at prog.cu:4\n",
            "#8  0x00005627ac11f18d in main () at prog.cu:14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlCkC_9Jno_d"
      },
      "source": [
        "So let's look at a program with an error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1moAW9WRxyO",
        "outputId": "3b5abe69-cb97-445d-ac83-7eea1ceeaf18"
      },
      "source": [
        "%%writefile prog.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void add(int a, int b, int *res) {\n",
        "  *res = a + b;\n",
        "}\n",
        "int main() {\n",
        "  int res=0;\n",
        "  int *d_res;\n",
        "  // suppose we forgot malloc: cudaMalloc((void**)&d_res, sizeof(int));\n",
        "  add<<<1,1>>>(2, 2, d_res);\n",
        "  cudaMemcpy(&res, d_res, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  printf(\"2 + 2 = %d\\n\", res);\n",
        "\n",
        "  return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prog.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYITIZh6pmF5"
      },
      "source": [
        "Compiling this faulty code gives a warning, but the program compiles and runs fine. It just doesn't give the correct result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWabd01AplPu",
        "outputId": "8852e476-e652-4aaf-bffe-9be5aaa400c8"
      },
      "source": [
        "!nvcc -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include -lcublas -lcusolver prog.cu\n",
        "!./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prog.cu(11): warning: variable \"d_res\" is used before its value is set\n",
            "\n",
            "prog.cu(11): warning: variable \"d_res\" is used before its value is set\n",
            "\n",
            "2 + 2 = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ncjdMUNqDCG"
      },
      "source": [
        "We can try to catch this problem in two ways: use a debugger to check for memory errors and other problems, or add explicit error checks (which is discussed in the  next section)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDnqYunsn9kf"
      },
      "source": [
        "Let's compile for debugging, write the debug commands to `tmp.txt` and call `cuda-gdb`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-CovU2Nn0X4",
        "outputId": "d6e074c9-45e7-47aa-d6bb-c03c5175b7f1"
      },
      "source": [
        "!nvcc -g -G -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include -lcublas -lcusolver prog.cu\n",
        "!printf \"set cuda memcheck on\\nset cuda api_failures stop\\ncatch throw\\nr\\nbt\\ninfo locals\\nthread 1\\nbt\\n\" > tmp.txt\n",
        "!cuda-gdb -batch -x tmp.txt ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prog.cu(11): warning: variable \"d_res\" is used before its value is set\n",
            "\n",
            "prog.cu(11): warning: variable \"d_res\" is used before its value is set\n",
            "\n",
            "Catchpoint 1 (throw)\n",
            "warning: Error disabling address space randomization: Operation not permitted\n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n",
            "[Detaching after fork from child process 588]\n",
            "[New Thread 0x7f933fe3e700 (LWP 592)]\n",
            "[New Thread 0x7f933f63d700 (LWP 593)]\n",
            "Cuda API error detected: cudaLaunchKernel returned (0xd1)\n",
            "#0  0x00007f934022e3e0 in cudbgReportDriverApiError () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#1  0x00007f9340237aa1 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#2  0x00007f934018b1f6 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#3  0x00007f93401b9373 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#4  0x0000564f8566b465 in cudaLaunchKernel ()\n",
            "#5  0x0000564f856214a1 in cudaLaunchKernel<char> (func=0x564f85621378 <add(int, int, int*)> \"UH\\211\\345H\\203\\354\\020\\211}\\374\\211u\\370H\\211U\\360H\\213U\\360\\213M\\370\\213E\\374\\211풀\\307\\350\\206\\376\\377\\377\\220\\311\\303UH\\211\\345H\\203\\354\\020H\\211}\\370H\\213E\\370H\\211\\005)\\035(\", gridDim=..., blockDim=..., args=0x7fffaad6fa90, sharedMem=0, stream=0x0) at /usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h:210\n",
            "#6  0x0000564f85621354 in __device_stub__Z3addiiPi (__par0=2, __par1=2, __par2=0x0) at /tmp/tmpxft_00000223_00000000-6_prog.cudafe1.stub.c:13\n",
            "#7  0x0000564f8562139d in add (__cuda_0=2, __cuda_1=2, __cuda_2=0x0) at prog.cu:4\n",
            "#8  0x0000564f8562117c in main () at prog.cu:11\n",
            "No symbol table info available.\n",
            "[Switching to thread 1 (Thread 0x7f9343126000 (LWP 583))]\n",
            "#0  0x00007f934022e3e0 in cudbgReportDriverApiError () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#0  0x00007f934022e3e0 in cudbgReportDriverApiError () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#1  0x00007f9340237aa1 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#2  0x00007f934018b1f6 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#3  0x00007f93401b9373 in ?? () from /usr/lib64-nvidia/libcuda.so.1\n",
            "#4  0x0000564f8566b465 in cudaLaunchKernel ()\n",
            "#5  0x0000564f856214a1 in cudaLaunchKernel<char> (func=0x564f85621378 <add(int, int, int*)> \"UH\\211\\345H\\203\\354\\020\\211}\\374\\211u\\370H\\211U\\360H\\213U\\360\\213M\\370\\213E\\374\\211풀\\307\\350\\206\\376\\377\\377\\220\\311\\303UH\\211\\345H\\203\\354\\020H\\211}\\370H\\213E\\370H\\211\\005)\\035(\", gridDim=..., blockDim=..., args=0x7fffaad6fa90, sharedMem=0, stream=0x0) at /usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h:210\n",
            "#6  0x0000564f85621354 in __device_stub__Z3addiiPi (__par0=2, __par1=2, __par2=0x0) at /tmp/tmpxft_00000223_00000000-6_prog.cudafe1.stub.c:13\n",
            "#7  0x0000564f8562139d in add (__cuda_0=2, __cuda_1=2, __cuda_2=0x0) at prog.cu:4\n",
            "#8  0x0000564f8562117c in main () at prog.cu:11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm9dVE1XlSCK"
      },
      "source": [
        "We get an exception and lots of information. There is an illegal address detected in line 5 of `prog.cu`, which is in kernel `add`. We also see the call stack for the host, which shows that the kernel is called in `main()` at line 11. To see line numbers in Colab, use Ctrl + M + L and take into account that the `%%writefile` increases the line number by one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwKHobUvYbPx"
      },
      "source": [
        "## Error Checking in Cuda\n",
        "The CPU is not notified when an error occurs on the GPU. This means that you need to check after every Cuda call whether there was an error, by looking at the return value of the Cuda function. Since kernel calls don't have a return value, you need to call `cudaPeekAtLastError()`. The following code from Stack Overflow works nicely. It uses a macro to show the function name and line number if there is an error:\n",
        "\n",
        "```\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess) \n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2aUxQa0aunC"
      },
      "source": [
        "Our faulty example program looks as follows with error checking. Note the `gpuErrchk` on every line involving Cuda and the `cudaPeekAtLastError()` after the kernel call:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx-cgmc6azJc",
        "outputId": "ca1b2114-1feb-46d8-dfcb-b2205ad3f9a3"
      },
      "source": [
        "%%writefile prog.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess) {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "\n",
        "__global__ void add(int a, int b, int *res) {\n",
        "  *res = a + b;\n",
        "}\n",
        "int main() {\n",
        "  int res=0;\n",
        "  int *d_res;\n",
        "  // suppose we forgot this:  gpuErrchk( cudaMalloc((void**)&d_res, sizeof(int)) );\n",
        "  add<<<1,1>>>(2, 2, d_res);\n",
        "  gpuErrchk( cudaPeekAtLastError() );\n",
        "  gpuErrchk( cudaDeviceSynchronize() );\n",
        "  gpuErrchk( cudaMemcpy(&res, d_res, sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "  // print result\n",
        "  printf(\"2 + 2 = %d\\n\", res);\n",
        "  return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prog.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSsANIImbh1p"
      },
      "source": [
        "Let's see if it still compiles and runs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOX3hSm1bh1y",
        "outputId": "e15cb80d-a572-4fca-bb38-6b20d45de09e"
      },
      "source": [
        "!nvcc -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include -lcublas -lcusolver prog.cu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prog.cu(20): warning: variable \"d_res\" is used before its value is set\n",
            "\n",
            "prog.cu(20): warning: variable \"d_res\" is used before its value is set\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owbrBb8_bh1y",
        "outputId": "6c074028-1008-4840-d1b6-34c5d50b3b2d"
      },
      "source": [
        "!./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUassert: no kernel image is available for execution on the device prog.cu 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzNQi9dSqdXq"
      },
      "source": [
        "Thanks to the error checking, we get an error message. That's much better than the program finishing its computation but giving a wrong result.\n",
        "Note that here, we only know that the last kernel caused the error, but not where inside the kernel the error occured. You can use the debugger to find out more details, as described above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah9KvoHhpXZp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}